[["index.html", "Creating the cssr R package 1 Introduction", " Creating the cssr R package Gregory Faletto April 17, 2023 1 Introduction Cluster stability selection is a feature selection method designed to allow stability selection to work effectively in the presence of highly correlated features. It was proposed in this paper: ###&quot;faletto2022&quot;### #&#39; Faletto, G., &amp; Bien, J. (2022). Cluster Stability Selection. #&#39; \\emph{arXiv preprint arXiv:2201.00494}. #&#39; \\url{https://arxiv.org/abs/2201.00494}. This bookdown uses literate programming to define the cssr R package, which implements the procedures described in the paper. For a light introduction demonstrating how to use cssr, please see the package’s website here. "],["overview.html", "2 Overview 2.1 Background 2.2 Outline 2.3 Package setup", " 2 Overview 2.1 Background 2.1.1 Complementary pairs stability selection The following paper introduces complementary pairs subsampling: ###&quot;shah2013&quot;### #&#39; Shah, R. D., &amp; Samworth, R. J. #&#39; (2013). Variable selection with error control: Another look at stability #&#39; selection. \\emph{Journal of the Royal Statistical Society. Series B: #&#39; Statistical Methodology}, 75(1), 55–80. #&#39; \\url{https://doi.org/10.1109/RITA.2014.2302071}. Subsamples \\(A_1, \\ldots, A_B \\subset [n]\\) of size \\(\\lfloor n/2 \\rfloor\\) are drawn, as well as subsamples \\(\\overline{A}_b \\subset [n]\\) of the same size with \\(A_b \\cap \\overline{A}_b = \\emptyset\\). Our function getSubsamps() implements this subsampling. Writing \\(\\hat{S}^\\lambda(A)\\) for the selected features from applying a variable selection procedure with tuning parameter \\(\\lambda\\) on the data in a subset \\(A\\subset[n]\\), Shah and Samworth suggest computing the following: \\[ \\hat{\\Pi}_B^{\\text{(SS)}}(j) = \\frac{1}{2B} \\sum_{b=1}^B \\left[1\\left\\{j \\in \\hat{S}^\\lambda \\left( A_b \\right)\\right\\} + 1\\left\\{j \\in \\hat{S}^\\lambda (\\overline{A}_b)\\right\\} \\right]. \\] 2.1.2 Cluster stability selection We compute the proportion of the time that a feature \\(j \\in [p]\\) is selected for at least one \\(\\lambda \\in \\Lambda\\): \\[ \\hat{\\Pi}_B(j) := \\frac{1}{2B} \\sum_{b=1}^B \\left[ 1\\left\\{ j \\in \\bigcup_{\\lambda \\in \\Lambda} \\hat{S}^\\lambda \\left( A_b \\right) \\right\\} + 1\\left\\{ j \\in \\bigcup_{\\lambda \\in \\Lambda} \\hat{S}^\\lambda (\\overline{A}_b)\\right\\} \\right]. \\] We also compute a similar quantity at the level of clusters: For every cluster \\(C_k\\), we calculate the proportion of the time that at least one feature from \\(C_k\\) is selected for at least one \\(\\lambda \\in \\Lambda\\): \\[ \\hat{\\Theta}_B(C_k) := \\frac{1}{2B} \\sum_{b=1}^B \\left[ 1 \\left\\{ C_k \\cap \\bigcup_{\\lambda \\in \\Lambda} \\hat{S}^{\\lambda}\\left(A_b \\right) \\neq \\emptyset \\right\\} + 1 \\left\\{ C_k \\cap \\bigcup_{\\lambda \\in \\Lambda} \\hat{S}^{\\lambda}\\left(\\overline{A}_b \\right) \\neq \\emptyset \\right\\} \\right]. \\] We then calculate cluster representatives \\(\\boldsymbol{X}_{\\cdot C_k}^{\\text{rep}}\\) as weighted averages of the cluster members: \\[ \\boldsymbol{X}_{\\cdot C_k}^{\\text{rep}}:= \\sum_{j \\in C_k } w_{kj} \\boldsymbol{X}_{\\cdot j}. \\] We allow for several choices of weights: Weighted averaged cluster stability selection: \\[ w_{kj} = \\frac{\\hat{\\Pi}_B(j)}{\\sum_{j&#39; \\in C_k} \\hat{\\Pi}_B(j&#39;)} \\qquad \\forall j \\in C_k . \\] Simple averaged cluster stability selection: \\[ w_{kj} = \\frac{1}{\\left| C_k \\right|} \\qquad \\forall j \\in C_k . \\] Sparse cluster stability selection: For each \\(j \\in C_k\\), \\[ w_{kj} = \\left. 1 \\left\\{ j \\in \\underset{j&#39; \\in C_k}{\\arg \\max} \\left\\{ \\hat{\\Pi}_B(j&#39;) \\right\\} \\right\\} \\middle/ \\left| \\underset{j&#39; \\in C_k}{\\arg \\max} \\left\\{ \\hat{\\Pi}_B(j&#39;) \\right\\} \\right| \\right. . \\] 2.2 Outline We will define the functions in this package in steps. First we define the workhorse function of the package, css(). This function takes as inputs a data set (\\(X\\), \\(y\\)), a feature selection method \\(\\hat S^\\lambda(\\cdot)\\), and clusters of features appearing in the data: \\(C_1,\\ldots,C_K\\). It calculates random subsamples of the data (\\(A_1,\\ldots, A_B\\) and \\(\\bar A_1,\\ldots, \\bar A_B\\)) and gets selected sets of features on each subsample (i.e., \\(\\hat S^\\lambda(A_b)\\) and \\(\\hat S^\\lambda(\\bar A_b)\\)). It returns a \\(2B\\times p\\) matrix of indicator variables for whether each feature was selected on each subsample (one row for each subsample, one column for each feature). It returns a similar \\(2B\\times K\\) matrix of indicator variables for whether any feature from each cluster was selected on each subsample. This is the most computationally intensive step of cluster stability selection, so it is isolated within its own function that is designed to be run only once on a data set. Next we define functions that take these indicator matrices and return useful output–for example, selected sets of features, or predictions on test data. These outputs depend on the selected features, which themselves depend on user-selected parameters (for example, the cutoff for selection proportions for selected clusters). Next, we define wrapper functions that compute all of the above in one step in a user-friendly way. (These functions are not recommended for large data sets or for “power users” who may want to call these functions multiple times on the same data set, because these wrapper functions make a new call to css() every time they are called, which is slow and computationally wasteful if the inputs to css() are not changed.) Finally, we define some other useful functions, like functions that generate clustered data to use for simulations or testing, or select a tuning parameter for the lasso via cross-validation. 2.3 Package setup Before proceeding to the actual functionality of the package, we start by specifying the information needed in the DESCRIPTION file of the R package. usethis::create_package( path = &quot;.&quot;, fields = list( Package = params$package_name, Version = &quot;0.1.8&quot;, Title = &quot;Cluster Stability Selection&quot;, Description = &quot;Implementation of Cluster Stability Selection (Faletto and Bien 2022).&quot;, `Authors@R` = c(person( given = &quot;Gregory&quot;, family = &quot;Faletto&quot;, email = &quot;gregory.faletto@marshall.usc.edu&quot;, role = c(&quot;aut&quot;, &quot;cre&quot;) ), person( given = &quot;Jacob&quot;, family = &quot;Bien&quot;, email = &quot;jbien@usc.edu&quot;, role = c(&quot;aut&quot;) )) ) ) usethis::use_mit_license(copyright_holder = &quot;F. Last&quot;) We also define the package-level documentation that shows up when someone types package?cssr in the console: #&#39; Cluster Stability Selection #&#39; #&#39; Cluster stability selection is a feature selection method designed to allow #&#39; stability selection to work effectively in the presence of highly correlated #&#39; features. It was proposed in &lt;https://arxiv.org/abs/2201.00494&gt;. To learn #&#39; more about this package, please visit its website #&#39; &lt;https://gregfaletto.github.io/cssr-project/&gt;. #&#39; #&#39; @docType package #&#39; @seealso \\code{\\link{css}} \\code{\\link{cssSelect}} "],["css.html", "3 The core function: css 3.1 Main components of css 3.2 Helper functions", " 3 The core function: css The main inputs that css() accepts are the following: a design matrix X a response y a selection method fitfun with specified tuning parameter lambda. This specifies \\(\\hat{S}^\\lambda(A)\\). In particular: ###&quot;param-fitfun&quot;### #&#39; @param fitfun A function; the feature selection function used on each #&#39; subsample by cluster stability selection. This can be any feature selection #&#39; method; the only requirement is that it accepts the arguments (and only the #&#39; arguments) `X`, `y`, and `lambda` and returns an integer vector that is a #&#39; subset of `1:p`. For example, `fitfun` could be best subset selection or #&#39; forward stepwise selection or LARS and `lambda` could be the desired model #&#39; size; or `fitfun` could be the elastic net and `lambda` could be a length-two #&#39; vector specifying lambda and alpha. Default is `cssLasso`, an implementation #&#39; of lasso (relying on the R package `glmnet`), where `lambda` must be a #&#39; positive numeric specifying the L1 penalty for the `lasso`. and ###&quot;param-lambda&quot;### #&#39; @param lambda A tuning parameter or set of tuning parameters that may be used #&#39; by the feature selection method `fitfun`. In the default case when #&#39; `fitfun = cssLasso`, lambda should be a numeric: the penalty to use for each #&#39; lasso fit. (`css()` does not require lambda to be any particular object because #&#39; for a user-specified feature selection method `fitfun`, lambda can be an #&#39; arbitrary object. See the description of `fitfun` below.) a specification of which features belong together in highly correlated clusters. This specifies the clusters \\(C_1,\\ldots, C_K\\). In particular: ###&quot;param-clusters&quot;### #&#39; @param clusters A list of integer vectors; each vector should contain the #&#39; indices of a cluster of features (a subset of `1:p`). (If there is only one #&#39; cluster, clusters can either be a list of length 1 or an integer vector.) #&#39; All of the provided clusters must be non-overlapping. Every feature not #&#39; appearing in any cluster will be assumed to be unclustered (that is, they #&#39; will be treated as if they are in a &quot;cluster&quot; containing only themselves). If #&#39; clusters is a list of length 0 (or a list only containing clusters of length #&#39; 1), then `css()` returns the same results as stability selection (so the #&#39; returned `feat_sel_mat` will be identical to `clus_sel_mat`). Names for the #&#39; clusters will be needed later; any clusters that are not given names in the #&#39; provided list will be given names automatically by `css()`. #&#39; CAUTION: if #&#39; the provided X is a data.frame that contains a categorical feature with more #&#39; than two levels, then the resulting matrix made from model.matrix will have a #&#39; different number of columns than the provided data.frame, some of the feature #&#39; numbers will change, and the clusters argument will not work properly (in the #&#39; current version of the package). To get correct results in this case, please #&#39; use model.matrix to convert the data.frame to a numeric matrix on your own, #&#39; then provide this matrix and cluster assignments with respect to this matrix. #&#39; Default is `list()` (so no clusters are specified). and a specification of the type of subsamples. For now we only consider the complementary subsets sampling of Shah and Samworth. However, we have included an option for Meinshausen-Buhlmann sampling which we may add later: ###&quot;param-sampling_type&quot;### #&#39; @param sampling_type A character vector; either &quot;SS&quot; or &quot;MB&quot;. For &quot;MB&quot;, #&#39; all B subsamples are drawn randomly (as proposed by Meinshausen and Bühlmann #&#39; 2010). For &quot;SS&quot;, in addition to these B subsamples, the B complementary pair #&#39; subsamples will be drawn as well (see Faletto and Bien 2022 or Shah and #&#39; Samworth 2013 for details). Default is &quot;SS&quot;, and &quot;MB&quot; is not supported yet. The number of subsamples is also up to the user: ###&quot;param-B&quot;### #&#39; @param B Integer or numeric; the number of subsamples. Note: For #&#39; `sampling_type==&quot;MB&quot;` the total number of subsamples will be `B`; for #&#39; `sampling_type=&quot;SS&quot;` the number of subsamples will be `2*B`. Default is 100 #&#39; for `sampling_type=&quot;MB&quot;` and 50 for `sampling_type=&quot;SS&quot;`. In this section, we will build the function css() step-by-step. First, css() creates random subsamples of the data: \\(A_1,\\ldots, A_B\\) (and \\(\\bar A_1,\\ldots, \\bar A_B\\) for Shah-Samworth subsampling). This is implemented in the function createSubsamples(). Next, css() executes the specified feature selection method \\(\\hat S^\\lambda(\\cdot)\\) on each subsample. This generates a binary matrix, feat_sel_mat, with one row for each subsample and one column for each feature in X. In each row, the entry corresponding to each feature equals 1 if the feature was selected on that subsample and 0 otherwise. feat_sel_mat is one of the outputs of css(); it is used to calculate the selection proportions for individual features. This is implemented in the function getSelMatrix(). So far this is the same as the original stability selection procedure. Now we take into account the clusters. The function getClusterSelMatrix() takes in the formatted clusters as well as feat_sel_mat and generates the binary matrix clus_sel_mat, which contains selection indicators for each cluster. clus_sel_mat has the same number of rows as feat_sel_mat and one column for each cluster rather than one for each feature. This is used to calculate the cluster selection proportions. The function css() is specified below. (There are some extra details that I omitted in the above description for brevity; you can read the full details below.) #&#39; Cluster Stability Selection #&#39; #&#39; Executes cluster stability selection algorithm. Takes subsamples of data, #&#39; executes feature selection algorithm on each subsample, and returns matrices #&#39; of feature selection indicators as well as cluster selection indicators. #&#39; #&#39; @param X An n x p numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; p &gt;= 2 features/predictors. #&#39; @param y The response; can be anything that takes the form of an #&#39; n-dimensional vector, with the ith entry corresponding to the ith row of X. #&#39; Typically (and for default `fitfun = cssLasso`), `y` should be an n-dimensional #&#39; numeric vector. &lt;&lt;param-lambda&gt;&gt; &lt;&lt;param-clusters&gt;&gt; &lt;&lt;param-fitfun&gt;&gt; &lt;&lt;param-sampling_type&gt;&gt; &lt;&lt;param-B&gt;&gt; #&#39; @param prop_feats_remove Numeric; if `prop_feats_remove` is greater than 0, #&#39; then on each subsample, each feature is randomly dropped from the design #&#39; matrix that is provided to `fitfun` with probability `prop_feats_remove` #&#39; (independently across features). That is, in a typical subsample, #&#39; `prop_feats_remove*p` features will be dropped (though this number will vary). #&#39; This is similar in spirit (but distinct from) extended stability selection #&#39; (Beinrucker et. al. 2016); see their paper for some of the benefits of #&#39; dropping features (besides increasing computational speed and decreasing #&#39; memory requirements). For `sampling_type=&quot;SS&quot;`, the features dropped in #&#39; each complementary pair of subsamples are identical in order to ensure that #&#39; the theoretical guarantees of Faletto and Bien (2022) are retained within #&#39; each individual pair of subsamples. (Note that this feature is not #&#39; investigated either theoretically or in simulations by Faletto and Bien #&#39; 2022). Must be between 0 and 1. Default is 0. #&#39; @param train_inds Optional; an integer or numeric vector containing the #&#39; indices of observations in `X` and `y` to set aside for model training by the #&#39; function `getCssPreds()` after feature selection. (This will only work if `y` is #&#39; real-valued, because `getCssPreds()` using ordinary least squares regression to #&#39; generate predictions.) If `train_inds` is not provided, all of the observations #&#39; in the provided data set will be used for feature selection. #&#39; @param num_cores Optional; an integer. If using parallel processing, the #&#39; number of cores to use for parallel processing (`num_cores` will be supplied #&#39; internally as the `mc.cores` argument of `parallel::mclapply()`). #&#39; @return A list containing the following items: #&#39; \\item{`feat_sel_mat`}{A `B` (or `2*B` for `sampling_type=&quot;SS&quot;`) x `p` numeric (binary) matrix. `feat_sel_mat[i, j] = 1` if feature `j` was selected by the base feature selection method on subsample `i`, and 0 otherwise.} #&#39; \\item{`clus_sel_mat`}{A `B` (or `2*B` for SS sampling) x `length(clusters)` numeric (binary) matrix. `clus_sel_mat[i, j] = 1` if at least one feature from cluster j was selected by the base feature selection method on subsample `i`, and 0 otherwise.} #&#39; \\item{`X`}{The `X` matrix provided to `css()`, coerced from a data.frame to a #&#39; matrix if needed.} #&#39; \\item{`y`}{The `y` vector provided to `css()`.} #&#39; \\item{`clusters`}{A named list of integer vectors containing all of the clusters provided to `css()`, as well as size 1 clusters of any features not listed in any #&#39; of the clusters provided to `css()`. All clusters will have names; any #&#39; clusters not provided with a name in the input to `css()` will be given names #&#39; automatically by `css()` (of the form c1, etc.).} #&#39; \\item{`train_inds`}{Identical to the `train_inds` provided to `css()`.} #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references &lt;&lt;faletto2022&gt;&gt; #&#39; &lt;&lt;shah2013&gt;&gt; #&#39; #&#39; Meinshausen, N., &amp; Bühlmann, P. (2010). Stability Selection. \\emph{Journal of the Royal #&#39; Statistical Society. Series B: Statistical Methodology}, 72(4), 417–473. #&#39; \\url{https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-9868.2010.00740.x}. #&#39; #&#39; Beinrucker, A., Dogan, Ü., &amp; #&#39; Blanchard, G. (2016). Extensions of stability selection using subsamples of #&#39; observations and covariates. \\emph{Statistics and Computing}, 26(5), 1059- #&#39; 1077. \\url{https://doi.org/10.1007/s11222-015-9589-y}. #&#39; #&#39; Jerome Friedman, Trevor Hastie, Robert Tibshirani (2010). Regularization Paths for Generalized #&#39; Linear Models via Coordinate Descent. \\emph{Journal of Statistical Software}, #&#39; 33(1), 1-22. URL \\url{https://www.jstatsoft.org/v33/i01/}. #&#39; @export css &lt;- function(X, y, lambda, clusters = list(), fitfun = cssLasso, sampling_type = &quot;SS&quot;, B = ifelse(sampling_type == &quot;MB&quot;, 100L, 50L), prop_feats_remove = 0, train_inds = integer(), num_cores = 1L ){ # Check inputs check_list &lt;- checkCssInputs(X, y, lambda, clusters, fitfun, sampling_type, B, prop_feats_remove, train_inds, num_cores) feat_names &lt;- check_list$feat_names X &lt;- check_list$X clusters &lt;- check_list$clusters rm(check_list) n &lt;- nrow(X) p &lt;- ncol(X) train_inds &lt;- as.integer(train_inds) ### Create subsamples sel_inds &lt;- setdiff(1:n, train_inds) n_sel &lt;- length(sel_inds) if(n_sel &lt; 4){ stop(&quot;Too many training indices provided (must be at least 4 observations left for feature selection, and ideally many more)&quot;) } subsamps_object &lt;- createSubsamples(n_sel, p, B, sampling_type, prop_feats_remove) ### Get matrix of selected feature sets from subsamples stopifnot(!is.matrix(y)) feat_sel_mat &lt;- getSelMatrix(X[sel_inds, ], y[sel_inds], lambda, B, sampling_type, subsamps_object, num_cores, fitfun) if(any(!is.na(feat_names))){ colnames(feat_sel_mat) &lt;- feat_names colnames(X) &lt;- feat_names } ### Get selection proportions for clusters corresponding to each feature clus_sel_mat &lt;- getClusterSelMatrix(clusters, feat_sel_mat) # Check outputs stopifnot(!is.null(colnames(clus_sel_mat))) stopifnot(all(colnames(clus_sel_mat) == names(clusters))) ret &lt;- list(feat_sel_mat = feat_sel_mat, clus_sel_mat = clus_sel_mat, X = X, y = y, clusters = clusters, train_inds = train_inds ) class(ret) &lt;- &quot;cssr&quot; return(ret) } Tests for css() and the other functions in this section are located at the end of this document. Next, we’ll build the individual functions one at a time. (The one function above that I didn’t mention at all is checkCssInputs(), which confirms that the inputs to css() are as expected and does some basic formatting on the inputs. To streamline presentation, this and other helper functions are specified later.) 3.1 Main components of css 3.1.1 Generating subsamples The function createSubsamples() is responsible for generating the subsamples \\(A_b\\), where \\(b\\) ranges from 1 to \\(B\\) or 1 to \\(2B\\) depending on the type of subsampling: #&#39; Creates lists of subsamples for stability selection. #&#39; #&#39; @param n Integer or numeric; sample size of the data set. #&#39; @param p Integer or numeric; number of features. &lt;&lt;param-B&gt;&gt; &lt;&lt;param-sampling_type&gt;&gt; #&#39; @param num_feats_remove Integer; number of features select automatically on #&#39; every iteration. Determined earlier from input prop_feats_remove to css. #&#39; @return A list of length `B` (or `2*B` for `sampling_type = &quot;SS&quot;`). If #&#39; `prop_feats_remove = 0`, each list element is an integer vector of length #&#39; `floor(n/2)` containing the indices of a subsample of `1:n`. (For #&#39; `sampling_type==&quot;SS&quot;`, the last `B` subsamples will be complementary pairs of #&#39; the first `B` subsamples; see Faletto and Bien 2022 or Shah and Samworth 2013 #&#39; for details.) If `prop_feats_remove &gt; 0`, each element is a named list with #&#39; members &quot;subsample&quot; (same as above) and &quot;feats_to_keep&quot;, a logical vector #&#39; of length `p`; `feats_to_keep[j] = TRUE` if feature `j` is chosen for this #&#39; subsample, and false otherwise. #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references &lt;&lt;faletto2022&gt;&gt; #&#39; &lt;&lt;shah2013&gt;&gt; createSubsamples &lt;- function(n, p, B, sampling_type, prop_feats_remove=0){ # Check inputs stopifnot(length(n) == 1) stopifnot(is.numeric(n) | is.integer(n)) stopifnot(n == round(n)) stopifnot(n &gt; 0) stopifnot(length(p) == 1) stopifnot(is.numeric(p) | is.integer(p)) stopifnot(p == round(p)) stopifnot(p &gt; 0) checkSamplingType(sampling_type) checkPropFeatsRemove(prop_feats_remove, p) if(prop_feats_remove == 0){ subsamples &lt;- getSubsamps(n, B, sampling_type) return(subsamples) } else{ # In this case, we generate subsamples as well as logical vectors # of features to keep subsamps_and_feats &lt;- list() subsamples &lt;- getSubsamps(n, B, sampling_type) for(i in 1:B){ # Logical p-vector, where each entry is TRUE with probability # 1 - prop_feats_remove feats_to_keep_i &lt;- as.logical(stats::rbinom(n=p, size=1, prob=1 - prop_feats_remove)) # Make sure at least two entries are equal to TRUE (so that at # least two features are present for every subsample)--if not, # randomly choose features to add while(sum(feats_to_keep_i) &lt; 2){ false_inds &lt;- which(!feats_to_keep_i) sel_feat &lt;- sample(false_inds, size=1) feats_to_keep_i[sel_feat] &lt;- TRUE } subsamps_and_feats[[i]] &lt;- list(subsample=subsamples[[i]], feats_to_keep=feats_to_keep_i) } if(sampling_type==&quot;SS&quot;){ stopifnot(length(subsamples) == 2*B) for(i in 1:B){ # Keep the same features as in the other subsample (this # ensures that the theoretical guarantee of Shah and Samworth # 2013 remains valid on every individual pair of subsamples) subsamps_and_feats[[B + i]] &lt;- list(subsample=subsamples[[B + i]], feats_to_keep=subsamps_and_feats[[i]]$feats_to_keep) } } # Check output stopifnot(all(names(subsamps_and_feats) == c(&quot;subsample&quot;, &quot;feats_to_keep&quot;))) return(subsamps_and_feats) } # Shouldn&#39;t be possible to reach this part of function stop(&quot;createSubsamples failed to return anything&quot;) } Notice that createSubsamples() calls some helper functions to check the inputs (again, these are specified later in the helper functions section). createSubsamples() also calls the workhorse function getSubsamps() to generate a list of subsamples. #&#39; Generate list of subsamples #&#39; #` Generate list of `B` (or `2*B` for sampling_type=&quot;SS&quot;) subsamples of size #` `n/2` #&#39; @param n Integer or numeric; sample size of the data set. &lt;&lt;param-B&gt;&gt; &lt;&lt;param-sampling_type&gt;&gt; #&#39; @return A list of length `B` (or `2*B` for `sampling_type=&quot;SS&quot;`), where each #&#39; element is an integer vector of length `floor(n/2)` containing the indices #&#39; of a subsample of `1:n`. For `sampling_type==&quot;SS&quot;`, the last `B` subsamples #&#39; will be complementary pairs of the first `B` subsamples (see Faletto and #&#39; Bien 2022 or Shah and Samworth 2013 for details). #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references #&#39; &lt;&lt;faletto2022&gt;&gt; #&#39; &lt;&lt;shah2013&gt;&gt; getSubsamps &lt;- function(n, B, sampling_type){ subsamples &lt;- list() for(i in 1:B){ subsamples[[i]] &lt;- sort(sample.int(n=n, size=floor(n/2), replace=FALSE)) } stopifnot(length(subsamples) == B) # TODO(gregfaletto): add support for sampling_type=&quot;MB&quot; if(sampling_type==&quot;SS&quot;){ for(i in 1:B){ # For the ith entry, take a subsample of size floor(n/2) from the # remaining n - floor(n/2) observations. (Only necessary to actually # take the subsample if n is odd; if not, the set we want is # setdiff(1:n, subsamples[[i]]), so skip the sample function.) if(n/2 == floor(n/2)){ subsamples[[B + i]] &lt;- sort(setdiff(1:n, subsamples[[i]])) } else{ subsamples[[B + i]] &lt;- sort(sample(x=setdiff(1:n, subsamples[[i]]), size=floor(n/2), replace=FALSE)) } # Check output stopifnot(is.integer(subsamples[[B + i]])) stopifnot(all(subsamples[[B + i]] == round(subsamples[[B + i]]))) stopifnot(floor(n/2) == length(subsamples[[B + i]])) stopifnot(length(subsamples[[B + i]]) == length(unique(subsamples[[B + i]]))) } stopifnot(length(subsamples) == 2*B) } return(subsamples) } 3.1.2 Forming selection matrices The next function called in the body of css() is getSelMatrix(), which records for each feature \\(j\\) and subsample \\(b\\) whether \\(j\\in \\hat S^\\lambda(A_b)\\): #&#39; Generates matrix of selection indicators from stability selection. #&#39; #&#39; @param x an n x p numeric matrix or a data.frame containing the predictors. #&#39; @param y A response vector; can be any response that takes the form of a #&#39; length n vector and is used (or not used) by fitfun. Typically (and for #&#39; default fitfun = cssLasso), y should be an n-dimensional numeric vector #&#39; containing the response. &lt;&lt;param-lambda&gt;&gt; &lt;&lt;param-B&gt;&gt; &lt;&lt;param-sampling_type&gt;&gt; #&#39; @param subsamps_object A list of length `B` (or `2*B` if `sampling_type=&quot;SS&quot;`), #&#39; where each element is one of the following: \\item{subsample}{An integer #&#39; vector of size `n/2` containing the indices of the observations in the #&#39; subsample.} \\item{drop_var_input}{A named list containing two elements: one #&#39; named &quot;subsample&quot;, matching the previous description, and a logical vector #&#39; named &quot;feats_to_keep&quot; containing the indices of the features to be #&#39; automatically selected.} (The first object is the output of the function #&#39; createSubsamples when the provided prop_feats_remove is 0, the default, and #&#39; the second object is the output of createSubsamples when prop_feats_remove &gt; #&#39; 0.) #&#39; @param num_cores Optional; an integer. If using parallel processing, the #&#39; number of cores to use for parallel processing (num_cores will be supplied #&#39; internally as the mc.cores argument of parallel::mclapply). &lt;&lt;param-fitfun&gt;&gt; #&#39; @return A binary integer matrix of dimension `B` x `p` (if sampling_type == #&#39; &quot;MB&quot;) or `2*B` x `p` (if sampling_type == &quot;SS&quot;). res[i, j] = 1 if feature j #&#39; was selected on subsample i and equals 0 otherwise. (That is, each row is a #&#39; selected set.) #&#39; @author Gregory Faletto, Jacob Bien getSelMatrix &lt;- function(x, y, lambda, B, sampling_type, subsamps_object, num_cores, fitfun=cssLasso){ # Check inputs stopifnot(is.matrix(x)) stopifnot(all(!is.na(x))) n &lt;- nrow(x) p &lt;- ncol(x) stopifnot(length(y) == n) stopifnot(!is.matrix(y)) # Intentionally don&#39;t check y or lambda further to allow for flexibility--these # inputs should be checked within fitfun. checkSamplingType(sampling_type) # Get list of selected feature sets from subsamples res_list &lt;- parallel::mclapply(X=subsamps_object, FUN=cssLoop, x=x, y=y, lambda=lambda, fitfun=fitfun, mc.cores=num_cores) # Store selected sets in B x p (or `2*B` x p for &quot;SS&quot;) binary matrix if(sampling_type==&quot;SS&quot;){ res &lt;- matrix(0L, 2*B, p) } else if(sampling_type==&quot;MB&quot;){ res &lt;- matrix(0L, B, p) } else{ stop(&quot;!(sampling_type %in% c(SS, MB)) (don&#39;t know how to set dimensions of res&quot;) } stopifnot(length(res_list) == nrow(res)) # Get selected sets into matrix res for(i in 1:nrow(res)){ if(length(res_list[[i]]) == 0){ # If no features are selected, don&#39;t fill in anything in this row next } if(!is.integer(res_list[[i]])){ print(paste(&quot;failed on iteration&quot;, i)) print(res_list[[i]]) stop(&quot;Something seems to be wrong with the feature selection method (fitfun failed to return an integer vector)&quot;) } stopifnot(length(res_list[[i]]) &lt;= p &amp; length(res_list[[i]]) &gt; 0) stopifnot(all(!is.na(res_list[[i]]))) stopifnot(max(res_list[[i]]) &lt;= p) stopifnot(min(res_list[[i]]) &gt;= 1) stopifnot(length(res_list[[i]]) == length(unique(res_list[[i]]))) stopifnot(!(&quot;try-error&quot; %in% class(res_list[[i]]) | &quot;error&quot; %in% class(res_list[[i]]) | &quot;simpleError&quot; %in% class(res_list[[i]]) | &quot;condition&quot; %in% class(res_list[[i]]))) # Store selected variables in the ith row of res res[i, res_list[[i]]] &lt;- 1L } # Check output stopifnot(is.matrix(res)) if(sampling_type==&quot;SS&quot;){ stopifnot(nrow(res) == 2*B) } else{ stopifnot(nrow(res) == B) } stopifnot(ncol(res) == p) stopifnot(all(res %in% c(0, 1))) return(res) } Again, getSelMatrix() uses some helper functions to check the inputs for safety. getSelMatrix() leverages the function parallel::mclapply() package, in order to allow for parallel processing if the user has set this up. This requires a helper function cssLoop(), which is also specified in the later section for helper functions. We add the parallel package to the DESCRIPTION file: usethis::use_package(&quot;parallel&quot;) ## ✔ Adding &#39;parallel&#39; to Imports field in DESCRIPTION ## • Refer to functions with `parallel::fun()` getSelMatrix() also uses a feature selection function fitfun as an input. fitfun can be provided by the user as an input to css(). We provide one default fitfun, cssLasso(), which works on a real-valued response y given a specified penalty parameter lambda &gt; 0. Both for its own importance and to show an example of a valid fitfun, we show cssLasso() here. #&#39; Provided fitfun implementing the lasso #&#39; #&#39; Function used to select features with the lasso on each subsample in cluster #&#39; stability selection. Uses glmnet implementation of the lasso. #&#39; @param X A design matrix containing the predictors. (In practice this will #&#39; be a subsample of the full design matrix provided to `css()`.) #&#39; @param y A numeric vector containing the response. #&#39; @param lambda Numeric; a nonnegative number for the lasso penalty to use #&#39; on each subsample. (For now, only one lambda value can be provided to #&#39; `cssLasso()`; in the future, we plan to allow for multiple lambda values to be #&#39; provided to `cssLasso()`, as described in Faletto and Bien 2022.) #&#39; @return An integer vector; the indices of the features selected by the lasso. #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references #&#39; &lt;&lt;faletto2022&gt;&gt; #&#39; #&#39; Jerome Friedman, Trevor Hastie, #&#39; Robert Tibshirani (2010). Regularization Paths for Generalized Linear Models #&#39; via Coordinate Descent. \\emph{Journal of Statistical Software}, 33(1), 1-22. #&#39; URL \\url{https://www.jstatsoft.org/v33/i01/}. #&#39; @export cssLasso &lt;- function(X, y, lambda){ # Check inputs # TODO(gregfaletto) allow cssLasso to accept a vector of lambda values rather # than just a single one. checkCssLassoInputs(X, y, lambda) n &lt;- nrow(X) p &lt;- ncol(X) # Fit a lasso path (full path for speed, per glmnet documentation) lasso_model &lt;- glmnet::glmnet(X, y, family=&quot;gaussian&quot;) stopifnot(all.equal(class(lasso_model), c(&quot;elnet&quot;, &quot;glmnet&quot;))) # Get coefficients at desired lambda pred &lt;- glmnet::predict.glmnet(lasso_model, type=&quot;nonzero&quot;, s=lambda, exact=TRUE, newx=X, x=X, y=y) if(is.null(pred[[1]])){return(integer())} stopifnot(is.data.frame(pred)) stopifnot(!(&quot;try-error&quot; %in% class(pred) | &quot;error&quot; %in% class(pred) | &quot;simpleError&quot; %in% class(pred) | &quot;condition&quot; %in% class(pred))) if(length(dim(pred)) == 2){ selected_glmnet &lt;- pred[, 1] } else if(length(dim(pred)) == 3){ selected_glmnet &lt;- pred[, 1, 1] } else if(length(dim(pred)) == 1){ selected_glmnet &lt;- pred } else{ stop(&quot;length(dim(pred)) not 1, 2, or 3&quot;) } stopifnot(length(selected_glmnet) &gt;= 1) stopifnot(length(selected_glmnet) &lt;= ncol(X)) stopifnot(all(selected_glmnet == round(selected_glmnet))) stopifnot(length(selected_glmnet) == length(unique(selected_glmnet))) selected_glmnet &lt;- as.integer(selected_glmnet) selected &lt;- sort(selected_glmnet) return(selected) } Notice that cssLasso() depends on the package glmnet, and calls the function checkCssLassoInputs(), which verifies that the inputs to cssLasso() are as needed. (In particular, the function css() imposes very few requirements on lambda and y to allow the end user flexibility for any specified fitfun. checkCssLassoInputs() ensures that y is a real-valued response, lambda is a nonnegative real number, etc.) checkCssLassoInputs() is specified in the helper functions section later. We add glmnet to the DESCRIPTION file as well: usethis::use_package(&quot;glmnet&quot;) ## ✔ Adding &#39;glmnet&#39; to Imports field in DESCRIPTION ## • Refer to functions with `glmnet::fun()` Finally, getClusterSelMatrix() is the last significant function called within css(). It takes the information from getSelMatrix(), i.e. whether feature \\(j\\in\\hat S^\\lambda(A_b)\\), and outputs for every cluster \\(C\\) whether \\(C\\cap S^\\lambda(A_b)\\neq\\emptyset\\). #&#39; Get cluster selection matrix #&#39; #&#39; Given a matrix of feature selection indicator variables and a list of #&#39; clusters of features, returns a matrix of cluster indicator variables. #&#39; #&#39; @param clusters A named list where each entry is an integer vector of indices #&#39; of features that are in a common cluster, as in the output of formatClusters. #&#39; (The length of list clusters is equal to the number of clusters.) All #&#39; identified clusters must be non-overlapping, and all features must appear in #&#39; exactly one cluster (any unclustered features should be in their own #&#39; &quot;cluster&quot; of size 1). #&#39; @param res A binary integer matrix. es[i, j] = 1 if feature j was selected #&#39; on subsample i and equals 0 otherwise, as in the output of `getSelMatrix()`. #&#39; (That is, each row is a selected set.) #&#39; @return A binary integer matrix with the same number of rows #&#39; as res and length(clusters) columns. Entry i, j is 1 if at least #&#39; one member of cluster j was selected on subsample i, and 0 otherwise. #&#39; @author Gregory Faletto, Jacob Bien getClusterSelMatrix &lt;- function(clusters, res){ # Check input checkGetClusterSelMatrixInput(clusters, res) p &lt;- ncol(res) n_clusters &lt;- length(clusters) # Matrix of cluster selection proportions (with n_clusters columns) res_n_clusters &lt;- matrix(rep(0L, nrow(res)*n_clusters), nrow=nrow(res), ncol=n_clusters) colnames(res_n_clusters) &lt;- names(clusters) for(j in 1:n_clusters){ # Identify rows of res where at least one feature from this cluster # was selected rows_j_sel &lt;- apply(res, 1, function(x){any(x[clusters[[j]]] == 1)}) # Put ones in these rows of res_n_clusters[, j] res_n_clusters[rows_j_sel, j] &lt;- 1L if(length(clusters[[j]]) &lt;= 1){ next } } # Check output stopifnot(is.matrix(res_n_clusters)) stopifnot(identical(colnames(res_n_clusters), names(clusters))) stopifnot(all(res_n_clusters %in% c(0, 1))) stopifnot(ncol(res_n_clusters) == length(clusters)) return(res_n_clusters) } The helper function checkGetClusterSelMatrixInput() verifies the inputs to getClusterSelMatrix(). With the above and the helper functions below, the css() function is complete! 3.2 Helper functions Below, we specify some of the helper functions for css(), which are less important for understanding what css() does. The function checkCssInputs() is called at the beginning of the css() function. It confirms that the inputs to css() are as expected. Also, css() allows some flexibility in how the inputs are formatted, and checkCssInputs() converts the inputs into consistent formats for later use. The function checkCssClustersInput() is called within checkCssInputs(), and specifically checks the clusters input. formatClusters() modifies clusters, ensuring every feature appears in exactly one cluster (any unclustered features are put in a “cluster” by themselves). checkFormatClustersInput() verifies the input to formatClusters() for safety (this might seem a little redundant here, but formatClusters() is also called by different functions in this package). checkY() ensures (here and elsewhere) that the provided y is as expected. (In particular, in general the inputted y can be a vector of any type as long as the specified fitfun can handle y appropriately. For some function inputs, y must be a numeric vector. checkY() enforces this, among other things.) checkClusters() verifies that the output of formatClusters() is as expected. getPrototypes() identifies the prototypes of each cluster–the feature within each cluster that has the largest marginal sample correlation with y. identifyPrototype() is the workhorse of getPrototypes(), identifying the prototype given a single cluster. corFunction() is a helper function called within identifyPrototype() to calculate the absolute value of the correlation between two vectors. checkSamplingType() ensures that the input sampling_type is as expected. checkB() ensures that the input B is as expected. checkPropFeatsRemove() ensures that the input prop_feats_remove is as expected. The function cssLoop() is called within css(). In particular, it is a helper function needed in order to allow for parallel processing of the feature selection method on each of the subsamples. checkCssLoopOutput() verifies that the output of cssLoop() is as expected. This is particularly important because the user can specify their own feature selection method; checkCssLoopOutput() verifies that the output of the feature selection method is valid, and provides an informative error message if not. checkCssLassoInputs() checks that the inputs to the provided fitfun, cssLasso(), are as needed. checkGetClusterSelMatrixInput() verifies that the input to getClusterSelMatrix() is as expected. Tests are written for all of these functions and appear as early as possible after the function is defined. (For functions that don’t depend on any other functions, tests appear immediately after the function; for functions with dependencies, the tests appear after all dependencies have been defined.) checkCssInputs(): #&#39; Helper function to confirm that inputs to the function `css()` are as expected, #&#39; and modify inputs if needed #&#39; #&#39; @param X An n x p numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; p &gt;= 2 features/predictors. #&#39; @param y The response; can be anything that takes the form of an #&#39; n-dimensional vector, with the ith entry corresponding to the ith row of X. #&#39; Typically (and for default fitfun = cssLasso), y should be an n-dimensional #&#39; numeric vector. &lt;&lt;param-lambda&gt;&gt; &lt;&lt;param-clusters&gt;&gt; #&#39; @param fitfun A function; the feature selection function used on each #&#39; subsample by cluster stability selection. This can be any feature selection #&#39; method; the only requirement is that it accepts the arguments (and only the #&#39; arguments) X, y, and lambda and returns an integer vector that is a subset of #&#39; 1:p. For example, fitfun could be best subset selection or forward stepwise #&#39; selection or LARS and lambda could be the desired model size; or fitfun could be the #&#39; elastic net and lambda could be a length-two vector specifying lambda and #&#39; alpha. Default is cssLasso, an implementation of lasso (relying on the R #&#39; package glmnet), where lambda must be a positive numeric specifying the L1 #&#39; penalty for the lasso. #&#39; @param sampling_type A character vector; either &quot;SS&quot; or &quot;MB&quot;. For &quot;MB&quot;, #&#39; all B subsamples are drawn randomly (as proposed by Meinshausen and Bühlmann #&#39; 2010). For &quot;SS&quot;, in addition to these B subsamples, the B complementary pair #&#39; subsamples will be drawn as well (see Faletto and Bien 2022 or Shah and #&#39; Samworth 2013 for details). Default is &quot;SS&quot;, and &quot;MB&quot; is not supported yet. #&#39; @param B Integer or numeric; the number of subsamples. Note: For #&#39; sampling.type==&quot;MB&quot; the total number of subsamples will be `B`; for #&#39; sampling_type=&quot;SS&quot; the number of subsamples will be `2*B`. Default is 100 #&#39; for sampling_type=&quot;MB&quot; and 50 for sampling_type=&quot;SS&quot;. #&#39; @param prop_feats_remove Numeric; if prop_feats_remove is greater than 0, #&#39; then on each subsample, each feature is randomly dropped from the design #&#39; matrix that is provided to fitfun with probability prop_feats_remove #&#39; (independently across features). That is, in a typical subsample, #&#39; prop_feats_remove*p features will be dropped (though this number will vary). #&#39; This is similar in spirit (but distinct from) extended stability selection #&#39; (Beinrucker et. al. 2016); see their paper for some of the benefits of #&#39; dropping features (besides increasing computational speed and decreasing #&#39; memory requirements). For sampling_type=&quot;SS&quot;, the features dropped in #&#39; each complementary pair of subsamples are identical in order to ensure that #&#39; the theoretical guarantees of Faletto and Bien (2022) are retained within #&#39; each individual pair of subsamples. (Note that this feature is not #&#39; investigated either theoretically or in simulations by Faletto and Bien #&#39; 2022). Must be between 0 and 1. Default is 0. #&#39; @param train_inds Optional; an integer or numeric vector containing the #&#39; indices of observations in X and y to set aside for model training by the #&#39; function getCssPreds after feature selection. (This will only work if y is #&#39; real-valued, because getCssPreds using ordinary least squares regression to #&#39; generate predictions.) If train_inds is not provided, all of the observations #&#39; in the provided data set will be used for feature selection. #&#39; @param num_cores Optional; an integer. If using parallel processing, the #&#39; number of cores to use for parallel processing (num_cores will be supplied #&#39; internally as the mc.cores argument of parallel::mclapply). #&#39; @return A named list with the following elements: \\item{feat_names}{A #&#39; character vector containing the column names of X (if the provided X #&#39; had column names). If the provided X did not have column names, feat_names #&#39; will be NA.} \\item{X}{The provided X, converted to a matrix if it was #&#39; originally provided as a data.frame, and with feature names removed if they #&#39; had been provided.}\\item{clusters}{A list of integer vectors; each vector #&#39; will contain the indices of a cluster of features. Any duplicated clusters #&#39; provided in the input will be removed.} #&#39; @author Gregory Faletto, Jacob Bien checkCssInputs &lt;- function(X, y, lambda, clusters, fitfun, sampling_type, B, prop_feats_remove, train_inds, num_cores){ stopifnot(is.matrix(X) | is.data.frame(X)) clust_names &lt;- as.character(NA) if(!is.null(names(clusters)) &amp; is.list(clusters)){ clust_names &lt;- names(clusters) } # Check if x is a matrix; if it&#39;s a data.frame, convert to matrix. if(is.data.frame(X)){ p &lt;- ncol(X) X &lt;- stats::model.matrix(~ ., X) X &lt;- X[, colnames(X) != &quot;(Intercept)&quot;] if(length(clusters) &gt; 0 &amp; (p != ncol(X))){ stop(&quot;When stats::model.matrix converted the provided data.frame X to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert X to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;) } } stopifnot(is.matrix(X)) stopifnot(all(!is.na(X))) feat_names &lt;- as.character(NA) if(!is.null(colnames(X))){ feat_names &lt;- colnames(X) } n &lt;- nrow(X) p &lt;- ncol(X) if(!is.null(colnames(X))){ feat_names &lt;- colnames(X) } stopifnot(p &gt;= 2) if(length(feat_names) &gt; 1){ stopifnot(length(feat_names) == p) } else{ stopifnot(is.na(feat_names)) } colnames(X) &lt;- character() stopifnot(length(y) == n) # Intentionally don&#39;t check y or lambda further to allow for flexibility--these # inputs should be checked within fitfun. # Check clusters argument clusters &lt;- checkCssClustersInput(clusters) ### Format clusters into a list where all features are in exactly one # cluster (any unclustered features are put in their own &quot;cluster&quot; of size # 1). clusters &lt;- formatClusters(clusters, p=p, clust_names=clust_names)$clusters stopifnot(class(fitfun) == &quot;function&quot;) stopifnot(length(fitfun) == 1) if(!identical(formals(fitfun), formals(cssLasso))){ err_mess &lt;- paste(&quot;fitfun must accept arguments named X, y, and lambda. Detected arguments to fitfun:&quot;, paste(names(formals(fitfun)), collapse=&quot;, &quot;)) stop(err_mess) } checkSamplingType(sampling_type) checkB(B) checkPropFeatsRemove(prop_feats_remove, p) stopifnot(is.numeric(train_inds) | is.integer(train_inds)) if(length(train_inds) &gt; 0){ stopifnot(all(!is.na(train_inds))) stopifnot(all(round(train_inds) == train_inds)) stopifnot(length(train_inds) == length(unique(train_inds))) stopifnot(all(train_inds &gt;= 1)) stopifnot(all(train_inds) &lt;= n) stopifnot(length(train_inds) &lt;= n - 2) stopifnot(length(train_inds) &gt;= 1) } stopifnot(length(num_cores) == 1) stopifnot(is.integer(num_cores) | is.numeric(num_cores)) stopifnot(!is.na(num_cores)) stopifnot(num_cores == round(num_cores)) stopifnot(num_cores &gt;= 1) stopifnot(num_cores &lt;= parallel::detectCores()) return(list(feat_names=feat_names, X=X, clusters=clusters)) } checkCssClustersInput: #&#39; Helper function to confirm that clusters input to css is as expected #&#39; &lt;&lt;param-clusters&gt;&gt; #&#39; @return Same as the input, but all of the clusters will be coerced to #&#39; integers. #&#39; @author Gregory Faletto, Jacob Bien checkCssClustersInput &lt;- function(clusters){ stopifnot(!is.na(clusters)) if(is.list(clusters)){ stopifnot(all(!is.na(clusters))) stopifnot(length(clusters) == length(unique(clusters))) if(length(clusters) &gt; 0){ for(i in 1:length(clusters)){ stopifnot(length(clusters[[i]]) == length(unique(clusters[[i]]))) stopifnot(all(!is.na(clusters[[i]]))) stopifnot(is.integer(clusters[[i]]) | is.numeric(clusters[[i]])) stopifnot(all(clusters[[i]] == round(clusters[[i]]))) stopifnot(all(clusters[[i]] &gt;= 1)) clusters[[i]] &lt;- as.integer(clusters[[i]]) } if(length(clusters) &gt;= 2){ # Check that clusters are non-overlapping for(i in 1:(length(clusters) - 1)){ for(j in (i+1):length(clusters)){ if(length(intersect(clusters[[i]], clusters[[j]])) != 0){ error_mes &lt;- paste(&quot;Overlapping clusters detected; clusters must be non-overlapping. Overlapping clusters: &quot;, i, &quot;, &quot;, j, &quot;.&quot;, sep=&quot;&quot;) stop(error_mes) } } } } } } else{ # If clusters is not a list, it should be a vector of indices of # features that are in the (one) cluster stopifnot(is.numeric(clusters) | is.integer(clusters)) stopifnot(length(clusters) == length(unique(clusters))) stopifnot(all(!is.na(clusters))) stopifnot(is.integer(clusters) | is.numeric(clusters)) stopifnot(all(clusters == round(clusters))) stopifnot(all(clusters &gt;= 1)) clusters &lt;- as.integer(clusters) } return(clusters) } tests for checkCssClustersInput: testthat::test_that(&quot;checkCssClustersInput works&quot;, { # Intentionally don&#39;t provide clusters for all feature, mix up formatting, # etc. good_clusters &lt;- list(red_cluster=1L:4L, green_cluster=5L:8L) res &lt;- checkCssClustersInput(good_clusters) # clusters testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), length(names(res))) testthat::expect_equal(length(res), length(unique(names(res)))) testthat::expect_true(all(!is.na(names(res)))) testthat::expect_true(all(!is.null(names(res)))) clust_feats &lt;- integer() for(i in 1:length(res)){ clust_feats &lt;- c(clust_feats, res[[i]]) } testthat::expect_equal(length(clust_feats), length(unique(clust_feats))) testthat::expect_equal(length(clust_feats), length(intersect(clust_feats, 1:8))) ## Trying other inputs unnamed_clusters &lt;- list(1L:3L, 5L:8L) res &lt;- checkCssClustersInput(unnamed_clusters) # clusters testthat::expect_true(is.list(res)) clust_feats &lt;- integer() for(i in 1:length(res)){ clust_feats &lt;- c(clust_feats, res[[i]]) } testthat::expect_equal(length(clust_feats), length(unique(clust_feats))) testthat::expect_equal(length(clust_feats), length(intersect(clust_feats, 1:8))) testthat::expect_error(checkCssClustersInput(list(1:4, 4:6)), &quot;Overlapping clusters detected; clusters must be non-overlapping. Overlapping clusters: 1, 2.&quot;, fixed=TRUE) testthat::expect_error(checkCssClustersInput(list(2:3, 2:3)), &quot;length(clusters) == length(unique(clusters)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkCssClustersInput(list(2:3, as.integer(NA))), &quot;!is.na(clusters) are not all TRUE&quot;, fixed=TRUE) testthat::expect_error(checkCssClustersInput(list(2:3, c(4, 4, 5))), &quot;length(clusters[[i]]) == length(unique(clusters[[i]])) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkCssClustersInput(list(2:3, -1)), &quot;all(clusters[[i]] &gt;= 1) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkCssClustersInput(c(0.4, 0.6)), &quot;all(clusters == round(clusters)) is not TRUE&quot;, fixed=TRUE) # Single cluster res_sing_clust &lt;- checkCssClustersInput(2:5) testthat::expect_equal(length(res_sing_clust), 4) }) ## Test passed 🎉 formatClusters(): #&#39; Formats clusters in standardized way, optionally estimating cluster #&#39; prototypes #&#39; #&#39; @param clusters Either an integer vector of a list of integer vectors; each #&#39; vector should contain the indices of a cluster of features. (If there is only #&#39; one cluster, clusters can either be a list of length 1 or simply an integer #&#39; vector.) If clusters is specified then R is ignored. #&#39; @param p integer or numeric; the numbe of features in x (should match #&#39; ncol(x), if x is provided) #&#39; @param clust_names A character vector of the names of the clusters in #&#39; clusters. #&#39; @param get_prototypes Logical: if TRUE, will identify prototype from each #&#39; cluster (the feature from each cluster that is most correlated with the #&#39; response) for the protolasso. In this case, x and y must be provided. #&#39; @param x n x p numeric matrix; design matrix. Only needs to be provided if #&#39; get_prototypes is TRUE. #&#39; @param y Numeric response vector; only needs to be provided if get_prototypes #&#39; is TRUE. Note: in general, the css function does not require y to be a #&#39; numeric vector, because the provided fitfun could use a different form of y #&#39; (for example, a categorical response variable). However, y must be numeric in #&#39; order to provide prototypes because the prototypes are determined using the #&#39; correlation between cluster members (columns of x) and y. #&#39; @param R Numeric p x p matrix; not currently used. Entry ij contains the #&#39; &quot;substitutive value&quot; of feature i for feature j (diagonal must consist of #&#39; ones, all entries must be between 0 and 1, and matrix must be symmetric) #&#39; @return A named list with the following elements: \\item{clusters}{A named #&#39; list where each entry is an integer vector of indices of features that are in #&#39; a common cluster. (The length of list clusters is equal to the number of #&#39; clusters.) All identified clusters are non-overlapping. All features appear #&#39; in exactly one cluster (any unclustered features will be put in their own #&#39; &quot;cluster&quot; of size 1).} \\item{multiple}{Logical; TRUE if there is more than #&#39; one cluster of size greater than 1, FALSE otherwise.} \\item{prototypes}{only #&#39; returned if get_prototypes=TRUE. An integer vector whose length is equal to #&#39; the number of clusters. Entry i is the index of the feature belonging to #&#39; cluster i that is most highly correlated with y (that is, the prototype for #&#39; the cluster, as in the protolasso; see Reid and Tibshirani 2016).} #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references Reid, S., &amp; Tibshirani, R. (2016). Sparse regression and marginal #&#39; testing using cluster prototypes. \\emph{Biostatistics}, 17(2), 364–376. #&#39; \\url{https://doi.org/10.1093/biostatistics/kxv049}. formatClusters &lt;- function(clusters=NA, p=-1, clust_names=NA, get_prototypes=FALSE, x=NA, y=NA, R=NA){ # Check inputs clusters &lt;- checkFormatClustersInput(clusters, p, clust_names, get_prototypes, x, y, R) n &lt;- nrow(x) multiple &lt;- FALSE if(any(lengths(clusters) &gt; 1)){ # &amp; length(clusters) &gt; 1 # Only care about clusters with more than one element (only ones that # need to be treated differently) # keep track of whether there&#39;s more than one cluster or not multiple &lt;- sum(lengths(clusters) &gt; 1) &gt; 1 } # For any features not already in a cluster, add a cluster containing only # that feature orig_length_clusters &lt;- length(clusters) stopifnot(p &gt;= 1) for(i in 1:p){ feat_i_found &lt;- FALSE if(orig_length_clusters &gt; 0){ for(j in 1:orig_length_clusters){ # If i is in cluster j, break out of this loop and consider the # next i if(i %in% clusters[[j]]){ feat_i_found &lt;- TRUE break } } } # If feature i wasn&#39;t found in any cluster, add a cluster containing # just feature i if(!feat_i_found){ clusters[[length(clusters) + 1]] &lt;- i } } n_clusters &lt;- length(clusters) # Add names to clusters if(is.null(names(clusters))){ names(clusters) &lt;- paste(&quot;c&quot;, 1:n_clusters, sep=&quot;&quot;) } else{ # What clusters need names? unnamed_clusts &lt;- which(is.na(names(clusters)) | names(clusters) == &quot;&quot;) if(length(unnamed_clusts) &gt; 0){ proposed_clust_names &lt;- paste(&quot;c&quot;, unnamed_clusts, sep=&quot;&quot;) # Replace any proposed cluster names that are already in use if(any(proposed_clust_names %in% names(clusters))){ proposed_clust_names[proposed_clust_names %in% names(clusters)] &lt;- paste(&quot;c&quot;, unnamed_clusts[proposed_clust_names %in% names(clusters)] + p, sep=&quot;&quot;) } while_counter &lt;- 0 while(any(proposed_clust_names %in% names(clusters))){ proposed_clust_names[proposed_clust_names %in% names(clusters)] &lt;- paste(proposed_clust_names[proposed_clust_names %in% names(clusters)], &quot;_1&quot;, sep=&quot;&quot;) while_counter &lt;- while_counter + 1 if(while_counter &gt;= 100){ stop(&quot;Function formatClusters stuck in an infinite while loop&quot;) } } stopifnot(length(unnamed_clusts) == length(proposed_clust_names)) names(clusters)[unnamed_clusts] &lt;- proposed_clust_names } } # Check output checkClusters(clusters, p) stopifnot(is.logical(multiple)) stopifnot(length(multiple) == 1) stopifnot(!is.na(multiple)) if(get_prototypes){ prototypes &lt;- getPrototypes(clusters, x, y) return(list(clusters=clusters, multiple=multiple, prototypes=prototypes)) } else{ return(list(clusters=clusters, multiple=multiple)) } } checkFormatClustersInput(): #&#39; Helper function to ensure that the inputs to formatClusters are as expected #&#39; #&#39; @param clusters Either an integer vector of a list of integer vectors; each #&#39; vector should contain the indices of a cluster of features. (If there is only #&#39; one cluster, clusters can either be a list of length 1 or simply an integer #&#39; vector.) If clusters is specified then R is ignored. #&#39; @param p integer or numeric; the numbe of features in x (should match #&#39; ncol(x), if x is provided) #&#39; @param clust_names A character vector of the names of the clusters in clusters. #&#39; @param get_prototypes Logical: if TRUE, will identify prototype from each #&#39; cluster (the feature from each cluster that is most correlated with the #&#39; response) for the protolasso. In this case, x and y must be provided. #&#39; @param x n x p numeric matrix; design matrix. Only needs to be provided if #&#39; get_prototypes is TRUE. #&#39; @param y Numeric response vector; only needs to be provided if get_prototypes #&#39; is TRUE. Note: in general, the css function does not require y to be a #&#39; numeric vector, because the provided fitfun could use a different form of y #&#39; (for example, a categorical response variable). However, y must be numeric in #&#39; order to provide prototypes because the prototypes are determined using the #&#39; correlation between cluster members (columns of x) and y. #&#39; @param R Numeric p x p matrix; not currently used. Entry ij contains the #&#39; &quot;substitutive value&quot; of feature i for feature j (diagonal must consist of #&#39; ones, all entries must be between 0 and 1, and matrix must be symmetric) #&#39; @return A list of integer vectors; each vector will contain the indices of a #&#39; cluster of features. Any duplicated clusters provided in the input will be #&#39; removed. #&#39; @author Gregory Faletto, Jacob Bien checkFormatClustersInput &lt;- function(clusters, p, clust_names, get_prototypes, x, y, R){ if(any(is.na(clusters)) &amp; any(is.na(R))){ stop(&quot;Must specify one of clusters or R (or does one of these provided inputs contain NA?)&quot;) } stopifnot(is.integer(p) | is.numeric(p)) stopifnot(length(p) == 1) stopifnot(p == round(p)) stopifnot(!is.na(p)) if(p &gt; 0){ stopifnot(p &gt;= 2) } use_R &lt;- FALSE if(any(is.na(clusters)) | length(clusters) == 0){ if(all(!is.na(R))){ stopifnot(is.matrix(R)) stopifnot(all(dim(R) == p)) stopifnot(all(diag(R) == 1)) stopifnot(identical(R, t(R))) stopifnot(all(!is.na(R))) stopifnot(all(R %in% c(0, 1))) use_R &lt;- TRUE } } else{ stopifnot(!is.list(clusters) | all(lengths(clusters) &gt;= 1)) stopifnot(is.list(clusters) | length(clusters) &gt;= 1) stopifnot(all(!is.na(clusters))) if(is.list(clusters) &amp; length(clusters) &gt; 0){ for(i in 1:length(clusters)){ stopifnot(length(clusters[[i]]) == length(unique(clusters[[i]]))) stopifnot(all(!is.na(clusters[[i]]))) stopifnot(all(clusters[[i]] &gt;= 1)) stopifnot(is.integer(clusters[[i]])) } stopifnot(length(clusters) == length(unique(clusters))) clusters &lt;- clusters[!duplicated(clusters)] if(length(clusters) &gt;= 2){ # Check that clusters are non-overlapping for(i in 1:(length(clusters) - 1)){ for(j in (i+1):length(clusters)){ stopifnot(length(intersect(clusters[[i]], clusters[[j]])) == 0) } } } if(any(!is.na(clust_names))){ stopifnot(length(clust_names) == length(clusters)) } } else if(!is.list(clusters)){ clusters_temp &lt;- clusters clusters &lt;- list() clusters[[1]] &lt;- clusters_temp rm(clusters_temp) } } stopifnot(length(get_prototypes) == 1) stopifnot(is.logical(get_prototypes)) if(any(!is.na(clust_names))){ stopifnot(is.character(clust_names)) } if(get_prototypes){ stopifnot(all(!is.na(x))) stopifnot(is.matrix(x)) n &lt;- nrow(x) checkY(y, n) } if(use_R){ # Determine clusters from R clusters &lt;- list() for(i in 1:nrow(R)){ clusters[[i]] &lt;- as.integer(which(R[i, ] &gt; 0)) stopifnot(length(clusters[[i]]) == length(unique(clusters[[i]]))) stopifnot(all(!is.na(clusters[[i]]))) stopifnot(is.integer(clusters[[i]])) } clusters &lt;- unique(clusters) stopifnot(is.list(clusters)) if(length(clusters) &gt;= 2){ # Check that clusters are non-overlapping for(i in 1:(length(clusters) - 1)){ for(j in (i+1):length(clusters)){ if(length(intersect(clusters[[i]], clusters[[j]])) != 0){ stop(&quot;Invalid R matrix with overlapping clusters (clusters must not be overlapping)&quot;) } } } } } stopifnot(is.list(clusters)) return(clusters) } checkY(): #&#39; Helper function to confirm that the argument y to several functions is #&#39; as expected #&#39; #&#39; @param y Numeric response vector. #&#39; @param n Number of observations of covariates; should match length of y. #&#39; @author Gregory Faletto, Jacob Bien checkY &lt;- function(y, n){ stopifnot(all(!is.na(y))) stopifnot(is.numeric(y) | is.integer(y)) stopifnot(length(unique(y)) &gt; 1) stopifnot(length(n) == 1) stopifnot(!is.na(n)) stopifnot(is.numeric(n) | is.integer(n)) stopifnot(n == round(n)) stopifnot(n &gt; 0) stopifnot(n == length(y)) } Tests for checkY(): testthat::test_that(&quot;checkY works&quot;, { testthat::expect_null(checkY(as.numeric(1:20)*.1, 20)) testthat::expect_null(checkY(1L:15L, 15)) testthat::expect_error(checkY(1:7, 8), &quot;n == length(y) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkY(1:7, -7), &quot;n &gt; 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkY(rep(as.numeric(NA), 13), 13), &quot;all(!is.na(y)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkY(rep(5.2, 9), 9), &quot;length(unique(y)) &gt; 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkY(c(TRUE, FALSE, TRUE), 3), &quot;is.numeric(y) | is.integer(y) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 😀 Tests for checkFormatClustersInput(): testthat::test_that(&quot;checkFormatClustersInput works&quot;, { # Intentionally don&#39;t provide clusters for all feature, mix up formatting, # etc. good_clusters &lt;- list(red_cluster=1L:4L, green_cluster=5L:8L) res &lt;- checkFormatClustersInput(good_clusters, p=10, clust_names=c(&quot;red_cluster&quot;, &quot;green_cluster&quot;), get_prototypes=FALSE, x=NA, y=NA, R=NA) testthat::expect_true(is.list(res)) clust_feats &lt;- integer() for(i in 1:length(res)){ clust_feats &lt;- c(clust_feats, res[[i]]) } testthat::expect_equal(length(clust_feats), length(unique(clust_feats))) testthat::expect_equal(length(clust_feats), length(intersect(clust_feats, 1:8))) ## Trying other inputs unnamed_clusters &lt;- list(1L:3L, 5L:8L) res &lt;- checkFormatClustersInput(unnamed_clusters, p=10, clust_names=NA, get_prototypes=FALSE, x=NA, y=NA, R=NA) # clusters testthat::expect_true(is.list(res)) clust_feats &lt;- integer() for(i in 1:length(res)){ clust_feats &lt;- c(clust_feats, res[[i]]) } testthat::expect_equal(length(clust_feats), length(unique(clust_feats))) testthat::expect_equal(length(clust_feats), length(intersect(clust_feats, 1:8))) testthat::expect_error(checkFormatClustersInput(list(1:4, 4:6), p=10, clust_names=NA, get_prototypes=FALSE, x=NA, y=NA, R=NA), &quot;length(intersect(clusters[[i]], clusters[[j]])) == 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormatClustersInput(list(2:3, 2:3), p=10, clust_names=NA, get_prototypes=FALSE, x=NA, y=NA, R=NA), &quot;length(clusters) == length(unique(clusters)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormatClustersInput(list(2:3, as.integer(NA)), p=10, clust_names=NA, get_prototypes=FALSE, x=NA, y=NA, R=NA), &quot;Must specify one of clusters or R (or does one of these provided inputs contain NA?)&quot;, fixed=TRUE) testthat::expect_error(checkFormatClustersInput(list(2:3, c(4, 4, 5)), p=10, clust_names=NA, get_prototypes=FALSE, x=NA, y=NA, R=NA), &quot;length(clusters[[i]]) == length(unique(clusters[[i]])) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormatClustersInput(list(1:4, -1), p=10, clust_names=NA, get_prototypes=FALSE, x=NA, y=NA, R=NA), &quot;all(clusters[[i]] &gt;= 1) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormatClustersInput(list(1:4, c(2.3, 1.2)), p=10, clust_names=NA, get_prototypes=FALSE, x=NA, y=NA, R=NA), &quot;is.integer(clusters[[i]]) is not TRUE&quot;, fixed=TRUE) # Single cluster testthat::expect_true(is.list(checkFormatClustersInput(c(1:5), p=10, clust_names=NA, get_prototypes=FALSE, x=NA, y=NA, R=NA))) }) ## Test passed 🥳 checkClusters(): #&#39; Helper function to confirm that the argument clusters to several functions is #&#39; as expected #&#39; #&#39; @param clusters A named list where each entry is an integer vector of indices #&#39; of features that are in a common cluster, as in the output of css or #&#39; formatClusters. (The length of list clusters is equal to the number of #&#39; clusters.) All identified clusters must be non-overlapping, and all features #&#39; must appear in exactly one cluster (any unclustered features should be in #&#39; their own &quot;cluster&quot; of size 1). #&#39; @param p The number of features; must be at least as large as the number of #&#39; clusters. #&#39; @author Gregory Faletto, Jacob Bien checkClusters &lt;- function(clusters, p){ stopifnot(is.list(clusters)) stopifnot(all(lengths(clusters) &gt;= 1)) stopifnot(all(!is.na(clusters))) n_clusters &lt;- length(clusters) stopifnot(n_clusters == length(unique(clusters))) stopifnot(n_clusters &lt;= p) stopifnot(!is.null(names(clusters))) stopifnot(is.character(names(clusters))) stopifnot(all(!is.na(names(clusters)) &amp; names(clusters) != &quot;&quot;)) stopifnot(length(unique(names(clusters))) == n_clusters) all_clustered_feats &lt;- integer() for(i in 1:n_clusters){ stopifnot(is.integer(clusters[[i]])) all_clustered_feats &lt;- c(all_clustered_feats, clusters[[i]]) } stopifnot(length(all_clustered_feats) == p) stopifnot(length(unique(all_clustered_feats)) == p) stopifnot(all(all_clustered_feats &lt;= p)) stopifnot(all(all_clustered_feats &gt;= 1)) } Tests for checkClusters(): testthat::test_that(&quot;checkClusters works&quot;, { good_clusters &lt;- list(c1=1L:5L, c2=6L:8L, c3=9L) testthat::expect_null(checkClusters(good_clusters, 9)) testthat::expect_error(checkClusters(good_clusters, 10), &quot;length(all_clustered_feats) == p is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkClusters(1L:10L, 10), &quot;is.list(clusters) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkClusters(list(c1=1L:5L, c2=6L:8L, c3=9L, c4=integer()), 9), &quot;all(lengths(clusters) &gt;= 1) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkClusters(list(c1=1L:5L, c2=6L:8L, c3=9L, c4=as.integer(NA)), 9), &quot;all(!is.na(clusters)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkClusters(list(c1=1L:5L, c2=6L:8L, c3=9L, c2=6L:8L), 9), &quot;n_clusters == length(unique(clusters)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkClusters(list(c1=1L:5L, c2=6L:8L, c3=10L), 9), &quot;all(all_clustered_feats &lt;= p) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🥳 getPrototypes(): #&#39; Estimate prototypes from a list of clusters #&#39; #&#39; Takes in list of clusters, x, and y and returns an integer vector (of length #&#39; equal to the number of clusters) of the indices of the feature prototypes #&#39; (the features from each cluster most correlated with the response). #&#39; #&#39; @param clusters A list where each entry is an integer vector of indices of #&#39; features that are in a common cluster. (The length of list clusters must be #&#39; equal to the number of clusters.) All identified clusters must be #&#39; non-overlapping. Must only include clusters of size 2 or larger. #&#39; @param x n x p numeric matrix; design matrix. #&#39; @param y Numeric response vector. Note: in general, the css function does not #&#39; require y to be a numeric vector, because the provided fitfun could use a #&#39; different form of y (for example, a categorical response variable). However, #&#39; y must be numeric in order to provide prototypes because the prototypes are #&#39; determined using the correlation between cluster members (columns of x) and #&#39; y. #&#39; @return An integer vector of the same length as clusters. Entry j is the #&#39; index of the feature identified as the prototype for cluster j. #&#39; @author Gregory Faletto, Jacob Bien getPrototypes &lt;- function(clusters, x, y){ # Check inputs stopifnot(!is.list(clusters) | all(lengths(clusters) &gt;= 1)) stopifnot(is.list(clusters) | length(clusters) &gt;= 1) stopifnot(all(!is.na(x))) stopifnot(is.matrix(x)) n &lt;- nrow(x) p &lt;- ncol(x) checkY(y, n) # Identify prototypes if(length(clusters) &gt; 0){ if(is.list(clusters)){ prototypes &lt;- rep(as.integer(NA), length(clusters)) for(i in 1:length(clusters)){ prototypes[i] &lt;- identifyPrototype(clusters[[i]], x, y) } } else{ # If clusters is not a list, then there is only one cluster. prototypes &lt;- identifyPrototype(clusters, x, y) } } else{ prototypes &lt;- integer() } # Check output stopifnot(is.integer(prototypes)) if(length(clusters) &gt; 0){ if(is.list(clusters)){ stopifnot(length(prototypes) == length(clusters)) } else { stopifnot(length(prototypes) == 1) } } else{ stopifnot(length(prototypes) == 0) } stopifnot(all(!is.na(prototypes))) stopifnot(length(prototypes) == length(unique(prototypes))) return(prototypes) } identifyPrototype(): #&#39; Estimate prototypes from a single cluster #&#39; #&#39; Takes in a single cluster, x, and y and returns an integer of the index of #&#39; the feature prototype (the feature from the cluster most correlated with the #&#39; response). #&#39; #&#39; @param cluster_members_i An integer vector of indices of features that are in #&#39; a common cluster. Must have length at least 2. #&#39; @param x n x p numeric matrix; design matrix. #&#39; @param y Numeric response vector. Note: in general, the css function does not #&#39; require y to be a numeric vector, because the provided fitfun could use a #&#39; different form of y (for example, a categorical response variable). However, #&#39; y must be numeric in order to provide prototypes because the prototypes are #&#39; determined using the correlation between cluster members (columns of x) and #&#39; y. #&#39; @return integer; the index of the feature identified as the prototype for #&#39; the cluster. #&#39; @author Gregory Faletto, Jacob Bien identifyPrototype &lt;- function(cluster_members_i, x, y){ # Check input stopifnot(is.integer(cluster_members_i)) # If cluster only has one member, that member is the prototype if(length(cluster_members_i) == 1){ return(cluster_members_i) } # Choose which cluster member to represent cluster for stability # metric purposes by choosing the one most highly correlated # with y cors_i &lt;- apply(x[, cluster_members_i], 2, corFunction, y=y) max_index_i &lt;- which.max(cors_i)[1] stopifnot(length(max_index_i) == 1) stopifnot(max_index_i %in% 1:length(cluster_members_i)) ret &lt;- cluster_members_i[max_index_i] # Check output stopifnot(is.integer(ret)) stopifnot(length(ret) == 1) stopifnot(ret %in% cluster_members_i) stopifnot(identical(x[, cluster_members_i][, max_index_i], x[, ret])) return(ret) } corFunction(): #&#39; Absolute value of sample correlation between two vectors #&#39; #&#39; Calculates the absolute value of correlation of t and y. If either input has #&#39; only one unique value, returns 0 by definition. #&#39; @param t A numeric or integer vector. #&#39; @param y A numeric or integer vector; must have the same length as t. #&#39; @return A numeric vector of the same length as cluster_i containing the #&#39; weights corresponding to each of the features in cluster_i. The weights #&#39; will all be nonnegative and sum to 1. #&#39; @author Gregory Faletto, Jacob Bien corFunction &lt;- function(t, y){ # Check inputs stopifnot(is.numeric(t) | is.integer(t)) stopifnot(is.numeric(y) | is.integer(y)) stopifnot(length(t) == length(y)) if(length(unique(t)) == 1){ return(0) } if(length(unique(y)) == 1){ warning(&quot;The second argument to corFunction only had one unique entry&quot;) return(0) } return(abs(stats::cor(t, y))) } Tests for corFunction() testthat::test_that(&quot;corFunction works&quot;, { testthat::expect_identical(corFunction(rep(1, 10), 1:10), 0) testthat::expect_identical(corFunction(rep(1.2, 5), 1:5), 0) set.seed(23451) x &lt;- stats::rnorm(8) y &lt;- stats::rnorm(8) testthat::expect_identical(corFunction(x, y), abs(stats::cor(x, y))) testthat::expect_warning(corFunction(1:5, rep(1.2, 5)), &quot;The second argument to corFunction only had one unique entry&quot;, fixed=TRUE) testthat::expect_error(corFunction(&quot;1&quot;, &quot;2&quot;), &quot;is.numeric(t) | is.integer(t) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(corFunction(3:8, &quot;2&quot;), &quot;is.numeric(y) | is.integer(y) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(corFunction(3:8, 1:2), &quot;length(t) == length(y) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 😸 Tests for identifyPrototype() (requires corFunction()): testthat::test_that(&quot;identifyPrototype works&quot;, { testthat::expect_identical(identifyPrototype(10L, &quot;a&quot;, 5), 10L) n &lt;- 10 p &lt;- 5 set.seed(9834) X &lt;- matrix(stats::rnorm(n*p), nrow=n, ncol=p) y &lt;- X[, p] testthat::expect_equal(identifyPrototype(as.integer(p), X, y), p) testthat::expect_equal(identifyPrototype(2L, X, y), 2) testthat::expect_equal(identifyPrototype(as.integer(2:p), X, y), p) testthat::expect_error(identifyPrototype(as.integer(2:p), y, X), &quot;incorrect number of dimensions&quot;, fixed=TRUE) y2 &lt;- rnorm(n) res &lt;- identifyPrototype(c(2L, 3L), X, y2) testthat::expect_true(is.integer(res)) testthat::expect_equal(length(res), 1) testthat::expect_true(res %in% c(2L, 3L)) }) ## Test passed 🎊 Tests for getPrototypes() testthat::test_that(&quot;getPrototypes works&quot;, { n &lt;- 10 p &lt;- 5 set.seed(902689) X &lt;- matrix(stats::rnorm(n*p), nrow=n, ncol=p) y &lt;- X[, p] testthat::expect_identical(getPrototypes(list(1L, 2L, 3L, 4L, 5L), X, y), 1:5) testthat::expect_identical(getPrototypes(list(1L:5L), X, y), 5L) testthat::expect_identical(getPrototypes(list(1L, 2L:5L), X, y), c(1L, 5L)) testthat::expect_identical(getPrototypes(list(3L:5L), X, y), 5L) y2 &lt;- rnorm(n) res &lt;- getPrototypes(list(1L, c(2L, 3L), c(4L, 5L)), X, y2) testthat::expect_true(is.integer(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(res[1], 1L) testthat::expect_true(res[2] %in% c(2L, 3L)) testthat::expect_true(res[3] %in% c(4L, 5L)) testthat::expect_error(getPrototypes(list(1L, 2L, 3L, 4L, 5L), y, X), &quot;is.matrix(x) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getPrototypes(list(1L, 2L, 3L, 4L, 5L), X, y[1:9]), &quot;n == length(y) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🎊 Finally, tests for formatClusters(): testthat::test_that(&quot;formatClusters works&quot;, { # Intentionally don&#39;t provide clusters for all feature, mix up formatting, # etc. good_clusters &lt;- list(red_cluster=1:3, 5:8) res &lt;- formatClusters(good_clusters, p=10) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;clusters&quot;, &quot;multiple&quot;)) # Clusters testthat::expect_true(is.list(res$clusters)) testthat::expect_equal(length(res$clusters), 5) testthat::expect_equal(5, length(names(res$clusters))) testthat::expect_equal(5, length(unique(names(res$clusters)))) testthat::expect_true(&quot;red_cluster&quot; %in% names(res$clusters)) testthat::expect_true(all(!is.na(names(res$clusters)))) testthat::expect_true(all(!is.null(names(res$clusters)))) testthat::expect_true(all(names(res$clusters) != &quot;&quot;)) clust_feats &lt;- integer() true_list &lt;- list(1:3, 5:8, 4, 9, 10) for(i in 1:length(res$clusters)){ testthat::expect_true(is.integer(res$clusters[[i]])) testthat::expect_equal(length(intersect(clust_feats, res$clusters[[i]])), 0) testthat::expect_true(all(res$clusters[[i]] %in% 1:10)) testthat::expect_equal(length(res$clusters[[i]]), length(unique(res$clusters[[i]]))) testthat::expect_true(all(res$clusters[[i]] == true_list[[i]])) clust_feats &lt;- c(clust_feats, res$clusters[[i]]) } testthat::expect_equal(length(clust_feats), 10) testthat::expect_equal(10, length(unique(clust_feats))) testthat::expect_equal(10, length(intersect(clust_feats, 1:10))) # Multiple testthat::expect_true(res$multiple) testthat::expect_false(formatClusters(3:5, p=10)$multiple) ## Trying other inputs testthat::expect_error(formatClusters(list(3:7, 7:10), p=15), &quot;length(intersect(clusters[[i]], clusters[[j]])) == 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formatClusters(list(5:8, 5:8), p=9), &quot;length(clusters) == length(unique(clusters)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formatClusters(list(5:8), p=7), &quot;length(all_clustered_feats) == p is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formatClusters(list(2:3, as.integer(NA)), p=10), &quot;Must specify one of clusters or R (or does one of these provided inputs contain NA?)&quot;, fixed=TRUE) testthat::expect_error(formatClusters(list(2:3, c(4, 4, 5)), p=8), &quot;length(clusters[[i]]) == length(unique(clusters[[i]])) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formatClusters(list(1:4, -1), p=10), &quot;all(clusters[[i]] &gt;= 1) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formatClusters(list(1:4, c(2.3, 1.2))), &quot;is.integer(clusters[[i]]) is not TRUE&quot;, fixed=TRUE) ### Test prototypes feature n &lt;- 8 p &lt;- 6 set.seed(690289) X &lt;- matrix(stats::rnorm(n*p), nrow=n, ncol=p) y &lt;- X[, p] res &lt;- formatClusters(clusters=list(), p=p, get_prototypes=TRUE, x=X, y=y) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;clusters&quot;, &quot;multiple&quot;, &quot;prototypes&quot;)) testthat::expect_true(is.integer(res$prototypes)) testthat::expect_identical(res$prototypes, 1:p) testthat::expect_equal(formatClusters(clusters=1:p, p=p, get_prototypes=TRUE, x=X, y=y)$prototypes, p) testthat::expect_identical(formatClusters(clusters=list(1L, 2L:p), p=p, get_prototypes=TRUE, x=X, y=y)$prototypes, as.integer(c(1, p))) testthat::expect_identical(formatClusters(clusters=3L:p, p=p, get_prototypes=TRUE, x=X, y=y)$prototypes, as.integer(c(p, 1, 2))) y2 &lt;- rnorm(n) res &lt;- formatClusters(clusters=list(2:3, 4:5), p=p, get_prototypes=TRUE, x=X, y=y2)$prototypes testthat::expect_true(is.integer(res)) testthat::expect_equal(length(res), 4) testthat::expect_true(res[1] %in% c(2L, 3L)) testthat::expect_true(res[2] %in% c(4L, 5L)) testthat::expect_equal(res[3], 1L) testthat::expect_equal(res[4], p) testthat::expect_error(formatClusters(clusters=list(2:3, 4:5), p=p, get_prototypes=TRUE, x=y2, y=X), &quot;is.matrix(x) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formatClusters(clusters=list(2:3, 4:5), p=p, get_prototypes=TRUE, x=X, y=y2[1:(n-1)]), &quot;n == length(y) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 😀 checkSamplingType(): #&#39; Helper function to confirm that the argument sampling_type to several #&#39; functions is as expected #&#39; #&#39; @param sampling_type A character vector; either &quot;SS&quot; or &quot;MB&quot;. &quot;MB&quot; is not #&#39; supported yet. #&#39; @author Gregory Faletto, Jacob Bien checkSamplingType &lt;- function(sampling_type){ stopifnot(is.character(sampling_type)) stopifnot(length(sampling_type) == 1) stopifnot(!is.na(sampling_type)) stopifnot(sampling_type %in% c(&quot;SS&quot;, &quot;MB&quot;)) if(sampling_type == &quot;MB&quot;){ stop(&quot;sampling_type MB is not yet supported (and isn&#39;t recommended anyway)&quot;) } } Tests for checkSamplingType(): testthat::test_that(&quot;checkSamplingType works&quot;, { testthat::expect_null(checkSamplingType(&quot;SS&quot;)) testthat::expect_error(checkSamplingType(&quot;MB&quot;), &quot;sampling_type MB is not yet supported (and isn&#39;t recommended anyway)&quot;, fixed=TRUE) testthat::expect_error(checkSamplingType(c(&quot;SS&quot;, &quot;SS&quot;)), &quot;length(sampling_type) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkSamplingType(1), &quot;is.character(sampling_type) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkSamplingType(as.character(NA)), &quot;!is.na(sampling_type) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🥇 checkB(): #&#39; Helper function to confirm that the argument B to several functions is as #&#39; expected #&#39; #&#39; @param B Integer or numeric; the number of subsamples. Note: For #&#39; sampling.type==&quot;MB&quot; the total number of subsamples will be `B`; for #&#39; sampling_type=&quot;SS&quot; the number of subsamples will be `2*B`. #&#39; @author Gregory Faletto, Jacob Bien checkB &lt;- function(B){ stopifnot(length(B) == 1) stopifnot(is.numeric(B) | is.integer(B)) stopifnot(!is.na(B)) stopifnot(B == round(B)) stopifnot(B &gt; 0) if(B &lt; 10){ warning(&quot;Small values of B may lead to poor results.&quot;) } else if (B &gt; 2000){ warning(&quot;Large values of B may require long computation times.&quot;) } } Tests for checkB(): testthat::test_that(&quot;checkB works&quot;, { testthat::expect_null(checkB(1500)) testthat::expect_null(checkB(15)) testthat::expect_error(checkB(&quot;B&quot;), &quot;is.numeric(B) | is.integer(B) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkB(20:25), &quot;length(B) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkB(as.integer(NA)), &quot;!is.na(B) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkB(1.2), &quot;B == round(B) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkB(-100), &quot;B &gt; 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_warning(checkB(5), &quot;Small values of B may lead to poor results.&quot;, fixed=TRUE) testthat::expect_warning(checkB(2200), &quot;Large values of B may require long computation times.&quot;, fixed=TRUE) }) ## Test passed 🎉 checkPropFeatsRemove(): #&#39; Helper function to confirm that the argument prop_feats_remove to several #&#39; functions is as expected #&#39; #&#39; @param prop_feats_remove Numeric; proportion of features that are dropped on #&#39; each subsample. Must be between 0 and 1. #&#39; @param p The number of features; must be greater than 2 if prop_feats_remove #&#39; is greater than 0. #&#39; @author Gregory Faletto, Jacob Bien checkPropFeatsRemove &lt;- function(prop_feats_remove, p){ stopifnot(length(prop_feats_remove) == 1) stopifnot(is.numeric(prop_feats_remove) | is.integer(prop_feats_remove)) stopifnot(!is.na(prop_feats_remove)) stopifnot(prop_feats_remove &gt;= 0 &amp; prop_feats_remove &lt; 1) if(prop_feats_remove &gt; 0){ # Make sure p is at least 2 or else this doesn&#39;t make sense stopifnot(p &gt;= 2) } } Tests for checkPropFeatsRemove(): testthat::test_that(&quot;checkPropFeatsRemove works&quot;, { testthat::expect_null(checkPropFeatsRemove(0, 5)) testthat::expect_null(checkPropFeatsRemove(.3, 10)) testthat::expect_error(checkPropFeatsRemove(1, 3), &quot;prop_feats_remove &gt;= 0 &amp; prop_feats_remove &lt; 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkPropFeatsRemove(c(.5, .6), 17), &quot;length(prop_feats_remove) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkPropFeatsRemove(&quot;.3&quot;, 99), &quot;is.numeric(prop_feats_remove) | is.integer(prop_feats_remove) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkPropFeatsRemove(as.numeric(NA), 172), &quot;!is.na(prop_feats_remove) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkPropFeatsRemove(.1, 1), &quot;p &gt;= 2 is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🎉 Finally, tests for checkCssInputs(): testthat::test_that(&quot;checkCssInputs works&quot;, { set.seed(80526) x &lt;- matrix(stats::rnorm(15*11), nrow=15, ncol=11) y &lt;- stats::rnorm(15) # Intentionally don&#39;t provide clusters for all feature, mix up formatting, # etc. good_clusters &lt;- list(red_cluster=1L:5L, green_cluster=6L:8L # , c4=10:11 ) res &lt;- checkCssInputs(X=x, y=y, lambda=0.01, clusters=good_clusters, fitfun = cssLasso, sampling_type = &quot;SS&quot;, B = 13, prop_feats_remove = 0, train_inds = integer(), num_cores = 1L) # Basic output testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;feat_names&quot;, &quot;X&quot;, &quot;clusters&quot;)) # feat_names testthat::expect_true(is.character(res$feat_names)) testthat::expect_true(is.na(res$feat_names)) testthat::expect_equal(length(res$feat_names), 1) # X testthat::expect_true(is.matrix(res$X)) testthat::expect_true(all(!is.na(res$X))) testthat::expect_true(is.numeric(res$X)) testthat::expect_equal(ncol(res$X), 11) testthat::expect_equal(nrow(res$X), 15) # clusters testthat::expect_true(is.list(res$clusters)) testthat::expect_equal(length(res$clusters), length(names(res$clusters))) testthat::expect_equal(length(res$clusters), length(unique(names(res$clusters)))) testthat::expect_true(all(!is.na(names(res$clusters)))) testthat::expect_true(all(!is.null(names(res$clusters)))) clust_feats &lt;- integer() for(i in 1:length(res$clusters)){ clust_feats &lt;- c(clust_feats, res$clusters[[i]]) } testthat::expect_equal(length(clust_feats), length(unique(clust_feats))) testthat::expect_equal(length(clust_feats), length(intersect(clust_feats, 1:11))) ## Trying other inputs # Custom fitfun with nonsense lambda (which will be ignored by fitfun, and # shouldn&#39;t throw any error, because the acceptable input for lambda should be # enforced only by fitfun) testFitfun &lt;- function(X, y, lambda){ p &lt;- ncol(X) stopifnot(p &gt;= 2) # Choose p/2 features randomly selected &lt;- sample.int(p, size=floor(p/2)) return(selected) } res_fitfun &lt;- checkCssInputs(X=x, y=y, lambda=x, clusters=1:3, fitfun = testFitfun, sampling_type = &quot;SS&quot;, B = 13, prop_feats_remove = 0, train_inds = integer(), num_cores = 1L) testthat::expect_true(is.list(res_fitfun)) # Single cluster res_sing_clust &lt;- checkCssInputs(X=x, y=y, lambda=c(&quot;foo&quot;, as.character(NA), &quot;bar&quot;), clusters=1:3, fitfun = testFitfun, sampling_type = &quot;SS&quot;, B = 13, prop_feats_remove = 0, train_inds = integer(), num_cores = 1L) testthat::expect_true(is.list(res_sing_clust)) testthat::expect_equal(length(res_sing_clust$clusters), 11 - 3 + 1) testthat::expect_true(length(unique(names(res_sing_clust$clusters))) == 11 - 3 + 1) testthat::expect_true(all(!is.na(names(res_sing_clust$clusters)))) testthat::expect_true(all(!is.null(names(res_sing_clust$clusters)))) # Other sampling types testthat::expect_error(checkCssInputs(X=x, y=y, lambda=c(&quot;foo&quot;, as.character(NA), &quot;bar&quot;), clusters=1:3, fitfun = testFitfun, sampling_type = &quot;MB&quot;, B = 13, prop_feats_remove = 0, train_inds = integer(), num_cores = 1L), &quot;sampling_type MB is not yet supported (and isn&#39;t recommended anyway)&quot;, fixed=TRUE) # Error has quotation marks in it testthat::expect_error(checkCssInputs(X=x, y=y, lambda=c(&quot;foo&quot;, as.character(NA), &quot;bar&quot;), clusters=1:3, fitfun = testFitfun, sampling_type = &quot;S&quot;, B = 13, prop_feats_remove = 0, train_inds = integer(), num_cores = 1L)) testthat::expect_error(checkCssInputs(X=x, y=y, lambda=c(&quot;foo&quot;, &quot;bar&quot;, as.character(NA)), clusters=1:3, fitfun = testFitfun, sampling_type = 2, B = 13, prop_feats_remove = 0, train_inds = integer(), num_cores = 1L), &quot;is.character(sampling_type) is not TRUE&quot;, fixed=TRUE) # B testthat::expect_warning(checkCssInputs(X=x, y=y, lambda=c(&quot;foo&quot;, &quot;bar&quot;, as.character(NA)), clusters=1:3, fitfun = testFitfun, sampling_type = &quot;SS&quot;, B = 5, prop_feats_remove = 0, train_inds = integer(), num_cores = 1L), &quot;Small values of B may lead to poor results.&quot;, fixed=TRUE) testthat::expect_error(checkCssInputs(X=x, y=y, lambda=c(&quot;foo&quot;, &quot;bar&quot;, as.character(NA)), clusters=1:3, fitfun = testFitfun, sampling_type = &quot;SS&quot;, B = &quot;foo&quot;, prop_feats_remove = 0, train_inds = integer(), num_cores = 1L), &quot;is.numeric(B) | is.integer(B) is not TRUE&quot;, fixed=TRUE) # prop_feats_remove testthat::expect_true(is.list(checkCssInputs(X=x, y=y, lambda=c(&quot;foo&quot;, &quot;bar&quot;, as.character(NA)), clusters=1:3, fitfun=testFitfun, sampling_type = &quot;SS&quot;, B = 12, prop_feats_remove = 0.3, train_inds = integer(), num_cores = 1L))) # Use train_inds argument testthat::expect_true(is.list(checkCssInputs(X=x, y=y, lambda=c(&quot;foo&quot;, &quot;bar&quot;, as.character(NA)), clusters=1:3, fitfun=testFitfun, sampling_type = &quot;SS&quot;, B = 12, prop_feats_remove = 0.3, train_inds = 11:15, num_cores = 1L))) }) ## Test passed 🥳 cssLoop(): #&#39; Helper function run on each subsample #&#39; #&#39; Runs provided feature selection method `fitfun` on each subsample for cluster #&#39; stability selection (this function is called within `mclapply`). #&#39; @param input Could be one of two things: \\item{subsample}{An integer vector #&#39; of size `n/2` containing the indices of the observations in the subsample.} #&#39; \\item{drop_var_input}{A named list containing two elements: one named #&#39; &quot;subsample&quot; and the same as the previous description, and a logical vector #&#39; named &quot;feats_to_keep&quot; containing the indices of the features to be #&#39; automatically selected.} (The first object is the output of the function #&#39; `createSubsamples()` when the provided `prop_feats_remove` is 0, the default, and #&#39; the second object is the output of `createSubsamples()` when `prop_feats_remove &gt; #&#39; 0`.) #&#39; @param x an n x p numeric matrix containing the predictors. (This should be #&#39; the full design matrix provided to css.) #&#39; @param y A response; can be any response that takes the form of a length n #&#39; vector and is used (or not used) by `fitfun`. Typically (and for default #&#39; `fitfun = cssLasso`), `y` should be an n-dimensional numeric vector containing the #&#39; response. This should be the full response provided to css. #&#39; @param lambda A tuning parameter or set of tuning parameters that may be used #&#39; by the feature selection method. For example, in the default case when #&#39; `fitfun = cssLasso`, `lambda` is a numeric: the penalty to use for each lasso #&#39; fit. #&#39; @param fitfun A function that takes in arguments X, y, and lambda and returns #&#39; a vector of indices of the columns of X (selected features). #&#39; @return An integer vector; the indices of the features selected by `fitfun`. #&#39; @author Gregory Faletto, Jacob Bien cssLoop &lt;- function(input, x, y, lambda, fitfun){ # Check inputs stopifnot(is.matrix(x)) stopifnot(all(!is.na(x))) colnames(x) &lt;- character() n &lt;- nrow(x) p &lt;- ncol(x) stopifnot(length(y) == n) stopifnot(!is.matrix(y)) # Intentionally don&#39;t check y or lambda further to allow for flexibility--these # inputs should be checked within fitfun. if(!is.list(input)){ subsample &lt;- input feats_to_keep &lt;- rep(TRUE, p) } else{ stopifnot(all(names(input) == c(&quot;subsample&quot;, &quot;feats_to_keep&quot;))) subsample &lt;- input$subsample feats_to_keep &lt;- input$feats_to_keep } stopifnot(is.integer(subsample)) stopifnot(all(subsample == round(subsample))) stopifnot(floor(n/2) == length(subsample)) stopifnot(length(subsample) == length(unique(subsample))) stopifnot(is.logical(feats_to_keep)) stopifnot(length(feats_to_keep) == p) selected &lt;- do.call(fitfun, list(X=x[subsample, feats_to_keep], y=y[subsample], lambda=lambda)) selected &lt;- which(feats_to_keep)[selected] # Check output checkCssLoopOutput(selected, p, as.integer(which(feats_to_keep))) return(as.integer(selected)) } checkCssLoopOutput(): #&#39; Helper function to confirm that the outputs of the provided feature selection #&#39; method are as required. #&#39; #&#39; @param selected An integer vector; the indices of the features selected by #&#39; the lasso. #&#39; @param p The total number of observed features; all selected features must be #&#39; in 1:p. #&#39; @param feats_on_subsamp Integer; the indices of the features considered by #&#39; the feature selection method. All selected features must be among these #&#39; features. #&#39; @author Gregory Faletto, Jacob Bien checkCssLoopOutput &lt;- function(selected, p, feats_on_subsamp){ if(!exists(&quot;selected&quot;)){ stop(&quot;The provided feature selection method fitfun failed to return anything on (at least) one subsample&quot;) } if(!is.integer(selected) &amp; !is.numeric(selected)){ stop(&quot;The provided feature selection method fitfun failed to return an integer or numeric vector on (at least) one subsample&quot;) } if(any(is.na(selected))){ stop(&quot;The provided feature selection method fitfun returned a vector containing NA values on (at least) one subsample&quot;) } if(!all(selected == round(selected))){ stop(&quot;The provided feature selection method fitfun failed to return a vector of valid (integer) indices on (at least) one subsample&quot;) } if(length(selected) != length(unique(selected))){ stop(&quot;The provided feature selection method fitfun returned a vector of selected features containing repeated indices on (at least) one subsample&quot;) } if(length(selected) &gt; p){ stop(&quot;The provided feature selection method fitfun returned a vector of selected features longer than p on (at least) one subsample&quot;) } if(length(selected) &gt; 0){ if(max(selected) &gt; p){ stop(&quot;The provided feature selection method fitfun returned a vector of selected features containing an index greater than ncol(X) on (at least) one subsample&quot;) } if(min(selected) &lt;= 0){ stop(&quot;The provided feature selection method fitfun returned a vector of selected features containing a non-positive index on (at least) one subsample&quot;) } } if(&quot;try-error&quot; %in% class(selected) | &quot;error&quot; %in% class(selected) | &quot;simpleError&quot; %in% class(selected) | &quot;condition&quot; %in% class(selected)){ stop(&quot;The provided feature selection method fitfun returned an error on (at least) one subsample&quot;) } if(!all(selected %in% feats_on_subsamp)){ stop(&quot;The provided feature selection method somehow selected features that were not provided for it to consider.&quot;) } } Tests for checkCssLoopOutput(): testthat::test_that(&quot;checkCssLoopOutput works&quot;, { testthat::expect_null(checkCssLoopOutput(selected=1:5, p=6, feats_on_subsamp=1:6)) testthat::expect_error(checkCssLoopOutput(selected=1:5, p=4, feats_on_subsamp=1:6), &quot;The provided feature selection method fitfun returned a vector of selected features longer than p on (at least) one subsample&quot;, fixed=TRUE) testthat::expect_error(checkCssLoopOutput(selected=1:5, p=7, feats_on_subsamp=1:4), &quot;The provided feature selection method somehow selected features that were not provided for it to consider.&quot;, fixed=TRUE) testthat::expect_error(checkCssLoopOutput(selected=c(1, 2, 3, 4.4, 5), p=7, feats_on_subsamp=1:7), &quot;The provided feature selection method fitfun failed to return a vector of valid (integer) indices on (at least) one subsample&quot;, fixed=TRUE) testthat::expect_error(checkCssLoopOutput(selected=rep(1, 3), p=7, feats_on_subsamp=1:7), &quot;The provided feature selection method fitfun returned a vector of selected features containing repeated indices on (at least) one subsample&quot;, fixed=TRUE) testthat::expect_error(checkCssLoopOutput(selected=c(-1, 5), p=7, feats_on_subsamp=1:7), &quot;The provided feature selection method fitfun returned a vector of selected features containing a non-positive index on (at least) one subsample&quot;, fixed=TRUE) testthat::expect_error(checkCssLoopOutput(selected=c(0, 5), p=7, feats_on_subsamp=1:7), &quot;The provided feature selection method fitfun returned a vector of selected features containing a non-positive index on (at least) one subsample&quot;, fixed=TRUE) testthat::expect_error(checkCssLoopOutput(selected=as.integer(NA), p=7, feats_on_subsamp=1:7), &quot;The provided feature selection method fitfun returned a vector containing NA values on (at least) one subsample&quot;, fixed=TRUE) testthat::expect_error(checkCssLoopOutput(selected=c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;), p=7, feats_on_subsamp=1:7), &quot;The provided feature selection method fitfun failed to return an integer or numeric vector on (at least) one subsample&quot;, fixed=TRUE) }) ## Test passed 🌈 checkCssLassoInputs(): #&#39; Helper function to confirm that the inputs to `cssLasso()` are as expected. #&#39; #&#39; @param X A design matrix containing the predictors. (Note that we don&#39;t need #&#39; to check X very much, because X will have already been checked by the #&#39; function `checkCssInputs()` when it was provided to `css()`.) #&#39; @param y A numeric vector containing the response. #&#39; @param lambda Numeric; a nonnegative number for the lasso penalty to use #&#39; on each subsample. (For now, only one lambda value can be provided to #&#39; `cssLasso()`; in the future, we plan to allow for multiple lambda values to be #&#39; provided to `cssLasso()`, as described in Faletto and Bien 2022.) #&#39; @author Gregory Faletto, Jacob Bien checkCssLassoInputs &lt;- function(X, y, lambda){ n &lt;- nrow(X) p &lt;- ncol(X) if(!is.numeric(y)){ stop(&quot;For method cssLasso, y must be a numeric vector.&quot;) } if(is.matrix(y)){ stop(&quot;For method cssLasso, y must be a numeric vector (inputted y was a matrix).&quot;) } if(n != length(y)){ stop(&quot;For method cssLasso, y must be a vector of length equal to nrow(X).&quot;) } if(length(unique(y)) &lt;= 1){ stop(&quot;Subsample with only one unique value of y detected--for method cssLasso, all subsamples of y of size floor(n/2) must have more than one unique value.&quot;) } if(!is.numeric(lambda) &amp; !is.integer(lambda)){ stop(&quot;For method cssLasso, lambda must be a numeric.&quot;) } if(any(is.na(lambda))){ stop(&quot;NA detected in provided lambda input to cssLasso&quot;) } if(length(lambda) != 1){ stop(&quot;For method cssLasso, lambda must be a numeric of length 1.&quot;) } if(lambda &lt; 0){ stop(&quot;For method cssLasso, lambda must be nonnegative.&quot;) } } Tests for checkCssLassoInputs(): testthat::test_that(&quot;checkCssLassoInputs works&quot;, { set.seed(761) x &lt;- matrix(stats::rnorm(15*4), nrow=15, ncol=4) y &lt;- stats::rnorm(15) testthat::expect_null(checkCssLassoInputs(X=x, y=y, lambda=0.01)) testthat::expect_error(checkCssLassoInputs(X=x, y=logical(15), lambda=0.05), &quot;For method cssLasso, y must be a numeric vector.&quot;, fixed=TRUE) testthat::expect_error(checkCssLassoInputs(X=x[1:13, ], y=y, lambda=0.01), &quot;For method cssLasso, y must be a vector of length equal to nrow(X).&quot;, fixed=TRUE) testthat::expect_error(checkCssLassoInputs(X=x, y=rep(1.2, 15), lambda=0.05), &quot;Subsample with only one unique value of y detected--for method cssLasso, all subsamples of y of size floor(n/2) must have more than one unique value.&quot;, fixed=TRUE) testthat::expect_error(checkCssLassoInputs(X=x, y=y, lambda=TRUE), &quot;For method cssLasso, lambda must be a numeric.&quot;, fixed=TRUE) testthat::expect_error(checkCssLassoInputs(X=x, y=y, lambda=as.numeric(NA)), &quot;NA detected in provided lambda input to cssLasso&quot;, fixed=TRUE) testthat::expect_error(checkCssLassoInputs(X=x, y=y, lambda=-0.01), &quot;For method cssLasso, lambda must be nonnegative.&quot;, fixed=TRUE) testthat::expect_error(checkCssLassoInputs(X=x, y=y, lambda=x), &quot;For method cssLasso, lambda must be a numeric of length 1.&quot;, fixed=TRUE) testthat::expect_error(checkCssLassoInputs(X=x, y=y, lambda=numeric()), &quot;For method cssLasso, lambda must be a numeric of length 1.&quot;, fixed=TRUE) testthat::expect_error(checkCssLassoInputs(X=x, y=y, lambda=-0.01), &quot;For method cssLasso, lambda must be nonnegative.&quot;, fixed=TRUE) }) ## Test passed 🌈 Tests for cssLoop() (had to define checkCssLassoInputs() first): testthat::test_that(&quot;cssLoop works&quot;, { set.seed(89134) x &lt;- matrix(stats::rnorm(9*8), nrow=9, ncol=8) y &lt;- stats::rnorm(9) output &lt;- cssLoop(input=1L:4L, x=x, y=y, lambda=0.05, fitfun=cssLasso) testthat::expect_true(is.integer(output)) testthat::expect_equal(length(output), length(unique(output))) testthat::expect_true(length(output) &lt;= 8) testthat::expect_true(all(output &gt;= 1)) testthat::expect_true(all(output &lt;= 8)) testthat::expect_error(cssLoop(input=1L:6L, x=x, y=y, lambda=0.05, fitfun=cssLasso), &quot;floor(n/2) == length(subsample) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssLoop(input=1L:4L, x=x, y=y[1:8], lambda=0.05, fitfun=cssLasso), &quot;length(y) == n is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssLoop(input=1L:4L, x=x, y=logical(9), lambda=0.05, fitfun=cssLasso), &quot;For method cssLasso, y must be a numeric vector.&quot;, fixed=TRUE) testthat::expect_error(cssLoop(input=1L:4L, x=x, y=y, lambda=x, fitfun=cssLasso), &quot;For method cssLasso, lambda must be a numeric of length 1.&quot;, fixed=TRUE) # Test other input format alt_input &lt;- list(&quot;subsample&quot;=2:5, &quot;feats_to_keep&quot;=c(FALSE, rep(TRUE, 4), rep(FALSE, 2), TRUE)) output2 &lt;- cssLoop(input=alt_input, x=x, y=y, lambda=0.08, fitfun=cssLasso) testthat::expect_true(is.integer(output2)) testthat::expect_equal(length(output2), length(unique(output2))) testthat::expect_true(length(output2) &lt;= 8) testthat::expect_true(all(output2 %in% c(2, 3, 4, 5, 8))) testthat::expect_error(cssLoop(input= list(&quot;subsample&quot;=2:5, &quot;feats_to_keep&quot;=c(FALSE, rep(TRUE, 4), rep(FALSE, 2))), x=x, y=y, lambda=0.08, fitfun=cssLasso), &quot;length(feats_to_keep) == p is not TRUE&quot;, fixed=TRUE) # Custom fitfun with nonsense lambda (which will be ignored by fitfun, and # shouldn&#39;t throw any error, because the acceptable input for lambda should be # enforced only by fitfun) and nonsense y testFitfun &lt;- function(X, y, lambda){ p &lt;- ncol(X) stopifnot(p &gt;= 2) # Choose p/2 features randomly selected &lt;- sample.int(p, size=floor(p/2)) return(selected) } testthat::expect_true(is.integer(cssLoop(input=1L:4L, x=x, y=y, lambda=TRUE, fitfun=testFitfun))) testthat::expect_true(is.integer(cssLoop(input=1L:4L, x=x, y=character(9), lambda=.05, fitfun=testFitfun))) }) ## Test passed 🎊 checkGetClusterSelMatrixInput(): #&#39; Helper function to check inputs to getClusterSelMatrix function #&#39; #&#39; @param clusters A named list where each entry is an integer vector of indices #&#39; of features that are in a common cluster, as in the output of formatClusters. #&#39; (The length of list clusters is equal to the number of clusters.) All #&#39; identified clusters must be non-overlapping, and all features must appear in #&#39; exactly one cluster (any unclustered features should be in their own #&#39; &quot;cluster&quot; of size 1). #&#39; @param res A binary integer matrix. res[i, j] = 1 if feature j was selected #&#39; on subsample i and equals 0 otherwise, as in the output of getSelMatrix. #&#39; (That is, each row is a selected set.) #&#39; @return The parameter B, corresponding to half of the subsamples for #&#39; sampling_type &quot;SS&quot;. #&#39; @author Gregory Faletto, Jacob Bien checkGetClusterSelMatrixInput &lt;- function(clusters, res){ stopifnot(is.matrix(res)) stopifnot(all(res %in% c(0, 1))) p &lt;- ncol(res) stopifnot(nrow(res) &gt; 0) checkClusters(clusters, p) } Tests for checkGetClusterSelMatrixInput(): testthat::test_that(&quot;checkGetClusterSelMatrixInput works&quot;, { good_clusters &lt;- list(happy=1L:8L, sad=9L:10L, med=11L) res &lt;- matrix(sample(c(0, 1), size=6*11, replace=TRUE), nrow=6, ncol=11) testthat::expect_null(checkGetClusterSelMatrixInput(good_clusters, res)) testthat::expect_error(checkGetClusterSelMatrixInput(list(happy=1L:8L, med=11L), res), &quot;length(all_clustered_feats) == p is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetClusterSelMatrixInput(good_clusters, 1:9), &quot;is.matrix(res) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetClusterSelMatrixInput(good_clusters, res + .3), &quot;all(res %in% c(0, 1)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetClusterSelMatrixInput(good_clusters, res[, 1:9]), &quot;length(all_clustered_feats) == p is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetClusterSelMatrixInput(1L:10L, res), &quot;is.list(clusters) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetClusterSelMatrixInput(list(c1=1L:5L, c2=6L:8L, c3=9L, c4=integer()), res), &quot;all(lengths(clusters) &gt;= 1) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetClusterSelMatrixInput(list(c1=1L:5L, c2=6L:8L, c3=9L, c4=as.integer(NA)), res), &quot;all(!is.na(clusters)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetClusterSelMatrixInput(list(c1=1L:5L, c2=6L:8L, c3=9L, c2=6L:8L), res), &quot;n_clusters == length(unique(clusters)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetClusterSelMatrixInput(list(c1=1L:5L, c2=6L:8L, c3=14L), res), &quot;length(all_clustered_feats) == p is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🎉 "],["tests-for-main-functions-in-cssr.html", "4 Tests for main functions in cssr", " 4 Tests for main functions in cssr Now that the helper functions have been defined, we move on to tests for the main functions in the package. Tests for createSubsamples(): testthat::test_that(&quot;createSubsamples works&quot;, { res &lt;- createSubsamples(n=20L, p=5L, B=11L, sampling_type=&quot;SS&quot;, prop_feats_remove=0) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 2*11) testthat::expect_true(all(lengths(res) == 20/2)) testthat::expect_equal(length(unique(res[[13]])), 20/2) set &lt;- res[[4]] comp_set &lt;- res[[4 + 11]] testthat::expect_equal(length(intersect(set, comp_set)), 0) testthat::expect_equal(length(union(set, comp_set)), length(c(set, comp_set))) testthat::expect_equal(20, length(c(set, comp_set))) # Try odd n res_odd &lt;- createSubsamples(n=19L, p=23L, B=13L, sampling_type=&quot;SS&quot;, prop_feats_remove=0) testthat::expect_true(is.list(res_odd)) testthat::expect_equal(length(res_odd), 2*13) testthat::expect_true(all(lengths(res_odd) == floor(19/2))) testthat::expect_equal(length(unique(res_odd[[3]])), floor(19/2)) set_odd &lt;- res_odd[[2]] comp_set_odd &lt;- res_odd[[2 + 13]] testthat::expect_equal(length(intersect(set_odd, comp_set_odd)), 0) testthat::expect_equal(length(union(set_odd, comp_set_odd)), length(c(set_odd, comp_set_odd))) testthat::expect_equal(19 - 1, length(c(set_odd, comp_set_odd))) testthat::expect_error(createSubsamples(n=20L, p=5L, B=11L, sampling_type=&quot;MB&quot;, prop_feats_remove=0), &quot;sampling_type MB is not yet supported (and isn&#39;t recommended anyway)&quot;, fixed=TRUE) # misspecified sampling_type (not specifying error because contains quotation # marks) testthat::expect_error(createSubsamples(n=20L, p=5L, B=11L, sampling_type=&quot;S&quot;, prop_feats_remove=0)) testthat::expect_error(createSubsamples(n=11.1, p=5L, B=11L, sampling_type=&quot;SS&quot;, prop_feats_remove=0), &quot;n == round(n) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(createSubsamples(n=-20L, p=5L, B=11L, sampling_type=&quot;SS&quot;, prop_feats_remove=0), &quot;n &gt; 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(createSubsamples(n=20L, p=5L, B=25.6, sampling_type=&quot;SS&quot;, prop_feats_remove=0), &quot;length(subsamples) == B is not TRUE&quot;, fixed=TRUE) }) ## Test passed 😸 Tests for getSubsamps(): testthat::test_that(&quot;getSubsamps works&quot;, { res &lt;- getSubsamps(n=18L, B=21L, sampling_type=&quot;SS&quot;) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 2*21) testthat::expect_true(all(lengths(res) == 18/2)) testthat::expect_equal(length(unique(res[[7]])), 18/2) set &lt;- res[[3]] comp_set &lt;- res[[3 + 21]] testthat::expect_equal(length(intersect(set, comp_set)), 0) testthat::expect_equal(length(union(set, comp_set)), length(c(set, comp_set))) testthat::expect_equal(18, length(c(set, comp_set))) }) ## Test passed 😸 Tests for getSelMatrix(): testthat::test_that(&quot;getSelMatrix works&quot;, { set.seed(98623) x &lt;- matrix(stats::rnorm(25*6), nrow=25, ncol=6) y &lt;- stats::rnorm(25) subsamps_object &lt;- createSubsamples(n=25, p=6, B=12, sampling_type=&quot;SS&quot;, prop_feats_remove=0) res &lt;- getSelMatrix(x=x, y=y, lambda=0.01, B=12, sampling_type=&quot;SS&quot;, subsamps_object=subsamps_object, num_cores=1, fitfun=cssLasso) testthat::expect_true(is.matrix(res)) testthat::expect_equal(nrow(res), 2*12) testthat::expect_equal(ncol(res), 6) testthat::expect_true(all(res %in% c(0, 1))) testthat::expect_true(all(is.integer(res))) # Try a different fitfun testFitfun &lt;- function(X, y, lambda){ p &lt;- ncol(X) stopifnot(p &gt;= 2) # Choose p/2 features randomly selected &lt;- sample.int(p, size=floor(p/2)) return(selected) } # Note that value of lambda doesn&#39;t matter res2 &lt;- getSelMatrix(x=x, y=y, lambda=&quot;foo&quot;, B=12, sampling_type=&quot;SS&quot;, subsamps_object=subsamps_object, num_cores=1, fitfun=testFitfun) testthat::expect_true(is.matrix(res2)) testthat::expect_equal(nrow(res2), 2*12) testthat::expect_equal(ncol(res2), 6) testthat::expect_true(all(res2 %in% c(0, 1))) testthat::expect_true(all(is.integer(res2))) testthat::expect_error(getSelMatrix(x=x, y=y, lambda=&quot;0.02&quot;, B=12, sampling_type=&quot;SS&quot;, subsamps_object=&quot;subsamps_object&quot;, num_cores=1, fitfun=testFitfun), &quot;is.integer(subsample) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getSelMatrix(x=x[1:8, ], y=y, lambda=&quot;foo&quot;, B=12, sampling_type=&quot;SS&quot;, subsamps_object=subsamps_object, num_cores=1, fitfun=testFitfun), &quot;length(y) == n is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getSelMatrix(x=x, y=y, lambda=-0.02, B=12, sampling_type=&quot;SS&quot;, subsamps_object=subsamps_object, num_cores=1, fitfun=cssLasso), &quot;For method cssLasso, lambda must be nonnegative.&quot;, fixed=TRUE) # Wrong B testthat::expect_error(getSelMatrix(x=x, y=y, lambda=0.02, B=37, sampling_type=&quot;SS&quot;, subsamps_object=subsamps_object, num_cores=1, fitfun=cssLasso), &quot;length(res_list) == nrow(res) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🎉 Tests for cssLasso(): testthat::test_that(&quot;cssLasso works&quot;, { set.seed(24509) x &lt;- matrix(stats::rnorm(15*4), nrow=15, ncol=4) y &lt;- stats::rnorm(15) res &lt;- cssLasso(X=x, y=y, lambda=0.01) testthat::expect_true(is.integer(res)) testthat::expect_true(length(res) &lt;= 4) testthat::expect_true(length(res) &gt;= 0) testthat::expect_true(length(res) == length(unique(res))) testthat::expect_true(all(res &lt;= 4)) testthat::expect_true(all(res &gt;= 1)) testthat::expect_error(cssLasso(X=x[1:13, ], y=y, lambda=0.01), &quot;For method cssLasso, y must be a vector of length equal to nrow(X).&quot;, fixed=TRUE) testthat::expect_error(cssLasso(X=x, y=y, lambda=-0.01), &quot;For method cssLasso, lambda must be nonnegative.&quot;, fixed=TRUE) }) ## Test passed 😀 Tests for getClusterSelMatrix(): testthat::test_that(&quot;getClusterSelMatrix works&quot;, { good_clusters &lt;- list(red_cluster=1L:5L, green_cluster=6L:8L, blue_clust=9L) B &lt;- 14 p &lt;- 9 res_entries &lt;- as.integer(sample(c(0, 1), size=2*B*p, replace=TRUE)) good_res &lt;- matrix(res_entries, nrow=2*B, ncol=p) res &lt;- getClusterSelMatrix(good_clusters, good_res) testthat::expect_true(is.matrix(res)) testthat::expect_equal(nrow(res), 2*B) # 3 clusters testthat::expect_equal(ncol(res), 3) testthat::expect_identical(colnames(res), c(&quot;red_cluster&quot;, &quot;green_cluster&quot;, &quot;blue_clust&quot;)) testthat::expect_true(all(is.integer(res))) testthat::expect_true(all(res %in% c(0, 1))) clust_2 &lt;- good_clusters[[2]] any_one &lt;- rowSums(good_res[, clust_2]) &gt; 0 if(any(any_one)){ testthat::expect_true(all(res[any_one, 2] == 1)) } all_zeros &lt;- rowSums(good_res[, clust_2]) == 0 if(any(all_zeros)){ testthat::expect_true(all(res[all_zeros, 2] == 0)) } # Not all features in a cluster bad_clusters &lt;- list(red_cluster=1L:5L, green_cluster=6L:7L, blue_clust=9L) testthat::expect_error(getClusterSelMatrix(bad_clusters, good_res), &quot;length(all_clustered_feats) == p is not TRUE&quot;, fixed=TRUE) bad_res_entries &lt;- as.integer(sample(c(0, 1, 2), size=2*B*p, replace=TRUE)) bad_res &lt;- matrix(bad_res_entries, nrow=2*B, ncol=p) testthat::expect_error(getClusterSelMatrix(good_clusters, bad_res), &quot;all(res %in% c(0, 1)) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🌈 Finally, tests for css() itself! testthat::test_that(&quot;css works&quot;, { set.seed(8712) x &lt;- matrix(stats::rnorm(15*11), nrow=15, ncol=11) y &lt;- stats::rnorm(15) # Intentionally don&#39;t provide clusters for all feature, mix up formatting, # etc. good_clusters &lt;- list(red_cluster=1L:5L, green_cluster=6L:8L, c4=10:11) res &lt;- css(X=x, y=y, lambda=0.01, clusters=good_clusters, fitfun = cssLasso, sampling_type = &quot;SS&quot;, B = 13, prop_feats_remove = 0, train_inds = integer(), num_cores = 1L) # Basic output testthat::expect_true(is.list(res)) testthat::expect_identical(class(res), &quot;cssr&quot;) testthat::expect_identical(names(res), c(&quot;feat_sel_mat&quot;, &quot;clus_sel_mat&quot;, &quot;X&quot;, &quot;y&quot;, &quot;clusters&quot;, &quot;train_inds&quot;)) # feat_sel mat testthat::expect_true(is.integer(res$feat_sel_mat)) testthat::expect_true(is.matrix(res$feat_sel_mat)) testthat::expect_true(all(res$feat_sel_mat %in% c(0, 1))) testthat::expect_equal(ncol(res$feat_sel_mat), 11) testthat::expect_null(colnames(res$feat_sel_mat)) # clus_sel_mat testthat::expect_true(is.integer(res$clus_sel_mat)) testthat::expect_true(is.matrix(res$clus_sel_mat)) testthat::expect_true(all(res$clus_sel_mat %in% c(0, 1))) # 4 clusters testthat::expect_equal(ncol(res$clus_sel_mat), 4) testthat::expect_identical(colnames(res$clus_sel_mat), names(res$clusters)) testthat::expect_equal(length(colnames(res$clus_sel_mat)), 4) testthat::expect_equal(length(unique(colnames(res$clus_sel_mat))), 4) testthat::expect_true(all(!is.na(colnames(res$clus_sel_mat)))) testthat::expect_true(all(!is.null(colnames(res$clus_sel_mat)))) # X testthat::expect_true(is.matrix(res$X)) testthat::expect_true(all(!is.na(res$X))) testthat::expect_true(is.numeric(res$X)) testthat::expect_equal(ncol(res$X), 11) testthat::expect_equal(nrow(res$X), 15) # y testthat::expect_true(is.numeric(res$y)) testthat::expect_equal(length(res$y), 15) # clusters testthat::expect_true(is.list(res$clusters)) testthat::expect_equal(length(res$clusters), length(names(res$clusters))) testthat::expect_equal(length(res$clusters), length(unique(names(res$clusters)))) testthat::expect_true(all(!is.na(names(res$clusters)))) testthat::expect_true(all(!is.null(names(res$clusters)))) clust_feats &lt;- integer() for(i in 1:length(res$clusters)){ clust_feats &lt;- c(clust_feats, res$clusters[[i]]) } testthat::expect_equal(length(clust_feats), length(unique(clust_feats))) testthat::expect_equal(length(clust_feats), length(intersect(clust_feats, 1:11))) # train_inds testthat::expect_identical(res$train_inds, integer()) ## Trying other inputs # X as a data.frame X_df &lt;- datasets::mtcars res_fitfun &lt;- css(X=X_df, y=stats::rnorm(nrow(X_df)), lambda=0.01, B = 10) testthat::expect_identical(class(res_fitfun), &quot;cssr&quot;) # X as a dataframe with factors (number of columns of final design matrix # after one-hot encoding factors won&#39;t match number of columns of df2) # cyl, gear, and carb are factors with more than 2 levels df2 &lt;- X_df df2$cyl &lt;- as.factor(df2$cyl) df2$vs &lt;- as.factor(df2$vs) df2$am &lt;- as.factor(df2$am) df2$gear &lt;- as.factor(df2$gear) df2$carb &lt;- as.factor(df2$carb) res_fitfun &lt;- css(X=df2, y=stats::rnorm(nrow(X_df)), lambda=0.01, B = 10) testthat::expect_identical(class(res_fitfun), &quot;cssr&quot;) # Should get error if I try to use clusters in this data.frame that contains # factors with more than two levels testthat::expect_error(css(X=df2, y=stats::rnorm(nrow(X_df)), lambda=0.01, B = 10, clusters=1:3), &quot;When stats::model.matrix converted the provided data.frame X to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert X to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;, fixed=TRUE) # X as a matrix with column names x2 &lt;- x colnames(x2) &lt;- LETTERS[1:11] res_names &lt;- css(X=x2, y=y, lambda=0.01, clusters=good_clusters, B = 13) testthat::expect_identical(class(res_names), &quot;cssr&quot;) testthat::expect_identical(colnames(x2), colnames(res_names$X)) testthat::expect_identical(colnames(x2), colnames(res_names$feat_sel_mat)) # Custom fitfun with nonsense lambda (which will be ignored by fitfun, and # shouldn&#39;t throw any error, because the acceptable input for lambda should be # enforced only by fitfun) testFitfun &lt;- function(X, y, lambda){ p &lt;- ncol(X) stopifnot(p &gt;= 2) # Choose p/2 features randomly selected &lt;- sample.int(p, size=floor(p/2)) return(selected) } res_fitfun &lt;- css(X=x, y=y, lambda=c(&quot;foo&quot;, as.character(NA), &quot;bar&quot;), clusters=1:3, B = 10, fitfun=testFitfun) testthat::expect_identical(class(res_fitfun), &quot;cssr&quot;) # Bad lambda testthat::expect_error(css(X=x, y=y, lambda=-0.01, B = 10), &quot;For method cssLasso, lambda must be nonnegative.&quot;, fixed=TRUE) testthat::expect_error(css(X=x, y=y, lambda=&quot;foo&quot;, B = 10), &quot;For method cssLasso, lambda must be a numeric.&quot;, fixed=TRUE) # Single cluster res_sing_clust &lt;- css(X=x, y=y, lambda=0.01, clusters=1:3, B = 10) testthat::expect_identical(class(res_sing_clust), &quot;cssr&quot;) testthat::expect_equal(length(res_sing_clust$clusters), 11 - 3 + 1) testthat::expect_true(length(unique(names(res_sing_clust$clusters))) == 11 - 3 + 1) testthat::expect_true(all(!is.na(names(res_sing_clust$clusters)))) testthat::expect_true(all(!is.null(names(res_sing_clust$clusters)))) # No cluster testthat::expect_identical(class(css(X=x, y=y, lambda=0.01, B = 10)), &quot;cssr&quot;) # All clusters named testthat::expect_identical(class(css(X=x, y=y, clusters=list(&quot;a&quot;=1:5, &quot;b&quot;=6:10, &quot;c&quot;=11), lambda=0.01, B=10)), &quot;cssr&quot;) # Other sampling types testthat::expect_error(css(X=x, y=y, lambda=1, sampling_type=&quot;MB&quot;), &quot;sampling_type MB is not yet supported (and isn&#39;t recommended anyway)&quot;, fixed=TRUE) # Error has quotation marks in it testthat::expect_error(css(X=x, y=y, lambda=1, sampling_type=&quot;S&quot;)) testthat::expect_error(css(X=x, y=y, lambda=1, sampling_type=1), &quot;is.character(sampling_type) is not TRUE&quot;, fixed=TRUE) # B testthat::expect_warning(css(X=x, y=y, lambda=1, B=5), &quot;Small values of B may lead to poor results.&quot;, fixed=TRUE) testthat::expect_error(css(X=x, y=y, lambda=1, B=list(10)), &quot;is.numeric(B) | is.integer(B) is not TRUE&quot;, fixed=TRUE) # Clusters testthat::expect_error(css(X=x, y=y, lambda=1, clusters=&quot;red&quot;), &quot;is.numeric(clusters) | is.integer(clusters) is not TRUE&quot;, fixed=TRUE) # prop_feats_remove testthat::expect_identical(class(css(X=x, y=y, lambda=0.01, B = 10, prop_feats_remove=0.3)), &quot;cssr&quot;) # Weirdly high, but still valid, value of prop_feats_remove testthat::expect_identical(class(css(X=x, y=y, lambda=0.01, B = 10, prop_feats_remove=0.9999999999)), &quot;cssr&quot;) # Use train_inds argument res_train &lt;- css(X=x, y=y, lambda=0.01, B = 10, train_inds=11:15) testthat::expect_equal(res_train$train_inds, 11:15) }) ## Test passed 🥳 "],["sel-and-pred.html", "5 Selection and prediction functions", " 5 Selection and prediction functions Now that css() has been defined and tested, we write functions to work with the output of css(). The output of these functions will be of more direct interest for most end users than the output of css(). These functions are defined separately from css() because the most computationally intensive steps happen within css(). css() can be called only once on a data set, and then the functions that follow can be explored relatively quickly (one can try different parameters, etc.). getCssSelections() takes in the results of css() along with user-defined parameters on how to select clusters (a minimum or maximum number of clusters to select, along with a cutoff for cluster selection proportions) and selects clusters as well as features from those clusters. getCssDesign() takes in the same inputs as getCssSelections() along with an unlabeled test matrix of features X (containing the same features as the X matrix provided originally to css()). It uses the results from css() to select clusters like getCssSelections(), then it uses a user-selected weighting scheme to compute weighted averages of the cluster members. It returns a test matrix of cluster representatives, which can be used for downstream predictive tasks. Finally, getCssPreds() has the same inputs as getCssPreds() FIX THIS TYPO, except it also accepts a set of labeled training data (where the response must be real-valued). getCssPreds() selects clusters, forms matrices of cluster representatives on the training and test data, uses the training matrix of cluster representatives (along with the vector of responses for the training data) to estimate a linear model via ordinary least squares, and finally generates predictions on the test data using this linear model. As in the previous section, we first define each function and then define the helper functions called by that function. Tests are written for each function as soon as all of its dependencies have been defined. getCssSelections() Calls checkCutoff(), which checks that the specified cutoff input is as expected checkWeighting() verifies the weighting input to getCssSelections() checkMinNumClusts() confirms that the min_num_clusts parameter provided to getCssSelections() is as expected Likewise for checkMaxNumClusts() getSelectedClusters() is the workhorse function of getCssSelections(), doing most of the work to get the selected clusters (and the selected features from those clusters) with the verified inputs checkSelectedClusters() checks internally that the selected clusters are as expected getAllClustWeights() gets the weights for each of the members of the selected clusters getClustWeights() gets the weights for a single cluster checkGetSelectedClustersOutput() verifies the output of getSelectedClusters() getCssDesign() checkNewXProvided() confirms that the design matrix provided to getCssDesign() matches the characteristics of the matrix that was provided to css(). checkXInputResults() also verifies these inputs (and is also used by getCssPreds() on both the training and test data) formCssDesign() is the workhorse function, generating a matrix of cluster representatives with the verified inputs to getCssDesign() checkFormCssDesignInputs() verifies the inputs to formCssDesign() (somewhat redundantly here, but formCssDesign() is called by more than one function, so this verifies the inputs to formCssDesign() regardless of where it is called). getCssPreds() checkGetCssPredsInputs() verifies the inputs to getCssPreds() getCssSelections(): #&#39; Obtain a selected set of clusters and features #&#39; #&#39; Generate sets of selected clusters and features from cluster stability #&#39; selection. #&#39; @param css_results An object of class &quot;cssr&quot; (the output of the function #&#39; css). #&#39; @param weighting Character; determines how to calculate the weights for #&#39; individual features within the selected clusters. Only those features with #&#39; nonzero weight within the selected clusters will be returned. Must be one of #&#39; &quot;sparse&quot;, &quot;weighted_avg&quot;, or &quot;simple_avg&#39;. For &quot;sparse&quot;, all the weight is #&#39; put on the most frequently #&#39; selected individual cluster member (or divided equally among all the clusters #&#39; that are tied for the top selection proportion if there is a tie). For #&#39; &quot;weighted_avg&quot;, only the features within a selected cluster that were #&#39; themselves selected on at least one subsample will have nonzero weight. For #&#39; &quot;simple_avg&quot;, each cluster member gets equal weight regardless of the #&#39; individual feature selection proportions (that is, all cluster members within #&#39; each selected cluster will be returned.). See Faletto and Bien (2022) for #&#39; details. Default is &quot;sparse&quot;. #&#39; @param cutoff Numeric; getCssSelections will select and return only of those #&#39; clusters with selection proportions equal to at least cutoff. Must be between #&#39; 0 and 1. Default is 0 (in which case either all clusters are selected, or #&#39; max_num_clusts are selected, if max_num_clusts is specified). #&#39; @param min_num_clusts Integer or numeric; the minimum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns fewer than #&#39; min_num_clusts clusters, the cutoff will be increased until at least #&#39; min_num_clusts clusters are selected.) Default is 1. #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) Default is NA (in which case #&#39; max_num_clusts is ignored). #&#39; @return A named list with two items. \\item{selected_clusts}{A named list of #&#39; integer vectors; each vector contains the indices of the features in one of #&#39; the selected clusters.} \\item{selected_feats}{A named integer vector; the #&#39; indices of the features with nonzero weights from all of the selected #&#39; clusters.} \\item{weights}{A named list of the same length as selected_clusts. #&#39; Each list element weights[[j]] is a numeric vector of the weights to use for #&#39; the jth selected cluster, and it has the same name as the cluster it #&#39; corresponds to.} #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references &lt;&lt;faletto2022&gt;&gt; #&#39; @export getCssSelections &lt;- function(css_results, weighting=&quot;sparse&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=NA){ # Check inputs stopifnot(class(css_results) == &quot;cssr&quot;) checkCutoff(cutoff) checkWeighting(weighting) p &lt;- ncol(css_results$feat_sel_mat) checkMinNumClusts(min_num_clusts, p, length(css_results$clusters)) max_num_clusts &lt;- checkMaxNumClusts(max_num_clusts, min_num_clusts, p, length(css_results$clusters)) sel_results &lt;- getSelectedClusters(css_results, weighting, cutoff, min_num_clusts, max_num_clusts) # sel_results$selected_clusts is guaranteed to have length at least 1 by # getSelectedClusters sel_clust_names &lt;- names(sel_results$selected_clusts) stopifnot(length(sel_clust_names) &gt;= 1) stopifnot(all(sel_clust_names %in% names(css_results$clusters))) sel_clusts &lt;- list() for(i in 1:length(sel_clust_names)){ sel_clusts[[i]] &lt;- css_results$clusters[[sel_clust_names[i]]] names(sel_clusts)[i] &lt;- sel_clust_names[i] } stopifnot(is.list(sel_clusts)) stopifnot(length(sel_clusts) == length(sel_clust_names)) # sel_results$selected_feats is guaranteed to have length at least as long # as sel_results$selected_clusts by getSelectedClusters return(list(selected_clusts=sel_clusts, selected_feats=sel_results$selected_feats, weights=sel_results$weights)) } checkCutoff(): #&#39; Helper function to confirm that the argument cutoff to several functions is #&#39; as expected #&#39; #&#39; @param cutoff Numeric; only those clusters with selection proportions equal #&#39; to at least cutoff will be selected by cluster stability selection. Must be #&#39; between 0 and 1. #&#39; @author Gregory Faletto, Jacob Bien checkCutoff &lt;- function(cutoff){ stopifnot(is.numeric(cutoff) | is.integer(cutoff)) stopifnot(length(cutoff) == 1) stopifnot(!is.na(cutoff)) stopifnot(cutoff &gt;= 0) stopifnot(cutoff &lt;= 1) } Tests for checkCutoff(): testthat::test_that(&quot;checkCutoff works&quot;, { testthat::expect_null(checkCutoff(0)) testthat::expect_null(checkCutoff(0.2)) testthat::expect_null(checkCutoff(1)) testthat::expect_error(checkCutoff(-.2), &quot;cutoff &gt;= 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkCutoff(2), &quot;cutoff &lt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkCutoff(&quot;.3&quot;), &quot;is.numeric(cutoff) | is.integer(cutoff) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkCutoff(matrix(1:12, nrow=4, ncol=3)), &quot;length(cutoff) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkCutoff(numeric()), &quot;length(cutoff) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkCutoff(as.numeric(NA)), &quot;!is.na(cutoff) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 😀 checkWeighting(): #&#39; Helper function to confirm that the argument weighting to several #&#39; functions is as expected #&#39; #&#39; @param weighting Character; determines how to calculate the weights to #&#39; combine features from the selected clusters into weighted averages, called #&#39; cluster representatives. Must be one of &quot;sparse&quot;, &quot;weighted_avg&quot;, or #&#39; &quot;simple_avg&#39;. #&#39; @author Gregory Faletto, Jacob Bien checkWeighting &lt;- function(weighting){ stopifnot(length(weighting)==1) stopifnot(!is.na(weighting)) if(!is.character(weighting)){ stop(&quot;Weighting must be a character&quot;) } if(!(weighting %in% c(&quot;sparse&quot;, &quot;simple_avg&quot;, &quot;weighted_avg&quot;))){ stop(&quot;Weighting must be a character and one of sparse, simple_avg, or weighted_avg&quot;) } } Tests for checkWeighting(): testthat::test_that(&quot;checkWeighting works&quot;, { testthat::expect_null(checkWeighting(&quot;sparse&quot;)) testthat::expect_null(checkWeighting(&quot;simple_avg&quot;)) testthat::expect_null(checkWeighting(&quot;weighted_avg&quot;)) testthat::expect_error(checkWeighting(c(&quot;sparse&quot;, &quot;simple_avg&quot;)), &quot;length(weighting) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkWeighting(NA), &quot;!is.na(weighting) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkWeighting(1), &quot;Weighting must be a character&quot;, fixed=TRUE) testthat::expect_error(checkWeighting(&quot;spasre&quot;), &quot;Weighting must be a character and one of sparse, simple_avg, or weighted_avg&quot;, fixed=TRUE) }) ## Test passed 🌈 checkMinNumClusts(): #&#39; Helper function to confirm that the argument min_num_clusts to several #&#39; functions is as expected #&#39; #&#39; @param min_num_clusts Integer or numeric; the minimum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns fewer than #&#39; min_num_clusts clusters, the cutoff will be increased until at least #&#39; min_num_clusts clusters are selected.) #&#39; @param p The number of features; since this is an upper bound on the number #&#39; of clusters of features, it is also an upper bound on min_num_clusts. #&#39; @param n_clusters The number of clusters; note that this is an upper bound #&#39; on min_num_clusts #&#39; @author Gregory Faletto, Jacob Bien checkMinNumClusts &lt;- function(min_num_clusts, p, n_clusters){ stopifnot(length(min_num_clusts) == 1) stopifnot(is.numeric(min_num_clusts) | is.integer(min_num_clusts)) stopifnot(!is.na(min_num_clusts)) stopifnot(min_num_clusts == round(min_num_clusts)) stopifnot(min_num_clusts &gt;= 1) stopifnot(min_num_clusts &lt;= p) stopifnot(min_num_clusts &lt;= n_clusters) } Tests for checkMinNumClusts(): testthat::test_that(&quot;checkMinNumClusts works&quot;, { testthat::expect_null(checkMinNumClusts(1, 5, 4)) testthat::expect_null(checkMinNumClusts(6, 6, 6)) testthat::expect_null(checkMinNumClusts(3, 1932, 3)) testthat::expect_error(checkMinNumClusts(c(2, 4), 5, 4), &quot;length(min_num_clusts) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMinNumClusts(&quot;3&quot;, &quot;1932&quot;, &quot;3&quot;), &quot;is.numeric(min_num_clusts) | is.integer(min_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMinNumClusts(NA, NA, NA), &quot;is.numeric(min_num_clusts) | is.integer(min_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMinNumClusts(as.numeric(NA), as.numeric(NA), as.numeric(NA)), &quot;!is.na(min_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMinNumClusts(0, 13, 7), &quot;min_num_clusts &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMinNumClusts(-1, 9, 8), &quot;min_num_clusts &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMinNumClusts(6, 5, 5), &quot;min_num_clusts &lt;= p is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMinNumClusts(6, 7, 5), &quot;min_num_clusts &lt;= n_clusters is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🥇 checkMaxNumClusts(): #&#39; Helper function to confirm that the argument max_num_clusts to several #&#39; functions is as expected #&#39; #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) Can be NA, in which case #&#39; max_num_clusts will be ignored. #&#39; @param min_num_clusts Integer or numeric; the minimum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns fewer than #&#39; min_num_clusts clusters, the cutoff will be increased until at least #&#39; min_num_clusts clusters are selected.) max_num_clusts must be at least as #&#39; large as min_num_clusts. #&#39; @param p The number of features; since this is an upper bound on the number #&#39; of clusters of features, it is also an upper bound on max_num_clusts. #&#39; @param n_clusters The number of clusters; note that this is an upper bound #&#39; on max_num_clusts #&#39; @return The provided max_num_clusts, coerced to an integer if needed, and #&#39; coerced to be less than or equal to the total number of clusters. #&#39; @author Gregory Faletto, Jacob Bien checkMaxNumClusts &lt;- function(max_num_clusts, min_num_clusts, p, n_clusters){ stopifnot(length(max_num_clusts) == 1) if(!is.na(max_num_clusts)){ stopifnot(is.numeric(max_num_clusts) | is.integer(max_num_clusts)) stopifnot(max_num_clusts == round(max_num_clusts)) stopifnot(max_num_clusts &gt;= 1) stopifnot(max_num_clusts &lt;= p) max_num_clusts &lt;- as.integer(min(n_clusters, max_num_clusts)) stopifnot(max_num_clusts &gt;= min_num_clusts) } return(max_num_clusts) } Tests for checkMaxNumClusts(): testthat::test_that(&quot;checkMaxNumClusts works&quot;, { testthat::expect_equal(checkMaxNumClusts(max_num_clusts=4, min_num_clusts=1, p=5, n_clusters=4), 4) testthat::expect_equal(checkMaxNumClusts(max_num_clusts=5, min_num_clusts=1, p=5, n_clusters=4), 4) testthat::expect_true(is.na(checkMaxNumClusts(max_num_clusts=NA, min_num_clusts=3, p=5, n_clusters=4))) testthat::expect_error(checkMaxNumClusts(max_num_clusts=&quot;4&quot;, min_num_clusts=1, p=5, n_clusters=4), &quot;is.numeric(max_num_clusts) | is.integer(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMaxNumClusts(max_num_clusts=3.2, min_num_clusts=2, p=5, n_clusters=4), &quot;max_num_clusts == round(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMaxNumClusts(max_num_clusts=1, min_num_clusts=2, p=5, n_clusters=4), &quot;max_num_clusts &gt;= min_num_clusts is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMaxNumClusts(max_num_clusts=c(3, 4), min_num_clusts=2, p=5, n_clusters=4), &quot;length(max_num_clusts) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMaxNumClusts(max_num_clusts=&quot;4&quot;, min_num_clusts=&quot;2&quot;, p=&quot;5&quot;, n_clusters=&quot;4&quot;), &quot;is.numeric(max_num_clusts) | is.integer(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMaxNumClusts(max_num_clusts=-1, min_num_clusts=2, p=5, n_clusters=4), &quot;max_num_clusts &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMaxNumClusts(max_num_clusts=6, min_num_clusts=2, p=5, n_clusters=4), &quot;max_num_clusts &lt;= p is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkMaxNumClusts(max_num_clusts=1, min_num_clusts=2, p=5, n_clusters=4), &quot;max_num_clusts &gt;= min_num_clusts is not TRUE&quot;, fixed=TRUE) }) ## Test passed 😀 getSelectedClusters(): #&#39; From css output, obtain names of selected clusters and selection proportions, #&#39; indices of all selected features, and weights of individual cluster members #&#39; #&#39; If cutoff is too high for at least min_num_clusts clusters to be selected, #&#39; then it will be lowered until min_num_clusts can be selected. After that, if #&#39; the cutoff is too low such that more than max_num_clusts are selected, then #&#39; the cutoff will be increased until no more than max_num_clusts are selected. #&#39; Note that because clusters can have tied selection proportions, it is #&#39; possible that the number of selected clusters will be strictly lower than #&#39; max_num_clusts or strictly greater than min_num_clusts. In fact, it is #&#39; possible that both cutoffs won&#39;t be able to be satisfied simulteaneously, #&#39; even if there is a strictly positive difference between max_num_clusts and #&#39; min_num_clusts. If this occurs, max_num_clusts will take precedence over #&#39; min_num_clusts. getSelectedClusters will throw an error if the provided #&#39; inputs don&#39;t allow it to select any clusters. #&#39; #&#39; @param css_results An object of class &quot;cssr&quot; (the output of the function #&#39; css). #&#39; @param weighting Character; determines how to calculate the weights for #&#39; individual features within the selected clusters. Only those features with #&#39; nonzero weight within the selected clusters will be returned. Must be one of #&#39; &quot;sparse&quot;, &quot;weighted_avg&quot;, or &quot;simple_avg&#39;. For &quot;sparse&quot;, all the weight is #&#39; put on the most frequently #&#39; selected individual cluster member (or divided equally among all the clusters #&#39; that are tied for the top selection proportion if there is a tie). For #&#39; &quot;weighted_avg&quot;, only the features within a selected cluster that were #&#39; themselves selected on at least one subsample will have nonzero weight. For #&#39; &quot;simple_avg&quot;, each cluster member gets equal weight regardless of the #&#39; individual feature selection proportions (that is, all cluster members within #&#39; each selected cluster will be returned.). See Faletto and Bien (2022) for #&#39; details. #&#39; @param cutoff Numeric; getCssSelections will select and return only of those #&#39; clusters with selection proportions equal to at least cutoff. Must be between #&#39; 0 and 1. #&#39; @param min_num_clusts Integer or numeric; the minimum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns fewer than #&#39; min_num_clusts clusters, the cutoff will be increased until at least #&#39; min_num_clusts clusters are selected.) #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) If NA, max_num_clusts is ignored. #&#39; @return A named list with the following elements: \\item{selected_clusts}{A #&#39; named numeric vector containing the selection proportions for the selected #&#39; clusters. The name of each entry is the name of the corresponding cluster.} #&#39; \\item{selected_feats}{A named integer vector; the indices of the features #&#39; with nonzero weights from all of the selected clusters.} \\item{weights}{A #&#39; named list of the same length as the number of selected clusters. Each list #&#39; element weights[[j]] is a numeric vector of the weights to use for the jth #&#39; selected cluster, and it has the same name as the cluster it corresponds #&#39; to.} #&#39; @author Gregory Faletto, Jacob Bien getSelectedClusters &lt;- function(css_results, weighting, cutoff, min_num_clusts, max_num_clusts){ # Check input stopifnot(class(css_results) == &quot;cssr&quot;) # Eliminate clusters with selection proportions below cutoff clus_sel_props &lt;- colMeans(css_results$clus_sel_mat) # Get selected clusters selected_clusts &lt;- clus_sel_props[clus_sel_props &gt;= cutoff] B &lt;- nrow(css_results$feat_sel_mat) # Check that selected_clusts has length at least min_num_clusts while(length(selected_clusts) &lt; min_num_clusts){ cutoff &lt;- cutoff - 1/B selected_clusts &lt;- clus_sel_props[clus_sel_props &gt;= cutoff] } # Check that selected_clusts has length at most max_num_clusts if(!is.na(max_num_clusts)){ n_clusters &lt;- ncol(css_results$clus_sel_mat) while(length(selected_clusts) &gt; max_num_clusts){ cutoff &lt;- cutoff + 1/B if(cutoff &gt; 1){ break } # Make sure we don&#39;t reduce to a selected set of size 0 if(any(clus_sel_props &gt;= cutoff)){ selected_clusts &lt;- clus_sel_props[clus_sel_props &gt;= cutoff] } else{ break } } } stopifnot(length(selected_clusts) &gt;= 1) clust_names &lt;- names(selected_clusts) n_sel_clusts &lt;- length(selected_clusts) # Check that n_sel_clusts is as expected, and throw warnings or an error if # not checkSelectedClusters(n_sel_clusts, min_num_clusts, max_num_clusts, max(clus_sel_props)) ### Get selected features from selected clusters clusters &lt;- css_results$clusters stopifnot(all(clust_names %in% names(clusters))) # Get a list of weights for all of the selected clusters weights &lt;- getAllClustWeights(css_results, selected_clusts, weighting) # Get selected features from each cluster (those features with nonzero # weights) selected_feats &lt;- integer() for(i in 1:n_sel_clusts){ clus_i_name &lt;- clust_names[i] clust_i &lt;- clusters[[clus_i_name]] weights_i &lt;- weights[[i]] selected_feats &lt;- c(selected_feats, clust_i[weights_i != 0]) } feat_names &lt;- colnames(css_results$feat_sel_mat) names(selected_feats) &lt;- feat_names[selected_feats] # Check output (already checked weights wihin getAllClustWeights) checkGetSelectedClustersOutput(selected_clusts, selected_feats, weights, n_clusters=length(clusters), p=ncol(css_results$feat_sel_mat)) return(list(selected_clusts=selected_clusts, selected_feats=selected_feats, weights=weights)) } checkSelectedClusters(): #&#39; Helper function to check operations within getSelectedClusters function #&#39; #&#39; @param n_sel_clusts The number of selected clusters; should be constrained #&#39; by min_num_clusts and max_num_clusts (though it may not be possible to #&#39; satisfy both constraints simulteneously, in which case a warning will be #&#39; thrown). #&#39; @param min_num_clusts Integer or numeric; the minimum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns fewer than #&#39; min_num_clusts clusters, the cutoff will be increased until at least #&#39; min_num_clusts clusters are selected.) #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) If NA, max_num_clusts is ignored. #&#39; @param max_sel_prop Numeric; the maximum selection proportion observed for #&#39; any cluster. #&#39; @author Gregory Faletto, Jacob Bien checkSelectedClusters &lt;- function(n_sel_clusts, min_num_clusts, max_num_clusts, max_sel_prop){ if(n_sel_clusts == 0){ err &lt;- paste(&quot;No clusters selected with this cutoff (try a cutoff below the maximum cluster selection proportion, &quot;, max_sel_prop, &quot;)&quot;, sep=&quot;&quot;) stop(err) } stopifnot(n_sel_clusts &gt;= 1) # It may be impossible to get at least min_num_clusts or at most # max_num_clusts; if so, give a warning if(n_sel_clusts &lt; min_num_clusts){ warn &lt;- paste(&quot;Returning fewer than min_num_clusts = &quot;, min_num_clusts, &quot; clusters because decreasing the cutoff any further would require returning more than max_num_clusts = &quot;, max_num_clusts, &quot; clusters&quot;, sep=&quot;&quot;) warning(warn) } if(!is.na(max_num_clusts)){ if(n_sel_clusts &gt; max_num_clusts){ warn &lt;- paste(&quot;Returning more than max_num_clusts = &quot;, max_num_clusts, &quot; clusters because increasing the cutoff any further would require returning 0 clusters&quot;, sep=&quot;&quot;) warning(warn) } } } Test for checkSelectedClusters(): testthat::test_that(&quot;checkSelectedClusters works&quot;, { testthat::expect_null(checkSelectedClusters(n_sel_clusts=5, min_num_clusts=1, max_num_clusts=NA, max_sel_prop=.8)) testthat::expect_null(checkSelectedClusters(n_sel_clusts=5, min_num_clusts=2, max_num_clusts=5, max_sel_prop=.3)) testthat::expect_null(checkSelectedClusters(n_sel_clusts=2, min_num_clusts=2, max_num_clusts=5, max_sel_prop=.3)) testthat::expect_error(checkSelectedClusters(n_sel_clusts=0, min_num_clusts=2, max_num_clusts=5, max_sel_prop=.6), &quot;No clusters selected with this cutoff (try a cutoff below the maximum cluster selection proportion, 0.6)&quot;, fixed=TRUE) testthat::expect_warning(checkSelectedClusters(n_sel_clusts=1, min_num_clusts=2, max_num_clusts=5, max_sel_prop=.6), &quot;Returning fewer than min_num_clusts = 2 clusters because decreasing the cutoff any further would require returning more than max_num_clusts = 5 clusters&quot;, fixed=TRUE) testthat::expect_warning(checkSelectedClusters(n_sel_clusts=6, min_num_clusts=2, max_num_clusts=5, max_sel_prop=.6), &quot;Returning more than max_num_clusts = 5 clusters because increasing the cutoff any further would require returning 0 clusters&quot;, fixed=TRUE) }) ## Test passed 🥇 getAllClustWeights(): #&#39; Calculate weights for each cluster member of all of the selected clusters. #&#39; #&#39; @param css_results An object of class &quot;cssr&quot; (the output of the function #&#39; css). #&#39; @param sel_clusters A named numeric vector containing the selection #&#39; proportions for the selected clusters. The name of each entry is the name #&#39; of the corresponding cluster. #&#39; @param weighting Character; determines how to calculate the weights for #&#39; individual features within the selected clusters. Only those features with #&#39; nonzero weight within the selected clusters will be returned. Must be one of #&#39; &quot;sparse&quot;, &quot;weighted_avg&quot;, or &quot;simple_avg&#39;. For &quot;sparse&quot;, all the weight is #&#39; put on the most frequently #&#39; selected individual cluster member (or divided equally among all the clusters #&#39; that are tied for the top selection proportion if there is a tie). For #&#39; &quot;weighted_avg&quot;, only the features within a selected cluster that were #&#39; themselves selected on at least one subsample will have nonzero weight. For #&#39; &quot;simple_avg&quot;, each cluster member gets equal weight regardless of the #&#39; individual feature selection proportions (that is, all cluster members within #&#39; each selected cluster will be returned.). See Faletto and Bien (2022) for #&#39; details. #&#39; @return A named list of the same length as sel_clusters of numeric vectors. #&#39; weights[[j]] is the weights to use for the jth selected cluster, and it has #&#39; the same name as the cluster it corresponds to. #&#39; @author Gregory Faletto, Jacob Bien getAllClustWeights &lt;- function(css_results, sel_clusters, weighting){ # Check inputs stopifnot(class(css_results) == &quot;cssr&quot;) stopifnot(is.numeric(sel_clusters)) p_ret &lt;- length(sel_clusters) stopifnot(length(unique(names(sel_clusters))) == p_ret) stopifnot(p_ret &gt; 0) checkWeighting(weighting) # Get selection proportions and clusters feat_sel_props &lt;- colMeans(css_results$feat_sel_mat) p &lt;- length(feat_sel_props) stopifnot(p &gt;= p_ret) clusters &lt;- css_results$clusters stopifnot(all(names(sel_clusters) %in% names(clusters))) # Identify weights weights &lt;- list() for(j in 1:p_ret){ # Find the members of the cluster feature j is a member of cluster_j &lt;- clusters[[names(sel_clusters)[j]]] # Get the weights for this cluster and add them to the list weights[[j]] &lt;- getClustWeights(cluster_j, weighting, feat_sel_props) } # Add names to weights names(weights) &lt;- names(sel_clusters) # Check output stopifnot(length(weights) == p_ret) stopifnot(is.list(weights)) for(i in 1:p_ret){ stopifnot(length(clusters[[names(sel_clusters)[i]]]) == length(weights[[i]])) stopifnot(all(weights[[i]] &gt;= 0)) stopifnot(all(weights[[i]] &lt;= 1)) stopifnot(abs(sum(weights[[i]]) - 1) &lt; 10^(-6)) } return(weights) } getClustWeights(): #&#39; Calculate weights for members of a cluster using selection proportions #&#39; #&#39; Given a cluster of features, the selection proportions for each cluster #&#39; member, and a specified weighting scheme, calculate the appropriate weights #&#39; for the cluster. #&#39; @param cluster_i An integer vector containing the indices of the members #&#39; of a cluster. #&#39; @param weighting Character; determines how to calculate the weights for #&#39; individual features within the selected clusters. Only those features with #&#39; nonzero weight within the selected clusters will be returned. Must be one of #&#39; &quot;sparse&quot;, &quot;weighted_avg&quot;, or &quot;simple_avg&#39;. For &quot;sparse&quot;, all the weight is #&#39; put on the most frequently #&#39; selected individual cluster member (or divided equally among all the clusters #&#39; that are tied for the top selection proportion if there is a tie). For #&#39; &quot;weighted_avg&quot;, only the features within a selected cluster that were #&#39; themselves selected on at least one subsample will have nonzero weight. For #&#39; &quot;simple_avg&quot;, each cluster member gets equal weight regardless of the #&#39; individual feature selection proportions (that is, all cluster members within #&#39; each selected cluster will be returned.). See Faletto and Bien (2022) for #&#39; details. #&#39; @param feat_sel_props A numeric vector of selection proportions corresponding #&#39; to each of the p features. #&#39; @return A numeric vector of the same length as cluster_i containing the #&#39; weights corresponding to each of the features in cluster_i. The weights #&#39; will all be nonnegative and sum to 1. #&#39; @author Gregory Faletto, Jacob Bien getClustWeights &lt;- function(cluster_i, weighting, feat_sel_props){ stopifnot(is.integer(cluster_i) | is.numeric(cluster_i)) stopifnot(all(cluster_i == round(cluster_i))) n_weights &lt;- length(cluster_i) stopifnot(length(unique(cluster_i)) == n_weights) p &lt;- length(feat_sel_props) stopifnot(all(cluster_i %in% 1:p)) # Get the selection proportions of each cluster member sel_props &lt;- feat_sel_props[cluster_i] stopifnot(all(sel_props &gt;= 0)) stopifnot(all(sel_props &lt;= 1)) weights_i &lt;- rep(as.numeric(NA), n_weights) # Weighted or simple average? if(weighting == &quot;sparse&quot;){ # Sparse cluster stability selection: All features in cluster with # selection proportion equal to the max # for the cluster get equal weight; rest of cluster gets 0 weight if(sum(sel_props) == 0){ weights_i &lt;- rep(1/n_weights, n_weights) } else{ maxes &lt;- sel_props==max(sel_props) stopifnot(sum(maxes) &gt; 0) stopifnot(sum(maxes) &lt;= n_weights) weights_i &lt;- rep(0, n_weights) weights_i[maxes] &lt;- 1/sum(maxes) } } else if(weighting == &quot;weighted_avg&quot;){ # Get weights for weighted average if(sum(sel_props) == 0){ weights_i &lt;- rep(1/n_weights, n_weights) } else{ weights_i &lt;- sel_props/sum(sel_props) } } else if(weighting == &quot;simple_avg&quot;){ weights_i &lt;- rep(1/n_weights, n_weights) } else{ stop(&quot;weighting must be one of sparse, simple_avg, or weighted_avg&quot;) } stopifnot(abs(sum(weights_i) - 1) &lt; 10^(-6)) stopifnot(length(weights_i) == n_weights) stopifnot(length(weights_i) &gt;= 1) stopifnot(all(weights_i &gt;= 0)) stopifnot(all(weights_i &lt;= 1)) return(weights_i) } Tests for getClustWeights(): testthat::test_that(&quot;getClustWeights works&quot;, { sel_props &lt;- c(0.1, 0.3, 0.5, 0.7, 0.9) # sparse testthat::expect_identical(getClustWeights(cluster_i=c(3L, 4L, 5L), weighting=&quot;sparse&quot;, feat_sel_props=sel_props), c(0, 0, 1)) # weighted_avg cluster=c(1L, 3L, 5L) true_weights &lt;- sel_props[cluster]/sum(sel_props[cluster]) testthat::expect_identical(getClustWeights(cluster_i=cluster, weighting=&quot;weighted_avg&quot;, feat_sel_props=sel_props), true_weights) # simple_avg testthat::expect_identical(getClustWeights(cluster_i=c(2L, 3L, 4L, 5L), weighting=&quot;simple_avg&quot;, feat_sel_props=sel_props), rep(0.25, 4)) }) ## Test passed 🥳 Tests for getAllClustWeights(): testthat::test_that(&quot;getAllClustWeights works&quot;, { set.seed(1872) x &lt;- matrix(stats::rnorm(10*5), nrow=10, ncol=5) y &lt;- stats::rnorm(10) clust_names &lt;- letters[1:3] good_clusters &lt;- list(1:2, 3:4, 5) names(good_clusters) &lt;- clust_names res &lt;- css(X=x, y=y, lambda=0.01, clusters=good_clusters, fitfun = cssLasso, sampling_type = &quot;SS&quot;, B = 10, prop_feats_remove = 0, train_inds = integer(), num_cores = 1L) sel_props &lt;- colMeans(res$feat_sel_mat) sel_clusts &lt;- list(1L:2L, 3L:4L) names(sel_clusts) &lt;- clust_names[1:2] # sparse true_weights &lt;- list() for(i in 1:2){ weights_i &lt;- sel_props[sel_clusts[[i]]]/sum(sel_props[sel_clusts[[i]]]) true_weights[[i]] &lt;- rep(0, length(weights_i)) true_weights[[i]][weights_i == max(weights_i)] &lt;- 1 true_weights[[i]] &lt;- true_weights[[i]]/sum(true_weights[[i]]) } names(true_weights) &lt;- clust_names[1:2] testthat::expect_identical(getAllClustWeights(res, colMeans(res$clus_sel_mat[, 1:2]), &quot;sparse&quot;), true_weights) # weighted_avg true_weights &lt;- list() for(i in 1:2){ true_weights[[i]] &lt;- sel_props[sel_clusts[[i]]]/sum(sel_props[unlist(sel_clusts[[i]])]) } names(true_weights) &lt;- clust_names[1:2] testthat::expect_identical(getAllClustWeights(res, colMeans(res$clus_sel_mat[, 1:2]), &quot;weighted_avg&quot;), true_weights) # simple_avg true_weights &lt;- list() for(i in 1:2){ n_weights_i &lt;- length(sel_clusts[[i]]) true_weights[[i]] &lt;- rep(1/n_weights_i, n_weights_i) } names(true_weights) &lt;- clust_names[1:2] testthat::expect_identical(getAllClustWeights(res, colMeans(res$clus_sel_mat[, 1:2]), &quot;simple_avg&quot;), true_weights) # Errors # css_results not correct (error has quotation marks) testthat::expect_error(getAllClustWeights(1:4, colMeans(res$clus_sel_mat[, 1:2]), &quot;simple_avg&quot;)) bad_sel_clusts &lt;- colMeans(res$clus_sel_mat[, 1:2]) names(bad_sel_clusts) &lt;- c(&quot;apple&quot;, &quot;banana&quot;) testthat::expect_error(getAllClustWeights(res, bad_sel_clusts, &quot;sparse&quot;), &quot;all(names(sel_clusters) %in% names(clusters)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getAllClustWeights(res, colMeans(res$clus_sel_mat[, 1:2]), c(&quot;sparse&quot;, &quot;simple_avg&quot;)), &quot;length(weighting) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getAllClustWeights(res, colMeans(res$clus_sel_mat[, 1:2]), NA), &quot;!is.na(weighting) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getAllClustWeights(res, colMeans(res$clus_sel_mat[, 1:2]), 1), &quot;Weighting must be a character&quot;, fixed=TRUE) testthat::expect_error(getAllClustWeights(res, colMeans(res$clus_sel_mat[, 1:2]), &quot;spasre&quot;), &quot;Weighting must be a character and one of sparse, simple_avg, or weighted_avg&quot;, fixed=TRUE) }) ## Test passed 🥇 checkGetSelectedClustersOutput(): #&#39; Helper function to check that output of getSelectedClusters is as expected #&#39; #&#39; @param selected_clusts A named numeric vector containing the selection #&#39; proportions for the selected clusters. The name of each entry is the name of #&#39; the corresponding cluster. #&#39; @param selected_feats A named integer vector; the indices of the features #&#39; with nonzero weights from all of the selected clusters. #&#39; @param weights A named list of the same length as the number of selected #&#39; clusters. Each list element weights[[j]] is a numeric vector of the weights #&#39; to use for the jth selected cluster, and it has the same name as the cluster #&#39; it corresponds to. #&#39; @param n_clusters Integer; the number of clusters in the data (upper bound #&#39; for the length of selected_clusts) #&#39; @param p Integer; number of features in the data (all selected_feats should #&#39; be in 1:p) #&#39; @author Gregory Faletto, Jacob Bien checkGetSelectedClustersOutput &lt;- function(selected_clusts, selected_feats, weights, n_clusters, p){ stopifnot(is.numeric(selected_clusts)) stopifnot(all(selected_clusts &gt;= 0)) stopifnot(all(selected_clusts &lt;= 1)) stopifnot(length(selected_clusts) &gt;= 1) stopifnot(length(selected_clusts) &lt;= n_clusters) stopifnot(length(names(selected_clusts)) == length(unique(names(selected_clusts)))) stopifnot(!is.null(names(selected_clusts))) stopifnot(all(!is.na(names(selected_clusts)) &amp; names(selected_clusts) != &quot;&quot;)) stopifnot(length(names(selected_clusts)) == length(selected_clusts)) stopifnot(is.integer(selected_feats)) stopifnot(length(selected_feats) == length(unique(selected_feats))) stopifnot(all(selected_feats %in% 1:p)) stopifnot(length(selected_clusts) &lt;= length(selected_feats)) stopifnot(identical(names(weights), names(selected_clusts))) stopifnot(length(weights) == length(selected_clusts)) } Tests for checkGetSelectedClustersOutput(): testthat::test_that(&quot;checkGetSelectedClustersOutput works&quot;, { sel_clusts &lt;- 0.1*(1:9) names(sel_clusts) &lt;- letters[1:9] weights &lt;- list() for(i in 1:8){ weights[[i]] &lt;- c(0.2, 0.3) } weights[[9]] &lt;- 0.4 names(weights) &lt;- letters[1:9] sel_feats &lt;- 10:26 names(sel_feats) &lt;- LETTERS[10:26] testthat::expect_null(checkGetSelectedClustersOutput(selected_clusts=sel_clusts, selected_feats=sel_feats, weights=weights, n_clusters=10, p=30)) testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=letters[1:4], selected_feats=sel_feats, weights=weights, n_clusters=10, p=30), &quot;is.numeric(selected_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=-sel_clusts, selected_feats=sel_feats, weights=weights, n_clusters=10, p=30), &quot;all(selected_clusts &gt;= 0) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=10*sel_clusts, selected_feats=sel_feats, weights=weights, n_clusters=10, p=30), &quot;all(selected_clusts &lt;= 1) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=numeric(), selected_feats=sel_feats, weights=weights, n_clusters=10, p=30), &quot;length(selected_clusts) &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=sel_clusts, selected_feats=sel_feats, weights=weights, n_clusters=8, p=30), &quot;length(selected_clusts) &lt;= n_clusters is not TRUE&quot;, fixed=TRUE) bad_clusts &lt;- sel_clusts names(bad_clusts) &lt;- rep(&quot;a&quot;, length(bad_clusts)) testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=bad_clusts, selected_feats=sel_feats, weights=weights, n_clusters=10, p=30), &quot;length(names(selected_clusts)) == length(unique(names(selected_clusts))) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=unname(sel_clusts), selected_feats=sel_feats, weights=weights, n_clusters=10, p=30), &quot;!is.null(names(selected_clusts)) is not TRUE&quot;, fixed=TRUE) bad_clusts &lt;- sel_clusts names(bad_clusts)[1] &lt;- &quot;&quot; testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=bad_clusts, selected_feats=sel_feats, weights=weights, n_clusters=10, p=30), &quot;all(!is.na(names(selected_clusts)) &amp; names(selected_clusts) != .... is not TRUE&quot;, fixed=TRUE) names(bad_clusts)[1] &lt;- as.character(NA) testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=bad_clusts, selected_feats=sel_feats, weights=weights, n_clusters=10, p=30), &quot;all(!is.na(names(selected_clusts)) &amp; names(selected_clusts) != .... is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=sel_clusts, selected_feats=0.1, weights=weights, n_clusters=10, p=30), &quot;is.integer(selected_feats) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=sel_clusts, selected_feats=c(1L, rep(2L, 2)), weights=weights, n_clusters=10, p=30), &quot;length(selected_feats) == length(unique(selected_feats)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=sel_clusts, selected_feats=sel_feats, weights=weights, n_clusters=10, p=25), &quot;all(selected_feats %in% 1:p) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetSelectedClustersOutput(selected_clusts=sel_clusts, selected_feats=sel_feats[1:8], weights=weights, n_clusters=10, p=25), &quot;length(selected_clusts) &lt;= length(selected_feats) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🥇 Tests for getSelectedClusters() testthat::test_that(&quot;getSelectedClusters works&quot;, { set.seed(26717) x &lt;- matrix(stats::rnorm(10*5), nrow=10, ncol=5) y &lt;- stats::rnorm(10) good_clusters &lt;- list(&quot;apple&quot;=1:2, &quot;banana&quot;=3:4, &quot;cantaloupe&quot;=5) css_res &lt;- css(X=x, y=y, lambda=0.01, clusters=good_clusters, B = 10) res &lt;- getSelectedClusters(css_res, weighting=&quot;sparse&quot;, cutoff=0.05, min_num_clusts=1, max_num_clusts=NA) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) testthat::expect_true(length(res$selected_clusts) &lt;= length(res$selected_feats)) testthat::expect_true(is.numeric(res$selected_clusts)) testthat::expect_true(length(res$selected_clusts) &gt;= 1) testthat::expect_equal(length(names(res$selected_clusts)), length(res$selected_clusts)) testthat::expect_equal(length(names(res$selected_clusts)), length(unique(names(res$selected_clusts)))) testthat::expect_true(all(res$selected_clusts &gt;= 0)) testthat::expect_true(all(res$selected_clusts &lt;= 1)) testthat::expect_true(is.integer(res$selected_feats)) testthat::expect_true(length(res$selected_feats) &gt;= 1) testthat::expect_equal(length(names(res$selected_feats)), length(unique(names(res$selected_feats)))) testthat::expect_true(all(res$selected_feats &gt;= 1)) testthat::expect_true(all(res$selected_feats &lt;= 5)) testthat::expect_equal(length(res$selected_feats), length(unique(res$selected_feats))) testthat::expect_equal(length(res$selected_clusts), length(res$weights)) for(i in 1:length(res$weights)){ weights_i &lt;- res$weights[[i]] num_nonzero_weights &lt;- sum(weights_i &gt; 0) # For &quot;sparse&quot; weighting, either there should only be one nonzero weight and # it should equal 1 (if there were no ties in selection proportions among # cluster members) or the nonzero weights should all be # 1/num_nonzero_weights testthat::expect_true(all(weights_i[weights_i &gt; 0] == 1/num_nonzero_weights)) } # weighted_avg res_weighted &lt;- getSelectedClusters(css_res, weighting=&quot;weighted_avg&quot;, cutoff=0.05, min_num_clusts=1, max_num_clusts=NA) testthat::expect_equal(length(res_weighted$selected_clusts), length(res_weighted$weights)) for(i in 1:length(res_weighted$weights)){ weights_i &lt;- res_weighted$weights[[i]] testthat::expect_true(all(weights_i &gt;= 0)) testthat::expect_true(all(weights_i &lt;= 1)) } # simple_avg res_simple &lt;- getSelectedClusters(css_res, weighting=&quot;simple_avg&quot;, cutoff=0.05, min_num_clusts=1, max_num_clusts=NA) testthat::expect_equal(length(res_simple$selected_clusts), length(res_simple$weights)) for(i in 1:length(res_simple$weights)){ weights_i &lt;- res_simple$weights[[i]] testthat::expect_equal(length(unique(weights_i)), 1) testthat::expect_equal(length(weights_i), sum(weights_i &gt; 0)) } # Test min_num_clusts res2 &lt;- getSelectedClusters(css_res, weighting=&quot;weighted_avg&quot;, cutoff=1, min_num_clusts=3, max_num_clusts=NA) testthat::expect_true(is.list(res2)) testthat::expect_equal(length(res2$selected_clusts), 3) res3 &lt;- getSelectedClusters(css_res, weighting=&quot;sparse&quot;, cutoff=1, min_num_clusts=2, max_num_clusts=NA) testthat::expect_true(length(res3$selected_clusts) &gt;= 2) # Test max_num_clusts # Ensure there is at least one relevant feature x2 &lt;- x x2[, 5] &lt;- y css_res2 &lt;- css(X=x2, y=y, lambda=0.01, clusters=good_clusters, B = 10) res4 &lt;- getSelectedClusters(css_res2, weighting=&quot;simple_avg&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=1) testthat::expect_true(is.list(res4)) testthat::expect_equal(length(res4$selected_clusts), 1) res5 &lt;- getSelectedClusters(css_res, weighting=&quot;weighted_avg&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=2) testthat::expect_true(length(res5$selected_clusts) &lt;= 2) # Name features colnames(x) &lt;- LETTERS[1:ncol(x)] css_res3 &lt;- css(X=x, y=y, lambda=0.01, clusters=good_clusters, B = 10) res &lt;- getSelectedClusters(css_res3, weighting=&quot;sparse&quot;, cutoff=0.05, min_num_clusts=1, max_num_clusts=NA) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) testthat::expect_true(length(res$selected_clusts) &lt;= length(res$selected_feats)) testthat::expect_true(is.numeric(res$selected_clusts)) testthat::expect_true(length(res$selected_clusts) &gt;= 1) testthat::expect_equal(length(names(res$selected_clusts)), length(res$selected_clusts)) testthat::expect_equal(length(names(res$selected_clusts)), length(unique(names(res$selected_clusts)))) testthat::expect_true(all(res$selected_clusts &gt;= 0)) testthat::expect_true(all(res$selected_clusts &lt;= 1)) testthat::expect_true(is.integer(res$selected_feats)) testthat::expect_true(length(res$selected_feats) &gt;= 1) testthat::expect_equal(length(names(res$selected_feats)), length(unique(names(res$selected_feats)))) testthat::expect_true(all(res$selected_feats &gt;= 1)) testthat::expect_true(all(res$selected_feats &lt;= 5)) testthat::expect_equal(length(res$selected_feats), length(unique(res$selected_feats))) testthat::expect_equal(length(names(res$selected_feats)), length(res$selected_feats)) testthat::expect_equal(length(names(res$selected_feats)), length(unique(names(res$selected_feats)))) }) ## Test passed 🎊 Finally, tests for getCssSelections() testthat::test_that(&quot;getCssSelections works&quot;, { set.seed(26717) x &lt;- matrix(stats::rnorm(10*7), nrow=10, ncol=7) y &lt;- stats::rnorm(10) good_clusters &lt;- list(&quot;apple&quot;=1:2, &quot;banana&quot;=3:4, &quot;cantaloupe&quot;=5) css_res &lt;- css(X=x, y=y, lambda=0.01, clusters=good_clusters, B = 10) res &lt;- getCssSelections(css_res) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) testthat::expect_true(length(res$selected_clusts) &lt;= length(res$selected_feats)) testthat::expect_true(is.list(res$selected_clusts)) testthat::expect_equal(length(names(res$selected_clusts)), length(res$selected_clusts)) testthat::expect_equal(length(names(res$selected_clusts)), length(unique(names(res$selected_clusts)))) already_used_feats &lt;- integer() for(i in 1:length(res$selected_clusts)){ sels_i &lt;- res$selected_clusts[[i]] testthat::expect_true(length(sels_i) &gt;= 1) testthat::expect_true(is.integer(sels_i)) testthat::expect_true(all(sels_i %in% 1:11)) testthat::expect_equal(length(sels_i), length(unique(sels_i))) testthat::expect_equal(length(intersect(already_used_feats, sels_i)), 0) already_used_feats &lt;- c(already_used_feats, sels_i) } testthat::expect_true(length(already_used_feats) &lt;= 11) testthat::expect_equal(length(already_used_feats), length(unique(already_used_feats))) testthat::expect_true(all(already_used_feats %in% 1:11)) testthat::expect_true(is.integer(res$selected_feats)) testthat::expect_true(length(res$selected_feats) &gt;= 1) testthat::expect_equal(length(names(res$selected_feats)), length(unique(names(res$selected_feats)))) testthat::expect_true(all(res$selected_feats &gt;= 1)) testthat::expect_true(all(res$selected_feats &lt;= 7)) testthat::expect_equal(length(res$selected_feats), length(unique(res$selected_feats))) testthat::expect_equal(length(res$selected_clusts), length(res$weights)) for(i in 1:length(res$weights)){ weights_i &lt;- res$weights[[i]] num_nonzero_weights &lt;- sum(weights_i &gt; 0) # For &quot;sparse&quot; weighting, either there should only be one nonzero weight and # it should equal 1 (if there were no ties in selection proportions among # cluster members) or the nonzero weights should all be # 1/num_nonzero_weights testthat::expect_true(all(weights_i[weights_i &gt; 0] == 1/num_nonzero_weights)) } # Test min_num_clusts (should be 5 clusters--3 named ones, plus last two get # put in their own unnamed clusters automatically by css) res2 &lt;- getCssSelections(css_res, weighting=&quot;weighted_avg&quot;, cutoff=1, min_num_clusts=5, max_num_clusts=NA) testthat::expect_true(is.list(res2)) testthat::expect_equal(length(res2$selected_clusts), 5) res3 &lt;- getCssSelections(css_res, weighting=&quot;sparse&quot;, cutoff=1, min_num_clusts=3, max_num_clusts=NA) testthat::expect_true(length(res3$selected_clusts) &gt;= 3) # Test max_num_clusts # Ensure there is at least one relevant feature x2 &lt;- x x2[, 5] &lt;- y css_res2 &lt;- css(X=x2, y=y, lambda=0.01, clusters=good_clusters, B = 10) res4 &lt;- getCssSelections(css_res2, weighting=&quot;simple_avg&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=1) testthat::expect_true(is.list(res4)) testthat::expect_equal(length(res4$selected_clusts), 1) res5 &lt;- getCssSelections(css_res, weighting=&quot;weighted_avg&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=2) testthat::expect_true(length(res5$selected_clusts) &lt;= 2) # Name features colnames(x) &lt;- LETTERS[1:ncol(x)] css_res3 &lt;- css(X=x, y=y, lambda=0.01, clusters=good_clusters, B = 10) res &lt;- getCssSelections(css_res3, weighting=&quot;sparse&quot;, cutoff=0.05, min_num_clusts=1, max_num_clusts=NA) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) testthat::expect_true(length(res$selected_clusts) &lt;= length(res$selected_feats)) testthat::expect_equal(length(names(res$selected_feats)), length(res$selected_feats)) testthat::expect_equal(length(names(res$selected_feats)), length(unique(names(res$selected_feats)))) # Bad inputs # Error has quotation marks in it testthat::expect_error(getCssSelections(&quot;css_results&quot;)) testthat::expect_error(getCssSelections(css_res, weighting=&quot;spasre&quot;), &quot;Weighting must be a character and one of sparse, simple_avg, or weighted_avg&quot;, fixed=TRUE) testthat::expect_error(getCssSelections(css_res, cutoff=-.5), &quot;cutoff &gt;= 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssSelections(css_res, min_num_clusts=0), &quot;min_num_clusts &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssSelections(css_res, min_num_clusts=0), &quot;min_num_clusts &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssSelections(css_res, max_num_clusts=50), &quot;max_num_clusts &lt;= p is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssSelections(css_res, max_num_clusts=4.5), &quot;max_num_clusts == round(max_num_clusts) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🥳 getCssDesign() #&#39; Obtain a design matrix of cluster representatives #&#39; #&#39; Takes a matrix of observations from the original feature space and returns #&#39; a matrix of representatives from the selected clusters based on the results #&#39; of cluster stability selection. #&#39; @param css_results An object of class &quot;cssr&quot; (the output of the function #&#39; css). #&#39; @param newX A numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; the data that will be used to generate the design matrix of cluster #&#39; representatives. Must contain the same features (in the same #&#39; number of columns) as the X matrix provided to css, and if the columns of #&#39; newX are labeled, the names must match the variable names provided to css. #&#39; newX may be omitted if train_inds were provided to css to set aside #&#39; observations for model estimation. If this is the case, then when newX is #&#39; omitted getCssDesign will return a design matrix of cluster representatives #&#39; formed from the train_inds observations from the matrix X provided to css. #&#39; (If no train_inds were provided to css, newX must be provided to #&#39; getCssDesign.) Default is NA. #&#39; @param weighting Character; determines how to calculate the weights to #&#39; combine features from the selected clusters into weighted averages, called #&#39; cluster representatives. Must be one of &quot;sparse&quot;, &quot;weighted_avg&quot;, or #&#39; &quot;simple_avg&#39;. For &quot;sparse&quot;, all the weight is put on the most frequently #&#39; selected individual cluster member (or divided equally among all the clusters #&#39; that are tied for the top selection proportion if there is a tie). For #&#39; &quot;weighted_avg&quot;, the weight used for each cluster member is calculated in #&#39; proportion to the individual selection proportions of each feature. For #&#39; &quot;simple_avg&quot;, each cluster member gets equal weight regardless of the #&#39; individual feature selection proportions (that is, the cluster representative #&#39; is just a simple average of all the cluster members). See Faletto and Bien #&#39; (2022) for details. Default is &quot;weighted_avg&quot;. #&#39; @param cutoff Numeric; getCssDesign will only include those clusters with #&#39; selection proportions equal to at least cutoff. Must be between 0 and 1. #&#39; Default is 0 (in which case either all clusters are used, or max_num_clusts #&#39; are used, if max_num_clusts is specified). #&#39; @param min_num_clusts Integer or numeric; the minimum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns fewer than #&#39; min_num_clusts clusters, the cutoff will be increased until at least #&#39; min_num_clusts clusters are selected.) Default is 1. #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) Default is NA (in which case #&#39; max_num_clusts is ignored). #&#39; @return A design matrix with either nrow(newX) (or length(train_inds), if #&#39; train_inds was provided to css and newX was not provided to getCssDesign) #&#39; observations and number of columns equal to the number of selected clusters, #&#39; containing the cluster representatives for each cluster. #&#39; @author Gregory Faletto, Jacob Bien #&#39; @export getCssDesign &lt;- function(css_results, newX=NA, weighting=&quot;weighted_avg&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=NA){ # Check inputs stopifnot(class(css_results) == &quot;cssr&quot;) check_results &lt;- checkNewXProvided(newX, css_results) newX &lt;- check_results$newX newXProvided &lt;- check_results$newXProvided rm(check_results) n_train &lt;- nrow(newX) results &lt;- checkXInputResults(newX, css_results$X) newX &lt;- results$newx feat_names &lt;- results$feat_names rm(results) n &lt;- nrow(newX) p &lt;- ncol(newX) checkCutoff(cutoff) checkWeighting(weighting) checkMinNumClusts(min_num_clusts, p, length(css_results$clusters)) max_num_clusts &lt;- checkMaxNumClusts(max_num_clusts, min_num_clusts, p, length(css_results$clusters)) # Take provided training design matrix and testX and turn them into # matrices of cluster representatives using information from css_results if(newXProvided){ newX_clusters &lt;- formCssDesign(css_results, weighting, cutoff, min_num_clusts, max_num_clusts, newx=newX) } else{ newX_clusters &lt;- formCssDesign(css_results, weighting, cutoff, min_num_clusts, max_num_clusts) } return(newX_clusters) } checkNewXProvided() #&#39; Helper function to confirm that the new X matrix provided to getCssDesign or #&#39; getCssPreds matches the characteristics of the X that was provided to css. #&#39; #&#39; @param trainX A numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix). Must contain #&#39; the same features (in the same number of columns) as the X matrix provided to #&#39; css, and if the columns of trainX are labeled, the names must match the #&#39; variable names provided to css. trainX may be omitted if train_inds were #&#39; provided to css to set aside observations. #&#39; @param css_results An object of class &quot;cssr&quot; (the output of the function #&#39; css). #&#39; @return A named list with the following elements: \\item{newX}{If trainX was #&#39; provided, this is the provided trainX matrix, coerced from a data.frame to a #&#39; matrix if the provided trainX was a data.frame. If trainX was not provided, #&#39; this is a matrix made up of the training indices provided to css in the #&#39; train_inds argument.} \\item{newXProvided}{Logical; indicates whether a valid #&#39; trainX input was provided.} #&#39; @author Gregory Faletto, Jacob Bien checkNewXProvided &lt;- function(trainX, css_results){ newXProvided &lt;- FALSE if(all(!is.na(trainX)) &amp; length(trainX) &gt; 1){ newXProvided &lt;- TRUE trainX &lt;- checkXInputResults(trainX, css_results$X)$newx n_train &lt;- nrow(trainX) stopifnot(n_train &gt; 1) } else{ if(length(css_results$train_inds) == 0){ stop(&quot;css was not provided with indices to set aside for model training (train_inds), so must provide new X in order to generate a design matrix&quot;) } trainX &lt;- css_results$X[css_results$train_inds, ] } stopifnot(is.matrix(trainX)) stopifnot(is.numeric(trainX) | is.integer(trainX)) stopifnot(all(!is.na(trainX))) stopifnot(ncol(trainX) &gt;= 2) return(list(newX=trainX, newXProvided=newXProvided)) } checkXInputResults() #&#39; Helper function to confirm that inputs to several functions are as expected, #&#39; and modify inputs if needed #&#39; #&#39; @param newx A numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; the data that will be used to generate the design matrix of cluster #&#39; representatives. Must contain the same features (in the same #&#39; number of columns) as the X matrix provided to css, and if the columns of #&#39; newX are labeled, the names must match the variable names provided to css. #&#39; @param css_X The X matrix provided to css, as in the output of the css #&#39; function (after having been coerced from a data.frame to a matrix by css if #&#39; needed). #&#39; @return A named list with the following elements. \\item{feat_names}{A #&#39; character vector containing the column names of newx (if the provided newx #&#39; had column names). If the provided newx did not have column names, feat_names #&#39; will be NA.} \\item{newx}{The provided newx matrix, coerced from a data.frame #&#39; to a matrix if the provided newx was a data.frame.} #&#39; @author Gregory Faletto, Jacob Bien checkXInputResults &lt;- function(newx, css_X){ # Check if x is a matrix; if it&#39;s a data.frame, convert to matrix. if(is.data.frame(newx)){ newx &lt;- stats::model.matrix(~ ., newx) newx &lt;- newx[, colnames(newx) != &quot;(Intercept)&quot;] } feat_names &lt;- as.character(NA) if(!is.null(colnames(newx))){ feat_names &lt;- colnames(newx) stopifnot(identical(feat_names, colnames(css_X))) } else{ # In this case, newx has no column names, so same better be true of # css_X if(!is.null(colnames(css_X))){ warning(&quot;New X provided had no variable names (column names) even though the X provided to css did.&quot;) } } stopifnot(is.matrix(newx)) stopifnot(all(!is.na(newx))) n &lt;- nrow(newx) p &lt;- ncol(newx) stopifnot(p &gt;= 2) if(length(feat_names) &gt; 1){ stopifnot(length(feat_names) == p) stopifnot(!(&quot;(Intercept)&quot; %in% feat_names)) } else{ stopifnot(is.na(feat_names)) } colnames(newx) &lt;- character() # Confirm that newx matches css_results$X if(p != ncol(css_X)){ err &lt;- paste(&quot;Number of columns in newx must match number of columns from matrix provided to css. Number of columns in new provided X: &quot;, p, &quot;. Number of columns in matrix provided to css: &quot;, ncol(css_X), &quot;.&quot;, sep=&quot;&quot;) stop(err) } if(length(feat_names) != 1 &amp; all(!is.na(feat_names))){ if(!identical(feat_names, colnames(css_X))){ stop(&quot;Provided feature names for newx do not match feature names provided to css&quot;) } } return(list(feat_names=feat_names, newx=newx)) } Tests for checkXInputResults() testthat::test_that(&quot;checkXInputResults works&quot;, { set.seed(72617) x_select &lt;- matrix(stats::rnorm(10*5), nrow=10, ncol=5) x_new &lt;- matrix(stats::rnorm(8*5), nrow=8, ncol=5) y_select &lt;- stats::rnorm(10) y_new &lt;- stats::rnorm(8) good_clusters &lt;- list(&quot;red&quot;=1:2, &quot;blue&quot;=3:4, &quot;green&quot;=5) css_res &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) res &lt;- checkXInputResults(x_new, css_res$X) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;feat_names&quot;, &quot;newx&quot;)) testthat::expect_true(is.character(res$feat_names)) testthat::expect_true(is.na(res$feat_names)) testthat::expect_true(is.numeric(res$newx)) testthat::expect_true(is.matrix(res$newx)) testthat::expect_equal(nrow(res$newx), 8) testthat::expect_equal(ncol(res$newx), 5) testthat::expect_null(colnames(res$newx)) # Try naming variables colnames(x_select) &lt;- LETTERS[1:5] css_res_named &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) # Named variables for css matrix but not new one--should get a warning testthat::expect_warning(checkXInputResults(x_new, css_res_named$X), &quot;New X provided had no variable names (column names) even though the X provided to css did.&quot;, fixed=TRUE) # Try mismatching variable names colnames(x_new) &lt;- LETTERS[2:6] testthat::expect_error(checkXInputResults(x_new, css_res_named$X), &quot;identical(feat_names, colnames(css_X)) is not TRUE&quot;, fixed=TRUE) colnames(x_new) &lt;- LETTERS[1:5] res_named &lt;- checkXInputResults(x_new, css_res_named$X) testthat::expect_true(is.list(res_named)) testthat::expect_identical(names(res_named), c(&quot;feat_names&quot;, &quot;newx&quot;)) testthat::expect_true(is.character(res_named$feat_names)) testthat::expect_identical(res_named$feat_names, LETTERS[1:5]) # Try data.frame input to css and checkXInputResults X_df &lt;- datasets::mtcars n &lt;- nrow(X_df) y &lt;- stats::rnorm(n) selec_inds &lt;- 1:round(n/2) fit_inds &lt;- setdiff(1:n, selec_inds) css_res_df &lt;- css(X=X_df[selec_inds, ], y=y[selec_inds], lambda=0.01, B = 10) res_df &lt;- checkXInputResults(X_df[fit_inds, ], css_res_df$X) testthat::expect_true(is.list(res_df)) testthat::expect_identical(names(res_df), c(&quot;feat_names&quot;, &quot;newx&quot;)) testthat::expect_true(is.character(res_df$feat_names)) testthat::expect_identical(res_df$feat_names, colnames(css_res_df$X)) testthat::expect_identical(res_df$feat_names, colnames(X_df)) testthat::expect_true(is.numeric(res_df$newx)) testthat::expect_true(is.matrix(res_df$newx)) testthat::expect_null(colnames(res_df$newx)) testthat::expect_equal(ncol(res_df$newx), ncol(css_res_df$X)) # Try again with X as a dataframe with factors (number of columns of final # design matrix after one-hot encoding factors won&#39;t match number of columns # of X_df) # cyl, gear, and carb are factors with more than 2 levels X_df$cyl &lt;- as.factor(X_df$cyl) X_df$vs &lt;- as.factor(X_df$vs) X_df$am &lt;- as.factor(X_df$am) X_df$gear &lt;- as.factor(X_df$gear) X_df$carb &lt;- as.factor(X_df$carb) css_res_df &lt;- css(X=X_df[selec_inds, ], y=y[selec_inds], lambda=0.01, B = 10) res_df &lt;- checkXInputResults(X_df[fit_inds, ], css_res_df$X) testthat::expect_true(is.list(res_df)) testthat::expect_identical(names(res_df), c(&quot;feat_names&quot;, &quot;newx&quot;)) testthat::expect_true(is.character(res_df$feat_names)) testthat::expect_identical(res_df$feat_names, colnames(css_res_df$X)) mat &lt;- model.matrix( ~., X_df) mat &lt;- mat[, colnames(mat) != &quot;(Intercept)&quot;] testthat::expect_identical(res_df$feat_names, colnames(mat)) testthat::expect_true(is.numeric(res_df$newx)) testthat::expect_true(is.matrix(res_df$newx)) testthat::expect_null(colnames(res_df$newx)) testthat::expect_equal(ncol(res_df$newx), ncol(css_res_df$X)) }) ## Test passed 🌈 Tests for checkNewXProvided() testthat::test_that(&quot;checkNewXProvided works&quot;, { set.seed(2673) x_select &lt;- matrix(stats::rnorm(10*5), nrow=10, ncol=5) x_new &lt;- matrix(stats::rnorm(8*5), nrow=8, ncol=5) y_select &lt;- stats::rnorm(10) y_new &lt;- stats::rnorm(8) good_clusters &lt;- list(&quot;red&quot;=1:2, &quot;blue&quot;=3:4, &quot;green&quot;=5) css_res &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) res &lt;- checkNewXProvided(x_new, css_res) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;newX&quot;, &quot;newXProvided&quot;)) testthat::expect_true(is.numeric(res$newX)) testthat::expect_true(is.matrix(res$newX)) testthat::expect_equal(nrow(res$newX), 8) testthat::expect_equal(ncol(res$newX), 5) testthat::expect_null(colnames(res$newX)) testthat::expect_true(is.logical(res$newXProvided)) testthat::expect_equal(length(res$newXProvided), 1) testthat::expect_true(!is.na(res$newXProvided)) testthat::expect_true(res$newXProvided) # Add training indices css_res_train &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10, train_inds=6:10) # Training indices should be ignored if new x is provided res &lt;- checkNewXProvided(x_new, css_res_train) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;newX&quot;, &quot;newXProvided&quot;)) testthat::expect_true(all(abs(x_new - res$newX) &lt; 10^(-9))) testthat::expect_true(res$newXProvided) # Things should still work if new x is not provided res &lt;- checkNewXProvided(NA, css_res_train) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;newX&quot;, &quot;newXProvided&quot;)) testthat::expect_true(is.numeric(res$newX)) testthat::expect_true(is.matrix(res$newX)) testthat::expect_equal(nrow(res$newX), 5) testthat::expect_equal(ncol(res$newX), 5) testthat::expect_null(colnames(res$newX)) testthat::expect_false(res$newXProvided) # Try not providing training indices and omitting newx--should get error testthat::expect_error(checkNewXProvided(NA, css_res), &quot;css was not provided with indices to set aside for model training (train_inds), so must provide new X in order to generate a design matrix&quot;, fixed=TRUE) # Try naming variables colnames(x_select) &lt;- LETTERS[1:5] css_res_named &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) # Named variables for css matrix but not new one--should get a warning testthat::expect_warning(checkNewXProvided(x_new, css_res_named), &quot;New X provided had no variable names (column names) even though the X provided to css did.&quot;, fixed=TRUE) # Try mismatching variable names colnames(x_new) &lt;- LETTERS[2:6] testthat::expect_error(checkNewXProvided(x_new, css_res_named), &quot;identical(feat_names, colnames(css_X)) is not TRUE&quot;, fixed=TRUE) colnames(x_new) &lt;- LETTERS[1:5] res_named &lt;- checkNewXProvided(x_new, css_res_named) testthat::expect_true(is.list(res_named)) testthat::expect_identical(names(res_named), c(&quot;newX&quot;, &quot;newXProvided&quot;)) testthat::expect_true(all(abs(x_new - res_named$newX) &lt; 10^(-9))) testthat::expect_true(res_named$newXProvided) # Try data.frame input to css and checkNewXProvided X_df &lt;- datasets::mtcars n &lt;- nrow(X_df) y &lt;- stats::rnorm(n) selec_inds &lt;- 1:round(n/2) fit_inds &lt;- setdiff(1:n, selec_inds) css_res_df &lt;- css(X=X_df[selec_inds, ], y=y[selec_inds], lambda=0.01, B = 10) res_df &lt;- checkNewXProvided(X_df[fit_inds, ], css_res_df) testthat::expect_true(is.list(res_df)) testthat::expect_identical(names(res_df), c(&quot;newX&quot;, &quot;newXProvided&quot;)) testthat::expect_true(is.numeric(res_df$newX)) testthat::expect_true(is.matrix(res_df$newX)) testthat::expect_equal(nrow(res_df$newX), length(fit_inds)) testthat::expect_equal(ncol(res_df$newX), ncol(css_res_df$X)) testthat::expect_null(colnames(res_df$newX)) testthat::expect_true(is.logical(res_df$newXProvided)) testthat::expect_equal(length(res_df$newXProvided), 1) testthat::expect_true(!is.na(res_df$newXProvided)) testthat::expect_true(res_df$newXProvided) # Try again with X as a dataframe with factors (number of columns of final # design matrix after one-hot encoding factors won&#39;t match number of columns # of X_df) X_df$cyl &lt;- as.factor(X_df$cyl) X_df$vs &lt;- as.factor(X_df$vs) X_df$am &lt;- as.factor(X_df$am) X_df$gear &lt;- as.factor(X_df$gear) X_df$carb &lt;- as.factor(X_df$carb) css_res_df &lt;- css(X=X_df[selec_inds, ], y=y[selec_inds], lambda=0.01, B = 10) res_df &lt;- checkNewXProvided(X_df[fit_inds, ], css_res_df) testthat::expect_true(is.list(res_df)) testthat::expect_identical(names(res_df), c(&quot;newX&quot;, &quot;newXProvided&quot;)) testthat::expect_true(is.numeric(res_df$newX)) testthat::expect_true(is.matrix(res_df$newX)) testthat::expect_equal(nrow(res_df$newX), length(fit_inds)) testthat::expect_equal(ncol(res_df$newX), ncol(css_res_df$X)) testthat::expect_null(colnames(res_df$newX)) testthat::expect_true(is.logical(res_df$newXProvided)) testthat::expect_equal(length(res_df$newXProvided), 1) testthat::expect_true(!is.na(res_df$newXProvided)) testthat::expect_true(res_df$newXProvided) }) ## Test passed 😀 formCssDesign(): #&#39; Create design matrix of cluster representatives from matrix of raw features #&#39; using results of css function #&#39; #&#39; @param css_results An object of class &quot;cssr&quot; (the output of the function #&#39; css). #&#39; @param weighting Character; determines how to calculate the weights to #&#39; combine features from the selected clusters into weighted averages, called #&#39; cluster representatives. Must be one of &quot;sparse&quot;, &quot;weighted_avg&quot;, or #&#39; &quot;simple_avg&#39;. For &quot;sparse&quot;, all the weight is put on the most frequently #&#39; selected individual cluster member (or divided equally among all the clusters #&#39; that are tied for the top selection proportion if there is a tie). For #&#39; &quot;weighted_avg&quot;, the weight used for each cluster member is calculated in #&#39; proportion to the individual selection proportions of each feature. For #&#39; &quot;simple_avg&quot;, each cluster member gets equal weight regardless of the #&#39; individual feature selection proportions (that is, the cluster representative #&#39; is just a simple average of all the cluster members). See Faletto and Bien #&#39; (2022) for details. Default is &quot;weighted_avg&quot;. #&#39; @param cutoff Numeric; css will return only those clusters with selection #&#39; proportions equal to at least cutoff. Must be between 0 and 1. Default is 0 #&#39; (in which case all clusters are returned in decreasing order of selection #&#39; proportion). #&#39; @param min_num_clusts Integer or numeric; the minimum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns fewer than #&#39; min_num_clusts clusters, the cutoff will be increased until at least #&#39; min_num_clusts clusters are selected.) Default is 1. #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) Default is NA (in which case #&#39; max_num_clusts is ignored). #&#39; @param newx A numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; the data that will be used to generate the design matrix of cluster #&#39; representatives. Must contain the same features (in the same #&#39; number of columns) as the X matrix provided to css, and if the columns of #&#39; newx are labeled, the names must match the variable names provided to css. #&#39; newx may be omitted if train_inds were provided to css to set aside #&#39; observations for model estimation. If this is the case, then when newx is #&#39; omitted formCssDesign will return a design matrix of cluster representatives #&#39; formed from the train_inds observations from the matrix X provided to css. #&#39; (If no train_inds were provided to css, newX must be provided to #&#39; formCssDesign.) Default is NA. #&#39; @return A design matrix with the same number of rows as newx (or the #&#39; train_inds provided to css) where the columns are the constructed cluster #&#39; representatives. #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references &lt;&lt;faletto2022&gt;&gt; formCssDesign &lt;- function(css_results, weighting=&quot;weighted_avg&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=NA, newx=NA){ # Check inputs ret &lt;- checkFormCssDesignInputs(css_results, weighting, cutoff, min_num_clusts, max_num_clusts, newx) newx &lt;- ret$newx max_num_clusts &lt;- ret$max_num_clusts rm(ret) n &lt;- nrow(newx) p &lt;- ncol(newx) # Get the names of the selected clusters and the weights for the features # within each cluster, according to the provided weighting rule weights &lt;- getSelectedClusters(css_results, weighting, cutoff, min_num_clusts, max_num_clusts)$weights n_sel_clusts &lt;- length(weights) # Form matrix of cluster representatives of selected clusters X_clus_reps &lt;- matrix(rep(as.numeric(NA), n*n_sel_clusts), nrow=n, ncol=n_sel_clusts) colnames(X_clus_reps) &lt;- rep(as.character(NA), n_sel_clusts) for(i in 1:n_sel_clusts){ clust_i_name &lt;- names(weights)[i] stopifnot(length(clust_i_name) == 1) stopifnot(clust_i_name %in% names(weights)) colnames(X_clus_reps)[i] &lt;- clust_i_name clust_i &lt;- css_results$clusters[[clust_i_name]] stopifnot(length(clust_i) &gt;= 1) stopifnot(all(clust_i) %in% 1:p) weights_i &lt;- weights[[clust_i_name]] stopifnot(length(clust_i) == length(weights_i)) if(length(weights_i) &gt; 1){ X_clus_reps[, i] &lt;- newx[, clust_i] %*% weights_i } else{ X_clus_reps[, i] &lt;- newx[, clust_i]*weights_i } } # Check output stopifnot(all(!is.na(X_clus_reps))) stopifnot(ncol(X_clus_reps) == n_sel_clusts) stopifnot(nrow(X_clus_reps) == n) return(X_clus_reps) } checkFormCssDesignInputs(): #&#39; Helper function to check that the inputs to formCssDesign are as expected #&#39; #&#39; @param css_results An object of class &quot;cssr&quot; (the output of the function #&#39; css). #&#39; @param weighting Character; determines how to calculate the weights to #&#39; combine features from the selected clusters into weighted averages, called #&#39; cluster representatives. Must be one of &quot;sparse&quot;, &quot;weighted_avg&quot;, or #&#39; &quot;simple_avg&#39;. #&#39; @param cutoff Numeric; css will return only those clusters with selection #&#39; proportions equal to at least cutoff. Must be between 0 and 1. #&#39; @param min_num_clusts Integer or numeric; the minimum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns fewer than #&#39; min_num_clusts clusters, the cutoff will be increased until at least #&#39; min_num_clusts clusters are selected.) #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) #&#39; @param newx A numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; the data that will be used to generate the design matrix of cluster #&#39; representatives. Must contain the same features (in the same #&#39; number of columns) as the X matrix provided to css, and if the columns of #&#39; newx are labeled, the names must match the variable names provided to css. #&#39; newx may be omitted if train_inds were provided to css to set aside #&#39; observations for model estimation. If this is the case, then when newx is #&#39; omitted formCssDesign will return a design matrix of cluster representatives #&#39; formed from the train_inds observations from the matrix X provided to css. #&#39; (If no train_inds were provided to css, newX must be provided to #&#39; formCssDesign.) #&#39; @return A named list with the following elements: \\item{newx}{If newx was #&#39; provided, the provided newx matrix, coerced from a data.frame to a matrix if #&#39; needed. If newx was not provided, a matrix formed by the train_inds set #&#39; aside in the original function call to css.} \\item{max_num_clusts}{The #&#39; provided max_num_clusts, coerced to an integer if needed, and coerced to be #&#39; less than or equal to the total number of clusters.} #&#39; @author Gregory Faletto, Jacob Bien checkFormCssDesignInputs &lt;- function(css_results, weighting, cutoff, min_num_clusts, max_num_clusts, newx){ stopifnot(class(css_results) == &quot;cssr&quot;) if(length(newx) == 1){ if(is.na(newx)){ if(length(css_results$train_inds) == 0){ stop(&quot;If css was not provided with indices to set aside for model training, then newx must be provided to formCssDesign&quot;) } newx &lt;- css_results$X[css_results$train_inds, ] # feat_names &lt;- colnames(newx) } else{ results &lt;- checkXInputResults(newx, css_results$X) newx &lt;- results$newx # feat_names &lt;- results$feat_names rm(results) } } else{ results &lt;- checkXInputResults(newx, css_results$X) newx &lt;- results$newx # feat_names &lt;- results$feat_names rm(results) } p &lt;- ncol(newx) checkCutoff(cutoff) checkWeighting(weighting) checkMinNumClusts(min_num_clusts, p, length(css_results$clusters)) max_num_clusts &lt;- checkMaxNumClusts(max_num_clusts, min_num_clusts, p, length(css_results$clusters)) return(list(newx=newx, max_num_clusts=max_num_clusts)) } Tests for checkFormCssDesignInputs() testthat::test_that(&quot;checkFormCssDesignInputs works&quot;, { set.seed(72617) x_select &lt;- matrix(stats::rnorm(10*6), nrow=10, ncol=6) x_new &lt;- matrix(stats::rnorm(8*6), nrow=8, ncol=6) y_select &lt;- stats::rnorm(10) y_new &lt;- stats::rnorm(8) good_clusters &lt;- list(&quot;red&quot;=1:2, &quot;blue&quot;=3:4, &quot;green&quot;=5) css_res &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) res &lt;- checkFormCssDesignInputs(css_results=css_res, weighting=&quot;sparse&quot;, cutoff=0.5, min_num_clusts=1, max_num_clusts=NA, newx=x_new) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;newx&quot;, &quot;max_num_clusts&quot;)) testthat::expect_true(is.numeric(res$newx)) testthat::expect_true(is.matrix(res$newx)) testthat::expect_equal(nrow(res$newx), 8) testthat::expect_equal(ncol(res$newx), 6) testthat::expect_null(colnames(res$newx)) testthat::expect_true(all(abs(x_new - res$newX) &lt; 10^(-9))) testthat::expect_equal(length(res$max_num_clusts), 1) testthat::expect_true(is.na(res$max_num_clusts)) # Add training indices css_res_train &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B=10, train_inds=6:10) # Training indices should be ignored if new x is provided res &lt;- checkFormCssDesignInputs(css_results=css_res_train, weighting=&quot;weighted_avg&quot;, cutoff=0, min_num_clusts=2, max_num_clusts=NA, newx=x_new) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;newx&quot;, &quot;max_num_clusts&quot;)) testthat::expect_true(is.numeric(res$newx)) testthat::expect_true(is.matrix(res$newx)) testthat::expect_equal(nrow(res$newx), 8) testthat::expect_equal(ncol(res$newx), 6) testthat::expect_null(colnames(res$newx)) testthat::expect_true(all(abs(x_new - res$newX) &lt; 10^(-9))) # Things should still work if new x is not provided res &lt;- checkFormCssDesignInputs(css_results=css_res_train, weighting=&quot;sparse&quot;, cutoff=1, min_num_clusts=3, max_num_clusts=NA, newx=NA) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;newx&quot;, &quot;max_num_clusts&quot;)) testthat::expect_true(is.numeric(res$newx)) testthat::expect_true(is.matrix(res$newx)) testthat::expect_equal(nrow(res$newx), length(6:10)) testthat::expect_equal(ncol(res$newx), 6) testthat::expect_null(colnames(res$newx)) testthat::expect_true(all(abs(x_select[1:5, ] - res$newX) &lt; 10^(-9))) # Try not providing training indices and omitting newx--should get error testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;sparse&quot;, cutoff=0.5, min_num_clusts=1, max_num_clusts=5, newx=NA), &quot;If css was not provided with indices to set aside for model training, then newx must be provided to formCssDesign&quot;, fixed=TRUE) # Try naming variables colnames(x_select) &lt;- LETTERS[1:6] css_res_named &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) # Named variables for css matrix but not new one--should get a warning testthat::expect_warning(checkFormCssDesignInputs(css_results=css_res_named, weighting=&quot;simple_avg&quot;, cutoff=0.9, min_num_clusts=1, max_num_clusts=3, newx=x_new), &quot;New X provided had no variable names (column names) even though the X provided to css did.&quot;, fixed=TRUE) # Try mismatching variable names colnames(x_new) &lt;- LETTERS[2:7] testthat::expect_error(checkFormCssDesignInputs(css_results=css_res_named, weighting=&quot;weighted_avg&quot;, cutoff=0.2, min_num_clusts=1, max_num_clusts=1, newx=x_new), &quot;identical(feat_names, colnames(css_X)) is not TRUE&quot;, fixed=TRUE) colnames(x_new) &lt;- LETTERS[1:6] res_named &lt;- checkFormCssDesignInputs(css_results=css_res_named, weighting=&quot;sparse&quot;, cutoff=0.5, min_num_clusts=2, max_num_clusts=NA, newx=x_new) testthat::expect_true(is.list(res_named)) testthat::expect_identical(names(res_named), c(&quot;newx&quot;, &quot;max_num_clusts&quot;)) testthat::expect_true(is.numeric(res_named$newx)) testthat::expect_true(is.matrix(res_named$newx)) testthat::expect_equal(nrow(res_named$newx), 8) testthat::expect_equal(ncol(res_named$newx), 6) testthat::expect_null(colnames(res_named$newx)) testthat::expect_identical(colnames(css_res_named$X), LETTERS[1:6]) testthat::expect_true(all(abs(x_new - res_named$newX) &lt; 10^(-9))) # Try data.frame input to css and checkFormCssDesignInputs X_df &lt;- datasets::mtcars n &lt;- nrow(X_df) y &lt;- stats::rnorm(n) selec_inds &lt;- 1:round(n/2) fit_inds &lt;- setdiff(1:n, selec_inds) css_res_df &lt;- css(X=X_df[selec_inds, ], y=y[selec_inds], lambda=0.01, B = 10) res_df &lt;- checkFormCssDesignInputs(css_results=css_res_df, weighting=&quot;simple_avg&quot;, cutoff=0.7, min_num_clusts=3, max_num_clusts=NA, newx=X_df[fit_inds, ]) testthat::expect_true(is.list(res_df)) testthat::expect_identical(names(res_df), c(&quot;newx&quot;, &quot;max_num_clusts&quot;)) testthat::expect_true(is.numeric(res_df$newx)) testthat::expect_true(is.matrix(res_df$newx)) testthat::expect_null(colnames(res_df$newx)) testthat::expect_equal(nrow(res_df$newx), length(fit_inds)) testthat::expect_equal(ncol(res_df$newx), ncol(css_res_df$X)) # Try again with X as a dataframe with factors (number of columns of final # design matrix after one-hot encoding factors won&#39;t match number of columns # of X_df) X_df$cyl &lt;- as.factor(X_df$cyl) X_df$vs &lt;- as.factor(X_df$vs) X_df$am &lt;- as.factor(X_df$am) X_df$gear &lt;- as.factor(X_df$gear) X_df$carb &lt;- as.factor(X_df$carb) css_res_df &lt;- css(X=X_df[selec_inds, ], y=y[selec_inds], lambda=0.01, B = 10) res_df &lt;- checkFormCssDesignInputs(css_results=css_res_df, weighting=&quot;weighted_avg&quot;, cutoff=0.3, min_num_clusts=1, max_num_clusts=4, newx=X_df[fit_inds, ]) testthat::expect_true(is.list(res_df)) testthat::expect_identical(names(res_df), c(&quot;newx&quot;, &quot;max_num_clusts&quot;)) testthat::expect_true(is.numeric(res_df$newx)) testthat::expect_true(is.matrix(res_df$newx)) testthat::expect_null(colnames(res_df$newx)) testthat::expect_equal(nrow(res_df$newx), length(fit_inds)) testthat::expect_equal(ncol(res_df$newx), ncol(css_res_df$X)) ##### Try other bad inputs colnames(x_new) &lt;- NULL testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;weighted_avg&quot;, cutoff=-0.3, min_num_clusts=1, max_num_clusts=4, newx=x_new), &quot;cutoff &gt;= 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;sparse&quot;, cutoff=&quot;0.5&quot;, min_num_clusts=1, max_num_clusts=NA, newx=x_new), &quot;is.numeric(cutoff) | is.integer(cutoff) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;sparse&quot;, cutoff=as.numeric(NA), min_num_clusts=1, max_num_clusts=NA, newx=x_new), &quot;!is.na(cutoff) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=c(&quot;sparse&quot;, &quot;simple_avg&quot;), cutoff=0.2, min_num_clusts=1, max_num_clusts=NA, newx=x_new), &quot;length(weighting) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=1, cutoff=0.2, min_num_clusts=1, max_num_clusts=NA, newx=x_new), &quot;Weighting must be a character&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;spasre&quot;, cutoff=0.2, min_num_clusts=1, max_num_clusts=NA, newx=x_new), &quot;Weighting must be a character and one of sparse, simple_avg, or weighted_avg&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;weighted_avg&quot;, cutoff=0.2, min_num_clusts=c(1, 2), max_num_clusts=NA, newx=x_new), &quot;length(min_num_clusts) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;weighted_avg&quot;, cutoff=0.2, min_num_clusts=&quot;3&quot;, max_num_clusts=NA, newx=x_new), &quot;is.numeric(min_num_clusts) | is.integer(min_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;weighted_avg&quot;, cutoff=0.2, min_num_clusts=0, max_num_clusts=NA, newx=x_new), &quot;min_num_clusts &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;weighted_avg&quot;, cutoff=0.2, min_num_clusts=6, max_num_clusts=NA, newx=x_new), &quot;min_num_clusts &lt;= n_clusters is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;weighted_avg&quot;, cutoff=0.2, min_num_clusts=1, max_num_clusts=&quot;4&quot;, newx=x_new), &quot;is.numeric(max_num_clusts) | is.integer(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;weighted_avg&quot;, cutoff=0.2, min_num_clusts=1, max_num_clusts=3.5, newx=x_new), &quot;max_num_clusts == round(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;weighted_avg&quot;, cutoff=0.2, min_num_clusts=2, max_num_clusts=1, newx=x_new), &quot;max_num_clusts &gt;= min_num_clusts is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkFormCssDesignInputs(css_results=css_res, weighting=&quot;weighted_avg&quot;, cutoff=0.2, min_num_clusts=2, max_num_clusts=8, newx=x_new), &quot;max_num_clusts &lt;= p is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🥇 Tests for formCssDesign() testthat::test_that(&quot;formCssDesign works&quot;, { set.seed(17230) x_select &lt;- matrix(stats::rnorm(10*6), nrow=10, ncol=6) x_new &lt;- matrix(stats::rnorm(8*6), nrow=8, ncol=6) y_select &lt;- stats::rnorm(10) y_new &lt;- stats::rnorm(8) good_clusters &lt;- list(&quot;red&quot;=1:2, &quot;blue&quot;=3:4, &quot;green&quot;=5) css_res &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) res &lt;- formCssDesign(css_res, newx=x_new) testthat::expect_true(is.matrix(res)) testthat::expect_true(is.numeric(res)) testthat::expect_equal(nrow(res), 8) testthat::expect_equal(ncol(res), length(css_res$clusters)) testthat::expect_true(all(colnames(res) %in% names(css_res$clusters))) testthat::expect_true(all(names(css_res$clusters) %in% colnames(res))) # Add training indices css_res_train &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B=10, train_inds=6:10) # Training indices should be ignored if new x is provided res &lt;- formCssDesign(css_results=css_res_train, weighting=&quot;weighted_avg&quot;, cutoff=0, min_num_clusts=2, max_num_clusts=NA, newx=x_new) testthat::expect_true(is.matrix(res)) testthat::expect_true(is.numeric(res)) testthat::expect_equal(nrow(res), 8) testthat::expect_equal(ncol(res), length(css_res_train$clusters)) testthat::expect_true(all(colnames(res) %in% names(css_res_train$clusters))) testthat::expect_true(all(names(css_res_train$clusters) %in% colnames(res))) # Things should still work if new x is not provided res &lt;- formCssDesign(css_results=css_res_train, weighting=&quot;weighted_avg&quot;, cutoff=0, min_num_clusts=2, max_num_clusts=NA) testthat::expect_true(is.matrix(res)) testthat::expect_true(is.numeric(res)) testthat::expect_equal(nrow(res), 5) testthat::expect_equal(ncol(res), length(css_res_train$clusters)) testthat::expect_true(all(colnames(res) %in% names(css_res_train$clusters))) testthat::expect_true(all(names(css_res_train$clusters) %in% colnames(res))) # Try not providing training indices and omitting newx--should get error testthat::expect_error(formCssDesign(css_results=css_res, weighting=&quot;sparse&quot;, cutoff=0.5, min_num_clusts=1, max_num_clusts=5, newx=NA), &quot;If css was not provided with indices to set aside for model training, then newx must be provided to formCssDesign&quot;, fixed=TRUE) # Try naming variables colnames(x_select) &lt;- LETTERS[1:6] css_res_named &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) # Named variables for css matrix but not new one--should get a warning testthat::expect_warning(formCssDesign(css_results=css_res_named, weighting=&quot;simple_avg&quot;, cutoff=0.9, min_num_clusts=1, max_num_clusts=3, newx=x_new), &quot;New X provided had no variable names (column names) even though the X provided to css did.&quot;, fixed=TRUE) # Try mismatching variable names colnames(x_new) &lt;- LETTERS[2:7] testthat::expect_error(formCssDesign(css_results=css_res_named, weighting=&quot;weighted_avg&quot;, cutoff=0.2, min_num_clusts=1, max_num_clusts=1, newx=x_new), &quot;identical(feat_names, colnames(css_X)) is not TRUE&quot;, fixed=TRUE) colnames(x_new) &lt;- LETTERS[1:6] res_named &lt;- formCssDesign(css_results=css_res_named, weighting=&quot;sparse&quot;, cutoff=0.5, min_num_clusts=2, max_num_clusts=NA, newx=x_new) testthat::expect_true(is.matrix(res_named)) testthat::expect_true(is.numeric(res_named)) testthat::expect_equal(nrow(res_named), 8) testthat::expect_true(ncol(res_named) &lt;= length(css_res_named$clusters)) testthat::expect_true(all(colnames(res_named) %in% names(css_res_named$clusters))) # Try data.frame input to css and formCssDesign X_df &lt;- datasets::mtcars n &lt;- nrow(X_df) y &lt;- stats::rnorm(n) selec_inds &lt;- 1:round(n/2) fit_inds &lt;- setdiff(1:n, selec_inds) css_res_df &lt;- css(X=X_df[selec_inds, ], y=y[selec_inds], lambda=0.01, B = 10) res_df &lt;- formCssDesign(css_results=css_res_df, weighting=&quot;simple_avg&quot;, cutoff=0.7, min_num_clusts=3, max_num_clusts=NA, newx=X_df[fit_inds, ]) testthat::expect_true(is.matrix(res_df)) testthat::expect_true(is.numeric(res_df)) testthat::expect_equal(nrow(res_df), length(fit_inds)) testthat::expect_true(ncol(res_df) &lt;= length(css_res_df$clusters)) testthat::expect_true(all(colnames(res_df) %in% names(css_res_df$clusters))) # Try again with X as a dataframe with factors (number of columns of final # design matrix after one-hot encoding factors won&#39;t match number of columns # of X_df) X_df$cyl &lt;- as.factor(X_df$cyl) X_df$vs &lt;- as.factor(X_df$vs) X_df$am &lt;- as.factor(X_df$am) X_df$gear &lt;- as.factor(X_df$gear) X_df$carb &lt;- as.factor(X_df$carb) css_res_df &lt;- css(X=X_df[selec_inds, ], y=y[selec_inds], lambda=0.01, B = 10) res_df &lt;- formCssDesign(css_results=css_res_df, weighting=&quot;weighted_avg&quot;, cutoff=0.3, min_num_clusts=1, max_num_clusts=4, newx=X_df[fit_inds, ]) testthat::expect_true(is.matrix(res_df)) testthat::expect_true(is.numeric(res_df)) testthat::expect_equal(nrow(res_df), length(fit_inds)) testthat::expect_true(ncol(res_df) &lt;= length(css_res_df$clusters)) testthat::expect_true(all(colnames(res_df) %in% names(css_res_df$clusters))) ##### Try other bad inputs colnames(x_new) &lt;- NULL testthat::expect_error(formCssDesign(css_results=css_res, cutoff=-0.3, newx=x_new), &quot;cutoff &gt;= 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, cutoff=&quot;0.5&quot;, newx=x_new), &quot;is.numeric(cutoff) | is.integer(cutoff) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, cutoff=as.numeric(NA), newx=x_new), &quot;!is.na(cutoff) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, weighting=c(&quot;sparse&quot;, &quot;simple_avg&quot;), newx=x_new), &quot;length(weighting) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, weighting=1, newx=x_new), &quot;Weighting must be a character&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, weighting=&quot;spasre&quot;, newx=x_new), &quot;Weighting must be a character and one of sparse, simple_avg, or weighted_avg&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, min_num_clusts=c(1, 2), newx=x_new), &quot;length(min_num_clusts) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, min_num_clusts=&quot;3&quot;, newx=x_new), &quot;is.numeric(min_num_clusts) | is.integer(min_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, min_num_clusts=0, newx=x_new), &quot;min_num_clusts &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, min_num_clusts=6, newx=x_new), &quot;min_num_clusts &lt;= n_clusters is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, max_num_clusts=&quot;4&quot;, newx=x_new), &quot;is.numeric(max_num_clusts) | is.integer(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, max_num_clusts=3.5, newx=x_new), &quot;max_num_clusts == round(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, min_num_clusts=2, max_num_clusts=1, newx=x_new), &quot;max_num_clusts &gt;= min_num_clusts is not TRUE&quot;, fixed=TRUE) testthat::expect_error(formCssDesign(css_results=css_res, max_num_clusts=8, newx=x_new), &quot;max_num_clusts &lt;= p is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🥇 Finally, tests for getCssDesign() testthat::test_that(&quot;getCssDesign works&quot;, { set.seed(23170) x_select &lt;- matrix(stats::rnorm(10*6), nrow=10, ncol=6) x_new &lt;- matrix(stats::rnorm(8*6), nrow=8, ncol=6) y_select &lt;- stats::rnorm(10) y_new &lt;- stats::rnorm(8) good_clusters &lt;- list(&quot;red&quot;=1:2, &quot;blue&quot;=3:4, &quot;green&quot;=5) css_res &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) res &lt;- getCssDesign(css_res, newX=x_new) testthat::expect_true(is.matrix(res)) testthat::expect_true(is.numeric(res)) testthat::expect_equal(nrow(res), 8) testthat::expect_equal(ncol(res), length(css_res$clusters)) testthat::expect_true(all(colnames(res) %in% names(css_res$clusters))) testthat::expect_true(all(names(css_res$clusters) %in% colnames(res))) # Add training indices css_res_train &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B=10, train_inds=6:10) # Training indices should be ignored if new x is provided res &lt;- getCssDesign(css_results=css_res_train, weighting=&quot;weighted_avg&quot;, min_num_clusts=2, newX=x_new) testthat::expect_true(is.matrix(res)) testthat::expect_true(is.numeric(res)) testthat::expect_equal(nrow(res), 8) testthat::expect_equal(ncol(res), length(css_res_train$clusters)) testthat::expect_true(all(colnames(res) %in% names(css_res_train$clusters))) testthat::expect_true(all(names(css_res_train$clusters) %in% colnames(res))) # Things should still work if new x is not provided res &lt;- getCssDesign(css_results=css_res_train, min_num_clusts=2) testthat::expect_true(is.matrix(res)) testthat::expect_true(is.numeric(res)) testthat::expect_equal(nrow(res), 5) testthat::expect_equal(ncol(res), length(css_res_train$clusters)) testthat::expect_true(all(colnames(res) %in% names(css_res_train$clusters))) testthat::expect_true(all(names(css_res_train$clusters) %in% colnames(res))) # Try not providing training indices and omitting newX--should get error testthat::expect_error(getCssDesign(css_results=css_res, weighting=&quot;sparse&quot;, cutoff=0.5, min_num_clusts=1, max_num_clusts=5, newX=NA), &quot;css was not provided with indices to set aside for model training (train_inds), so must provide new X in order to generate a design matrix&quot;, fixed=TRUE) # Try naming variables colnames(x_select) &lt;- LETTERS[1:6] css_res_named &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) # Named variables for css matrix but not new one--should get a warning testthat::expect_warning(getCssDesign(css_results=css_res_named, weighting=&quot;simple_avg&quot;, cutoff=0.9, min_num_clusts=1, max_num_clusts=3, newX=x_new), &quot;New X provided had no variable names (column names) even though the X provided to css did.&quot;, fixed=TRUE) # Try mismatching variable names colnames(x_new) &lt;- LETTERS[2:7] testthat::expect_error(getCssDesign(css_results=css_res_named, weighting=&quot;weighted_avg&quot;, cutoff=0.2, min_num_clusts=1, max_num_clusts=1, newX=x_new), &quot;identical(feat_names, colnames(css_X)) is not TRUE&quot;, fixed=TRUE) colnames(x_new) &lt;- LETTERS[1:6] res_named &lt;- getCssDesign(css_results=css_res_named, weighting=&quot;sparse&quot;, cutoff=0.5, min_num_clusts=2, max_num_clusts=NA, newX=x_new) testthat::expect_true(is.matrix(res_named)) testthat::expect_true(is.numeric(res_named)) testthat::expect_equal(nrow(res_named), 8) testthat::expect_true(ncol(res_named) &lt;= length(css_res_named$clusters)) testthat::expect_true(all(colnames(res_named) %in% names(css_res_named$clusters))) # Try data.frame input to css and getCssDesign X_df &lt;- datasets::mtcars n &lt;- nrow(X_df) y &lt;- stats::rnorm(n) selec_inds &lt;- 1:round(n/2) fit_inds &lt;- setdiff(1:n, selec_inds) css_res_df &lt;- css(X=X_df[selec_inds, ], y=y[selec_inds], lambda=0.01, B = 10) res_df &lt;- getCssDesign(css_results=css_res_df, weighting=&quot;simple_avg&quot;, cutoff=0.7, min_num_clusts=3, max_num_clusts=NA, newX=X_df[fit_inds, ]) testthat::expect_true(is.matrix(res_df)) testthat::expect_true(is.numeric(res_df)) testthat::expect_equal(nrow(res_df), length(fit_inds)) testthat::expect_true(ncol(res_df) &lt;= length(css_res_df$clusters)) testthat::expect_true(all(colnames(res_df) %in% names(css_res_df$clusters))) # Try again with X as a dataframe with factors (number of columns of final # design matrix after one-hot encoding factors won&#39;t match number of columns # of X_df) X_df$cyl &lt;- as.factor(X_df$cyl) X_df$vs &lt;- as.factor(X_df$vs) X_df$am &lt;- as.factor(X_df$am) X_df$gear &lt;- as.factor(X_df$gear) X_df$carb &lt;- as.factor(X_df$carb) css_res_df &lt;- css(X=X_df[selec_inds, ], y=y[selec_inds], lambda=0.01, B = 10) res_df &lt;- getCssDesign(css_results=css_res_df, weighting=&quot;weighted_avg&quot;, cutoff=0.3, min_num_clusts=1, max_num_clusts=4, newX=X_df[fit_inds, ]) testthat::expect_true(is.matrix(res_df)) testthat::expect_true(is.numeric(res_df)) testthat::expect_equal(nrow(res_df), length(fit_inds)) testthat::expect_true(ncol(res_df) &lt;= length(css_res_df$clusters)) testthat::expect_true(all(colnames(res_df) %in% names(css_res_df$clusters))) ##### Try other bad inputs colnames(x_new) &lt;- NULL testthat::expect_error(getCssDesign(css_results=css_res, cutoff=-0.3, newX=x_new), &quot;cutoff &gt;= 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, cutoff=&quot;0.5&quot;, newX=x_new), &quot;is.numeric(cutoff) | is.integer(cutoff) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, cutoff=as.numeric(NA), newX=x_new), &quot;!is.na(cutoff) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, weighting=c(&quot;sparse&quot;, &quot;simple_avg&quot;), newX=x_new), &quot;length(weighting) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, weighting=1, newX=x_new), &quot;Weighting must be a character&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, weighting=&quot;spasre&quot;, newX=x_new), &quot;Weighting must be a character and one of sparse, simple_avg, or weighted_avg&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, min_num_clusts=c(1, 2), newX=x_new), &quot;length(min_num_clusts) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, min_num_clusts=&quot;3&quot;, newX=x_new), &quot;is.numeric(min_num_clusts) | is.integer(min_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, min_num_clusts=0, newX=x_new), &quot;min_num_clusts &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, min_num_clusts=6, newX=x_new), &quot;min_num_clusts &lt;= n_clusters is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, max_num_clusts=&quot;4&quot;, newX=x_new), &quot;is.numeric(max_num_clusts) | is.integer(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, max_num_clusts=3.5, newX=x_new), &quot;max_num_clusts == round(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, min_num_clusts=2, max_num_clusts=1, newX=x_new), &quot;max_num_clusts &gt;= min_num_clusts is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssDesign(css_results=css_res, max_num_clusts=8, newX=x_new), &quot;max_num_clusts &lt;= p is not TRUE&quot;, fixed=TRUE) }) ## ── Warning (&#39;&lt;text&gt;:63&#39;): getCssDesign works ─────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. testthat::expect_warning(...) ## 7. litr (local) getCssDesign(...) ## 8. litr (local) checkXInputResults(newX, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:63&#39;): getCssDesign works ─────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. testthat::expect_warning(...) ## 7. litr (local) getCssDesign(...) ## 8. litr (local) formCssDesign(...) ## 9. litr (local) checkFormCssDesignInputs(...) ## 10. litr (local) checkXInputResults(newx, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:80&#39;): getCssDesign works ─────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. litr (local) getCssDesign(...) ## 2. litr (local) checkXInputResults(newX, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:80&#39;): getCssDesign works ─────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. litr (local) getCssDesign(...) ## 2. litr (local) formCssDesign(...) ## 3. litr (local) checkFormCssDesignInputs(...) ## 4. litr (local) checkXInputResults(newx, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:101&#39;): getCssDesign works ────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. litr (local) getCssDesign(...) ## 2. litr (local) checkXInputResults(newX, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:101&#39;): getCssDesign works ────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. litr (local) getCssDesign(...) ## 2. litr (local) formCssDesign(...) ## 3. litr (local) checkFormCssDesignInputs(...) ## 4. litr (local) checkXInputResults(newx, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:121&#39;): getCssDesign works ────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. litr (local) getCssDesign(...) ## 2. litr (local) checkXInputResults(newX, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:121&#39;): getCssDesign works ────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. litr (local) getCssDesign(...) ## 2. litr (local) formCssDesign(...) ## 3. litr (local) checkFormCssDesignInputs(...) ## 4. litr (local) checkXInputResults(newx, css_results$X) getCssPreds() #&#39; Fit model and generate predictions from new data #&#39; #&#39; Generate predictions on test data using cluster stability-selected model. #&#39; @param css_results An object of class &quot;cssr&quot; (the output of the function #&#39; css). #&#39; @param testX A numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; the data that will be used to generate predictions. Must contain the same #&#39; features (in the same number of columns) as the matrix provided to css, and #&#39; if the columns of testX are labeled, the names must match the variable names #&#39; provided to css. #&#39; @param weighting Character; determines how to calculate the weights to #&#39; combine features from the selected clusters into weighted averages, called #&#39; cluster representatives. Must be one of &quot;sparse&quot;, &quot;weighted_avg&quot;, or #&#39; &quot;simple_avg&#39;. For &quot;sparse&quot;, all the weight is put on the most frequently #&#39; selected individual cluster member (or divided equally among all the clusters #&#39; that are tied for the top selection proportion if there is a tie). For #&#39; &quot;weighted_avg&quot;, the weight used for each cluster member is calculated in #&#39; proportion to the individual selection proportions of each feature. For #&#39; &quot;simple_avg&quot;, each cluster member gets equal weight regardless of the #&#39; individual feature selection proportions (that is, the cluster representative #&#39; is just a simple average of all the cluster members). See Faletto and Bien #&#39; (2022) for details. Default is &quot;weighted_avg&quot;. #&#39; @param cutoff Numeric; getCssPreds will make use only of those clusters with #&#39; selection proportions equal to at least cutoff. Must be between 0 and 1. #&#39; Default is 0 (in which case either all clusters are used, or max_num_clusts #&#39; are used, if max_num_clusts is specified). #&#39; @param min_num_clusts Integer or numeric; the minimum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns fewer than #&#39; min_num_clusts clusters, the cutoff will be increased until at least #&#39; min_num_clusts clusters are selected.) Default is 1. #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) Default is NA (in which case #&#39; max_num_clusts is ignored). #&#39; @param trainX A numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; the data that will be used to estimate the linear model from the selected #&#39; clusters. trainX is only necessary to provide if no train_inds were #&#39; designated in the css function call to set aside observations for model #&#39; estimation (though even if train_inds was provided, trainX and trianY will be #&#39; used for model estimation if they are both provided to getCssPreds). Must #&#39; contain the same features (in the same number of columns) as the matrix #&#39; provided to css, and if the columns of trainX are labeled, the names must #&#39; match the variable names provided to css. Default is NA (in which case #&#39; getCssPreds uses the observations from the train_inds that were provided to #&#39; css to estimate a linear model). #&#39; @param trainY The response corresponding to trainX. Must be a real-valued #&#39; response (unlike in the general css setup) because predictions will be #&#39; generated by an ordinary least squares model. Must have the same length as #&#39; the number of rows of trainX. Like trainX, only needs to be provided if no #&#39; observations were set aside for model estimation by the parameter train_inds #&#39; in the css function call. Default is NA (in which case getCssPreds uses the #&#39; observations from the train_inds that were provided to css). #&#39; @return A vector of predictions corresponding to the observations from testX. #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references &lt;&lt;faletto2022&gt;&gt; #&#39; @export getCssPreds &lt;- function(css_results, testX, weighting=&quot;weighted_avg&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=NA, trainX=NA, trainY=NA){ # TODO(gregfaletto) Consider adding an argument for a user-provided prediction # function in order to allow for more general kinds of predictions than # OLS. # Check inputs check_list &lt;- checkGetCssPredsInputs(css_results, testX, weighting, cutoff, min_num_clusts, max_num_clusts, trainX, trainY) trainXProvided &lt;- check_list$trainXProvided trainX &lt;- check_list$trainX testX &lt;- check_list$testX feat_names &lt;- check_list$feat_names max_num_clusts &lt;- check_list$max_num_clusts rm(check_list) n_train &lt;- nrow(trainX) n &lt;- nrow(testX) p &lt;- ncol(testX) # Take provided training design matrix and testX and turn them into # matrices of cluster representatives using information from css_results if(trainXProvided){ train_X_clusters &lt;- formCssDesign(css_results, weighting, cutoff, min_num_clusts, max_num_clusts, newx=trainX) if(!is.numeric(trainY) &amp; !is.integer(trainY)){ stop(&quot;The provided trainY must be real-valued, because predictions will be generated by ordinary least squares regression.&quot;) } y_train &lt;- trainY } else{ train_X_clusters &lt;- formCssDesign(css_results, weighting, cutoff, min_num_clusts, max_num_clusts) y_train &lt;- css_results$y[css_results$train_inds] if(!is.numeric(y_train) &amp; !is.integer(y_train)){ stop(&quot;Can&#39;t generated predictions from the data that was provided to css because the provided y was not real-valued (getCssPreds generated predictions using ordinary least squares regression).&quot;) } } stopifnot(length(y_train) == nrow(train_X_clusters)) testX_clusters &lt;- formCssDesign(css_results, weighting, cutoff, min_num_clusts, max_num_clusts, newx=testX) stopifnot(ncol(testX_clusters) == ncol(train_X_clusters)) # Get names for clusters clust_X_names &lt;- paste(&quot;c_fit_&quot;, 1:ncol(testX_clusters), sep=&quot;&quot;) if(!is.null(colnames(train_X_clusters))){ stopifnot(identical(colnames(train_X_clusters), colnames(testX_clusters))) clust_X_names &lt;- colnames(train_X_clusters) } # Fit linear model on training data via OLS if(nrow(train_X_clusters) &lt; ncol(train_X_clusters)){ err_mess &lt;- paste(&quot;css not provided with enough indices to fit OLS model for predictions (number of training indices: &quot;, nrow(train_X_clusters), &quot;, number of clusters: &quot;, ncol(train_X_clusters), &quot;). Try reducing number of clusters by increasing cutoff, or re-run css with a larger number of training indices.&quot;, sep=&quot;&quot;) stop(err_mess) } df &lt;- data.frame(y=y_train, train_X_clusters) colnames(df)[2:ncol(df)] &lt;- clust_X_names model &lt;- stats::lm(y ~., data=df) # Use fitted model to generate predictions on testX df_test &lt;- data.frame(testX_clusters) colnames(df_test) &lt;- clust_X_names predictions &lt;- stats::predict.lm(model, newdata=df_test) names(predictions) &lt;- NULL # Check output stopifnot(is.numeric(predictions) | is.integer(predictions)) stopifnot(length(predictions) == n) stopifnot(all(!is.na(predictions))) return(predictions) } checkGetCssPredsInputs(): #&#39; Helper function to confirm that inputs to the function getCssPreds are as #&#39; expected, and modify inputs if needed. #&#39; #&#39; @param css_results An object of class &quot;cssr&quot; (the output of the function #&#39; css). #&#39; @param testX A numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; the data that will be used to generate predictions. Must contain the same #&#39; features (in the same number of columns) as the matrix provided to css. #&#39; @param weighting Character; determines how to calculate the weights to #&#39; combine features from the selected clusters into weighted averages, called #&#39; cluster representatives. Must be one of &quot;sparse&quot;, &quot;weighted_avg&quot;, or #&#39; &quot;simple_avg&#39;. For &quot;sparse&quot;, all the weight is put on the most frequently #&#39; selected individual cluster member (or divided equally among all the clusters #&#39; that are tied for the top selection proportion if there is a tie). For #&#39; &quot;weighted_avg&quot;, the weight used for each cluster member is calculated in #&#39; proportion to the individual selection proportions of each feature. For #&#39; &quot;simple_avg&quot;, each cluster member gets equal weight regardless of the #&#39; individual feature selection proportions (that is, the cluster representative #&#39; is just a simple average of all the cluster members). See Faletto and Bien #&#39; (2022) for details. Default is &quot;weighted_avg&quot;. #&#39; @param cutoff Numeric; getCssPreds will make use only of those clusters with #&#39; selection proportions equal to at least cutoff. Must be between 0 and 1. #&#39; Default is 0 (in which case either all clusters are used, or max_num_clusts #&#39; are used, if max_num_clusts is specified). #&#39; @param min_num_clusts Integer or numeric; the minimum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns fewer than #&#39; min_num_clusts clusters, the cutoff will be increased until at least #&#39; min_num_clusts clusters are selected.) Default is 1. #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) Default is NA (in which case #&#39; max_num_clusts is ignored). #&#39; @param trainX A numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; the data that will be used to estimate the linear model from the selected #&#39; clusters. trainX is only necessary to provide if no train_inds were #&#39; designated in the css function call to set aside observations for model #&#39; estimation (though even if train_inds was provided, trainX and trianY will be #&#39; used for model estimation if they are both provided to getCssPreds). Must #&#39; contain the same features (in the same number of columns) as the matrix #&#39; provided to css, and if the columns of trainX are labeled, the names must #&#39; match the variable names provided to css. Default is NA (in which case #&#39; getCssPreds uses the observations from the train_inds that were provided to #&#39; css to estimate a linear model). #&#39; @param trainY The response corresponding to trainX. Must be a real-valued #&#39; response (unlike in the general css setup) because predictions will be #&#39; generated by an ordinary least squares model. Must have the same length as #&#39; the number of rows of trainX. Like trainX, only needs to be provided if no #&#39; observations were set aside for model estimation by the parameter train_inds #&#39; in the css function call. Default is NA (in which case getCssPreds uses the #&#39; observations from the train_inds that were provided to css). #&#39; @return A named list with the following elements: \\item{trainXProvided}{ #&#39; Logical; indicates whether a valid trainX input was provided.} \\item{trainX}{ #&#39; The provided trainX matrix, coerced from a data.frame to a matrix if the #&#39; provided trainX was a data.frame. (If a valid trainX was not provided, this #&#39; output simply passes whatever was provided as trainX.)} \\item{testX}{The #&#39; provided testX matrix, coerced from a data.frame to a matrix if the provided #&#39; testX was a data.frame.} \\item{feat_names}{A character vector containing the #&#39; column names of testX (if the provided testX had column names). If the #&#39; provided testX did not have column names, feat_names will be NA.} #&#39; \\item{max_num_clusts}{The provided max_num_clusts, coerced to an integer if #&#39; needed, and coerced to be less than or equal to the total number of clusters #&#39; from the output of css_results.} #&#39; @author Gregory Faletto, Jacob Bien checkGetCssPredsInputs &lt;- function(css_results, testX, weighting, cutoff, min_num_clusts, max_num_clusts, trainX, trainY){ # Check inputs stopifnot(class(css_results) == &quot;cssr&quot;) check_results &lt;- checkNewXProvided(trainX, css_results) trainX &lt;- check_results$newX trainXProvided &lt;- check_results$newXProvided rm(check_results) n_train &lt;- nrow(trainX) if(trainXProvided){ if(all(!is.na(trainY)) &amp; length(trainY) &gt; 1){ stopifnot(is.numeric(trainY)) stopifnot(n_train == length(trainY)) } else{ if(length(css_results$train_inds) == 0){ stop(&quot;css was not provided with indices to set aside for model training (train_inds), so must provide both trainX and trainY in order to generate predictions&quot;) } trainXProvided &lt;- FALSE warning(&quot;trainX provided but no trainY provided; instead, training model using the train_inds observations provided to css to set aside for model training.&quot;) } } else{ if(length(css_results$train_inds) == 0){ stop(&quot;css was not provided with indices to set aside for model training (train_inds), so must provide both trainX and trainY in order to generate predictions&quot;) } if(all(!is.na(trainY)) &amp; length(trainY) &gt; 1){ warning(&quot;trainY provided but no trainX provided; instead, training model using the train_inds observations provided to css to set aside for model training.&quot;) } } results &lt;- checkXInputResults(testX, css_results$X) testX &lt;- results$newx feat_names &lt;- results$feat_names if(all(!is.na(feat_names))){ stopifnot(length(feat_names) == ncol(testX)) stopifnot(!(&quot;(Intercept)&quot; %in% feat_names)) colnames(testX) &lt;- feat_names } rm(results) n &lt;- nrow(testX) p &lt;- ncol(testX) stopifnot(n &gt;= 1) stopifnot(p == ncol(trainX)) if(!is.null(colnames(trainX)) &amp; is.null(colnames(testX))){ warning(&quot;Column names were provided for trainX but not for testX (are you sure they both contain identical features in the same order?)&quot;) } if(is.null(colnames(trainX)) &amp; !is.null(colnames(testX))){ warning(&quot;Column names were provided for testX but not for trainX (are you sure they both contain identical features in the same order?)&quot;) } if(!is.null(colnames(trainX)) &amp; !is.null(colnames(testX))){ stopifnot(all(colnames(trainX) == colnames(testX))) } checkCutoff(cutoff) checkWeighting(weighting) checkMinNumClusts(min_num_clusts, p, length(css_results$clusters)) max_num_clusts &lt;- checkMaxNumClusts(max_num_clusts, min_num_clusts, p, length(css_results$clusters)) return(list(trainXProvided=trainXProvided, trainX=trainX, testX=testX, feat_names=feat_names, max_num_clusts=max_num_clusts)) } Tests for checkGetCssPredsInputs() testthat::test_that(&quot;checkGetCssPredsInputs works&quot;, { set.seed(17081) x_select &lt;- matrix(stats::rnorm(10*6), nrow=10, ncol=6) x_train &lt;- matrix(stats::rnorm(8*6), nrow=8, ncol=6) x_pred &lt;- matrix(stats::rnorm(7*6), nrow=7, ncol=6) y_select &lt;- stats::rnorm(10) y_train &lt;- stats::rnorm(8) good_clusters &lt;- list(&quot;red&quot;=1:2, &quot;blue&quot;=3:4, &quot;green&quot;=5) css_res &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) res &lt;- checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;simple_avg&quot;, cutoff=0.05, min_num_clusts=1, max_num_clusts=NA, trainX=x_train, trainY=y_train) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;trainXProvided&quot;, &quot;trainX&quot;, &quot;testX&quot;, &quot;feat_names&quot;, &quot;max_num_clusts&quot;)) testthat::expect_true(!is.na(res$trainXProvided)) testthat::expect_equal(length(res$trainXProvided), 1) testthat::expect_true(is.logical(res$trainXProvided)) testthat::expect_true(res$trainXProvided) testthat::expect_true(all(!is.na(res$trainX))) testthat::expect_true(is.matrix(res$trainX)) testthat::expect_true(is.numeric(res$trainX)) testthat::expect_equal(nrow(res$trainX), 8) testthat::expect_equal(ncol(res$trainX), 6) testthat::expect_true(all(abs(x_train - res$trainX) &lt; 10^(-9))) testthat::expect_true(all(!is.na(res$testX))) testthat::expect_true(is.matrix(res$testX)) testthat::expect_true(is.numeric(res$testX)) testthat::expect_equal(nrow(res$testX), 7) testthat::expect_equal(ncol(res$testX), 6) testthat::expect_true(all(abs(x_pred - res$testX) &lt; 10^(-9))) testthat::expect_true(is.character(res$feat_names)) testthat::expect_true(is.na(res$feat_names)) testthat::expect_true(is.na(res$max_num_clusts)) testthat::expect_true(length(res$max_num_clusts) == 1) ##### Try other bad inputs testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;weighted_avg&quot;, cutoff=-0.5, min_num_clusts=1, max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;cutoff &gt;= 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;sparse&quot;, cutoff=&quot;0.3&quot;, min_num_clusts=1, max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;is.numeric(cutoff) | is.integer(cutoff) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;sparse&quot;, cutoff=as.numeric(NA), min_num_clusts=1, max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;!is.na(cutoff) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=c(&quot;sparse&quot;, &quot;simple_avg&quot;), cutoff=0.1, min_num_clusts=1, max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;length(weighting) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=2, cutoff=0.1, min_num_clusts=1, max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;Weighting must be a character&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;spasre&quot;, cutoff=0.1, min_num_clusts=1, max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;Weighting must be a character and one of sparse, simple_avg, or weighted_avg&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;sparse&quot;, cutoff=0.1, min_num_clusts=c(1, 2), max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;length(min_num_clusts) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;weighted_avg&quot;, cutoff=0.1, min_num_clusts=&quot;2&quot;, max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;is.numeric(min_num_clusts) | is.integer(min_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;simple_avg&quot;, cutoff=0.1, min_num_clusts=0, max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;min_num_clusts &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;weighted_avg&quot;, cutoff=0.1, min_num_clusts=10, max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;min_num_clusts &lt;= p is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;simple_avg&quot;, cutoff=0.1, min_num_clusts=1, max_num_clusts=&quot;5&quot;, trainX=x_train, trainY=y_train), &quot;is.numeric(max_num_clusts) | is.integer(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;sparse&quot;, cutoff=0.1, min_num_clusts=1, max_num_clusts=4.5, trainX=x_train, trainY=y_train), &quot;max_num_clusts == round(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;sparse&quot;, cutoff=0.1, min_num_clusts=3, max_num_clusts=2, trainX=x_train, trainY=y_train), &quot;max_num_clusts &gt;= min_num_clusts is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;sparse&quot;, cutoff=0.1, min_num_clusts=1, max_num_clusts=10, trainX=x_train, trainY=y_train), &quot;max_num_clusts &lt;= p is not TRUE&quot;, fixed=TRUE) # Add training indices css_res_train &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B=10, train_inds=6:10) # Training indices should be ignored if new x is provided res &lt;- checkGetCssPredsInputs(css_res_train, testX=x_pred, weighting=&quot;weighted_avg&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=NA, trainX=x_train, trainY=y_train) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;trainXProvided&quot;, &quot;trainX&quot;, &quot;testX&quot;, &quot;feat_names&quot;, &quot;max_num_clusts&quot;)) testthat::expect_true(!is.na(res$trainXProvided)) testthat::expect_equal(length(res$trainXProvided), 1) testthat::expect_true(is.logical(res$trainXProvided)) testthat::expect_true(res$trainXProvided) testthat::expect_true(all(!is.na(res$trainX))) testthat::expect_true(is.matrix(res$trainX)) testthat::expect_true(is.numeric(res$trainX)) testthat::expect_equal(nrow(res$trainX), 8) testthat::expect_equal(ncol(res$trainX), 6) testthat::expect_true(all(abs(x_train - res$trainX) &lt; 10^(-9))) testthat::expect_true(all(!is.na(res$testX))) testthat::expect_true(is.matrix(res$testX)) testthat::expect_true(is.numeric(res$testX)) testthat::expect_equal(nrow(res$testX), 7) testthat::expect_equal(ncol(res$testX), 6) testthat::expect_true(all(abs(x_pred - res$testX) &lt; 10^(-9))) testthat::expect_true(is.character(res$feat_names)) testthat::expect_true(is.na(res$feat_names)) testthat::expect_true(is.na(res$max_num_clusts)) testthat::expect_true(length(res$max_num_clusts) == 1) # Things should still work if new x is not provided res &lt;- checkGetCssPredsInputs(css_res_train, testX=x_pred, weighting=&quot;weighted_avg&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=NA, trainX=NA, trainY=NA) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;trainXProvided&quot;, &quot;trainX&quot;, &quot;testX&quot;, &quot;feat_names&quot;, &quot;max_num_clusts&quot;)) testthat::expect_true(!is.na(res$trainXProvided)) testthat::expect_equal(length(res$trainXProvided), 1) testthat::expect_true(is.logical(res$trainXProvided)) testthat::expect_true(!res$trainXProvided) testthat::expect_true(all(!is.na(res$trainX))) testthat::expect_true(is.matrix(res$trainX)) testthat::expect_true(is.numeric(res$trainX)) testthat::expect_equal(nrow(res$trainX), 5) testthat::expect_equal(ncol(res$trainX), 6) testthat::expect_true(all(abs(x_select[6:10, ] - res$trainX) &lt; 10^(-9))) testthat::expect_true(all(!is.na(res$testX))) testthat::expect_true(is.matrix(res$testX)) testthat::expect_true(is.numeric(res$testX)) testthat::expect_equal(nrow(res$testX), 7) testthat::expect_equal(ncol(res$testX), 6) testthat::expect_true(all(abs(x_pred - res$testX) &lt; 10^(-9))) testthat::expect_true(is.character(res$feat_names)) testthat::expect_true(is.na(res$feat_names)) testthat::expect_true(is.na(res$max_num_clusts)) testthat::expect_true(length(res$max_num_clusts) == 1) # Try not providing training indices and omitting newX--should get error testthat::expect_error(checkGetCssPredsInputs(css_res, testX=x_pred, weighting=&quot;sparse&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=NA, trainX=NA, trainY=NA), &quot;css was not provided with indices to set aside for model training (train_inds), so must provide new X in order to generate a design matrix&quot;, fixed=TRUE) # Try naming variables colnames(x_select) &lt;- LETTERS[1:6] css_res_named &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) # Named variables for css matrix but not new one--should get a warning testthat::expect_warning(checkGetCssPredsInputs(css_res_named, testX=x_pred, weighting=&quot;simple_avg&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;New X provided had no variable names (column names) even though the X provided to css did.&quot;, fixed=TRUE) # Try mismatching variable names colnames(x_train) &lt;- LETTERS[2:7] colnames(x_pred) &lt;- LETTERS[1:6] testthat::expect_error(checkGetCssPredsInputs(css_res_named, testX=x_pred, weighting=&quot;weighted_avg&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;identical(feat_names, colnames(css_X)) is not TRUE&quot;, fixed=TRUE) colnames(x_train) &lt;- LETTERS[1:6] colnames(x_pred) &lt;- LETTERS[2:7] testthat::expect_error(checkGetCssPredsInputs(css_res_named, testX=x_pred, weighting=&quot;sparse&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=NA, trainX=x_train, trainY=y_train), &quot;identical(feat_names, colnames(css_X)) is not TRUE&quot;, fixed=TRUE) colnames(x_pred) &lt;- LETTERS[1:6] res_named &lt;- checkGetCssPredsInputs(css_res_named, testX=x_pred, weighting=&quot;simple_avg&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=NA, trainX=x_train, trainY=y_train) testthat::expect_true(is.list(res_named)) testthat::expect_identical(names(res_named), c(&quot;trainXProvided&quot;, &quot;trainX&quot;, &quot;testX&quot;, &quot;feat_names&quot;, &quot;max_num_clusts&quot;)) testthat::expect_true(all(!is.na(res_named$trainX))) testthat::expect_true(is.matrix(res_named$trainX)) testthat::expect_true(is.numeric(res_named$trainX)) testthat::expect_equal(nrow(res_named$trainX), 8) testthat::expect_equal(ncol(res_named$trainX), 6) testthat::expect_true(all(abs(x_train - res_named$trainX) &lt; 10^(-9))) testthat::expect_true(is.character(res_named$feat_names)) testthat::expect_identical(res_named$feat_names, LETTERS[1:6]) # Try data.frame input to css and checkGetCssPredsInputs X_df &lt;- datasets::mtcars n &lt;- nrow(X_df) y &lt;- stats::rnorm(n) selec_inds &lt;- 1:round(n/3) train_inds &lt;- (max(selec_inds) + 1):(2*round(n/3)) test_inds &lt;- setdiff(1:n, c(selec_inds, train_inds)) css_res_df &lt;- css(X=X_df[c(selec_inds, train_inds), ], y=y[c(selec_inds, train_inds)], lambda=0.01, B = 10, train_inds=train_inds) res_df &lt;- checkGetCssPredsInputs(css_res_df, testX=X_df[test_inds, ], weighting=&quot;sparse&quot;, cutoff=0, min_num_clusts=1, max_num_clusts=NA, trainX=NA, trainY=NA) testthat::expect_true(is.list(res_df)) testthat::expect_identical(names(res_df), c(&quot;trainXProvided&quot;, &quot;trainX&quot;, &quot;testX&quot;,&quot;feat_names&quot;, &quot;max_num_clusts&quot;)) testthat::expect_true(all(!is.na(res_df$trainX))) testthat::expect_true(is.matrix(res_df$trainX)) testthat::expect_true(is.numeric(res_df$trainX)) testthat::expect_equal(nrow(res_df$trainX), length(train_inds)) stopifnot(nrow(css_res_df$X) &gt;= max(train_inds)) train_mat &lt;- css_res_df$X[train_inds, ] testthat::expect_equal(ncol(res_df$trainX), ncol(train_mat)) testthat::expect_true(all(abs(train_mat - res_df$trainX) &lt; 10^(-9))) testthat::expect_identical(colnames(res_df$trainX), colnames(train_mat)) testthat::expect_true(all(!is.na(res_df$testX))) testthat::expect_true(is.matrix(res_df$testX)) testthat::expect_true(is.numeric(res_df$testX)) testthat::expect_equal(nrow(res_df$testX), length(test_inds)) test_mat &lt;- stats::model.matrix(~ ., X_df[test_inds, ]) test_mat &lt;- test_mat[, colnames(test_mat) != &quot;(Intercept)&quot;] testthat::expect_equal(ncol(res_df$testX), ncol(test_mat)) testthat::expect_true(all(abs(test_mat - res_df$testX) &lt; 10^(-9))) testthat::expect_identical(colnames(res_df$testX), colnames(test_mat)) testthat::expect_identical(colnames(res_df$testX), colnames(res_df$trainX)) # Try again with X as a dataframe with factors (number of columns of final # design matrix after one-hot encoding factors won&#39;t match number of columns # of X_df) X_df$cyl &lt;- as.factor(X_df$cyl) X_df$vs &lt;- as.factor(X_df$vs) X_df$am &lt;- as.factor(X_df$am) X_df$gear &lt;- as.factor(X_df$gear) X_df$carb &lt;- as.factor(X_df$carb) css_res_df &lt;- css(X=X_df[selec_inds, ], y=y[selec_inds], lambda=0.01, B = 10) res_df &lt;- checkGetCssPredsInputs(css_res_df, testX=X_df[test_inds, ], weighting=&quot;simple_avg&quot;, cutoff=0.3, min_num_clusts=1, max_num_clusts=4, trainX=X_df[train_inds, ], trainY=y[train_inds]) testthat::expect_true(is.list(res_df)) testthat::expect_identical(names(res_df), c(&quot;trainXProvided&quot;, &quot;trainX&quot;, &quot;testX&quot;,&quot;feat_names&quot;, &quot;max_num_clusts&quot;)) testthat::expect_true(all(!is.na(res_df$trainX))) testthat::expect_true(is.matrix(res_df$trainX)) testthat::expect_true(is.numeric(res_df$trainX)) testthat::expect_equal(nrow(res_df$trainX), length(train_inds)) train_mat &lt;- stats::model.matrix(~ ., X_df[train_inds, ]) train_mat &lt;- train_mat[, colnames(train_mat) != &quot;(Intercept)&quot;] testthat::expect_equal(ncol(res_df$trainX), ncol(train_mat)) testthat::expect_true(all(abs(train_mat - res_df$trainX) &lt; 10^(-9))) testthat::expect_true(all(!is.na(res_df$testX))) testthat::expect_true(is.matrix(res_df$testX)) testthat::expect_true(is.numeric(res_df$testX)) testthat::expect_equal(nrow(res_df$testX), length(test_inds)) test_mat &lt;- stats::model.matrix(~ ., X_df[test_inds, ]) test_mat &lt;- test_mat[, colnames(test_mat) != &quot;(Intercept)&quot;] testthat::expect_equal(ncol(res_df$testX), ncol(test_mat)) testthat::expect_true(all(abs(test_mat - res_df$testX) &lt; 10^(-9))) }) ## ── Warning (&#39;&lt;text&gt;:251&#39;): checkGetCssPredsInputs works ──────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. testthat::expect_warning(...) ## 7. litr (local) checkGetCssPredsInputs(...) ## 8. litr (local) checkXInputResults(testX, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:278&#39;): checkGetCssPredsInputs works ──────────────────────── ## Column names were provided for testX but not for trainX (are you sure they both contain identical features in the same order?) ## Backtrace: ## 1. litr (local) checkGetCssPredsInputs(...) ## ## ── Warning (&#39;&lt;text&gt;:357&#39;): checkGetCssPredsInputs works ──────────────────────── ## Column names were provided for testX but not for trainX (are you sure they both contain identical features in the same order?) ## Backtrace: ## 1. litr (local) checkGetCssPredsInputs(...) Finally, tests for getCssPreds() testthat::test_that(&quot;getCssPreds works&quot;, { set.seed(70811) x_select &lt;- matrix(stats::rnorm(10*6), nrow=10, ncol=6) x_train &lt;- matrix(stats::rnorm(8*6), nrow=8, ncol=6) x_pred &lt;- matrix(stats::rnorm(7*6), nrow=7, ncol=6) y_select &lt;- stats::rnorm(10) y_train &lt;- stats::rnorm(8) good_clusters &lt;- list(&quot;red&quot;=1:2, &quot;blue&quot;=3:4, &quot;green&quot;=5) css_res &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) res &lt;- getCssPreds(css_res, testX=x_pred, trainX=x_train, trainY=y_train) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), 7) ##### Try other bad inputs testthat::expect_error(getCssPreds(css_res, testX=x_pred, cutoff=-0.5, trainX=x_train, trainY=y_train), &quot;cutoff &gt;= 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, cutoff=&quot;0.3&quot;, trainX=x_train, trainY=y_train), &quot;is.numeric(cutoff) | is.integer(cutoff) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, cutoff=as.numeric(NA), trainX=x_train, trainY=y_train), &quot;!is.na(cutoff) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, weighting=c(&quot;sparse&quot;, &quot;simple_avg&quot;), trainX=x_train, trainY=y_train), &quot;length(weighting) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, weighting=2, trainX=x_train, trainY=y_train), &quot;Weighting must be a character&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, weighting=&quot;spasre&quot;, trainX=x_train, trainY=y_train), &quot;Weighting must be a character and one of sparse, simple_avg, or weighted_avg&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, min_num_clusts=c(1, 2), trainX=x_train, trainY=y_train), &quot;length(min_num_clusts) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, min_num_clusts=&quot;2&quot;, trainX=x_train, trainY=y_train), &quot;is.numeric(min_num_clusts) | is.integer(min_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, min_num_clusts=0, trainX=x_train, trainY=y_train), &quot;min_num_clusts &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, min_num_clusts=10, trainX=x_train, trainY=y_train), &quot;min_num_clusts &lt;= p is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, max_num_clusts=&quot;5&quot;, trainX=x_train, trainY=y_train), &quot;is.numeric(max_num_clusts) | is.integer(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, max_num_clusts=4.5, trainX=x_train, trainY=y_train), &quot;max_num_clusts == round(max_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, min_num_clusts=3, max_num_clusts=2, trainX=x_train, trainY=y_train), &quot;max_num_clusts &gt;= min_num_clusts is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getCssPreds(css_res, testX=x_pred, max_num_clusts=10, trainX=x_train, trainY=y_train), &quot;max_num_clusts &lt;= p is not TRUE&quot;, fixed=TRUE) # Add training indices css_res_train &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B=10, train_inds=6:10) # Training indices should be ignored if new x is provided res &lt;- getCssPreds(css_res_train, testX=x_pred, trainX=x_train, trainY=y_train) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), 7) # Things should still work if new x is not provided res &lt;- getCssPreds(css_res_train, testX=x_pred) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), 7) # Try not providing training indices and omitting newX--should get error testthat::expect_error(getCssPreds(css_res, testX=x_pred), &quot;css was not provided with indices to set aside for model training (train_inds), so must provide new X in order to generate a design matrix&quot;, fixed=TRUE) # Try naming variables colnames(x_select) &lt;- LETTERS[1:6] css_res_named &lt;- css(X=x_select, y=y_select, lambda=0.01, clusters=good_clusters, B = 10) # Named variables for css matrix but not new one--should get a warning testthat::expect_warning(getCssPreds(css_res_named, testX=x_pred, trainX=x_train, trainY=y_train), &quot;New X provided had no variable names (column names) even though the X provided to css did.&quot;, fixed=TRUE) # Try mismatching variable names colnames(x_train) &lt;- LETTERS[2:7] colnames(x_pred) &lt;- LETTERS[1:6] testthat::expect_error(getCssPreds(css_res_named, testX=x_pred, trainX=x_train, trainY=y_train), &quot;identical(feat_names, colnames(css_X)) is not TRUE&quot;, fixed=TRUE) colnames(x_train) &lt;- LETTERS[1:6] colnames(x_pred) &lt;- LETTERS[2:7] testthat::expect_error(getCssPreds(css_res_named, testX=x_pred, trainX=x_train, trainY=y_train), &quot;identical(feat_names, colnames(css_X)) is not TRUE&quot;, fixed=TRUE) colnames(x_pred) &lt;- LETTERS[1:6] res_named &lt;- getCssPreds(css_res_named, testX=x_pred, trainX=x_train, trainY=y_train) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), 7) # Try data.frame input to css and getCssPreds X_df &lt;- datasets::mtcars n &lt;- nrow(X_df) y &lt;- stats::rnorm(n) selec_inds &lt;- 1:round(n/3) train_inds &lt;- (max(selec_inds) + 1):(max(selec_inds) + 17) test_inds &lt;- setdiff(1:n, c(selec_inds, train_inds)) css_res_df &lt;- css(X=X_df[c(selec_inds, train_inds), ], y=y[c(selec_inds, train_inds)], lambda=0.01, B = 10, train_inds=train_inds) res_df &lt;- getCssPreds(css_res_df, testX=X_df[test_inds, ]) testthat::expect_true(all(!is.na(res_df))) testthat::expect_true(is.numeric(res_df)) testthat::expect_equal(length(res_df), length(test_inds)) # Try again with X as a dataframe with factors (number of columns of final # design matrix after one-hot encoding factors won&#39;t match number of columns # of X_df) X_df$cyl &lt;- as.factor(X_df$cyl) X_df$vs &lt;- as.factor(X_df$vs) X_df$am &lt;- as.factor(X_df$am) X_df$gear &lt;- as.factor(X_df$gear) X_df$carb &lt;- as.factor(X_df$carb) css_res_df &lt;- css(X=X_df[selec_inds, ], y=y[selec_inds], lambda=0.01, B = 10) res_df &lt;- getCssPreds(css_res_df, testX=X_df[test_inds, ], trainX=X_df[train_inds, ], trainY=y[train_inds]) # TODO(gregfaletto): known issue--the above code produces the following # undesired warnings: # 1: In checkGetCssPredsInputs(css_results, testX, weighting, cutoff, : # Column names were provided for testX but not for trainX (are you sure they both contain identical features in the same order?) # 2: In checkXInputResults(newx, css_results$X) : # New X provided had no variable names (column names) even though the X provided to css did. testthat::expect_true(all(!is.na(res_df))) testthat::expect_true(is.numeric(res_df)) testthat::expect_equal(length(res_df), length(test_inds)) }) ## ── Warning (&#39;&lt;text&gt;:122&#39;): getCssPreds works ─────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. testthat::expect_warning(...) ## 7. litr (local) getCssPreds(...) ## 8. litr (local) checkGetCssPredsInputs(...) ## 9. litr (local) checkXInputResults(testX, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:122&#39;): getCssPreds works ─────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. testthat::expect_warning(...) ## 7. litr (local) getCssPreds(...) ## 8. litr (local) formCssDesign(...) ## 9. litr (local) checkFormCssDesignInputs(...) ## 10. litr (local) checkXInputResults(newx, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:122&#39;): getCssPreds works ─────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. testthat::expect_warning(...) ## 7. litr (local) getCssPreds(...) ## 8. litr (local) formCssDesign(...) ## 9. litr (local) checkFormCssDesignInputs(...) ## 10. litr (local) checkXInputResults(newx, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:143&#39;): getCssPreds works ─────────────────────────────────── ## Column names were provided for testX but not for trainX (are you sure they both contain identical features in the same order?) ## Backtrace: ## 1. litr (local) getCssPreds(...) ## 2. litr (local) checkGetCssPredsInputs(...) ## ## ── Warning (&#39;&lt;text&gt;:143&#39;): getCssPreds works ─────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. litr (local) getCssPreds(...) ## 2. litr (local) formCssDesign(...) ## 3. litr (local) checkFormCssDesignInputs(...) ## 4. litr (local) checkXInputResults(newx, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:181&#39;): getCssPreds works ─────────────────────────────────── ## Column names were provided for testX but not for trainX (are you sure they both contain identical features in the same order?) ## Backtrace: ## 1. litr (local) getCssPreds(...) ## 2. litr (local) checkGetCssPredsInputs(...) ## ## ── Warning (&#39;&lt;text&gt;:181&#39;): getCssPreds works ─────────────────────────────────── ## New X provided had no variable names (column names) even though the X provided to css did. ## Backtrace: ## 1. litr (local) getCssPreds(...) ## 2. litr (local) formCssDesign(...) ## 3. litr (local) checkFormCssDesignInputs(...) ## 4. litr (local) checkXInputResults(newx, css_results$X) ## ## ── Warning (&#39;&lt;text&gt;:181&#39;): getCssPreds works ─────────────────────────────────── ## prediction from a rank-deficient fit may be misleading ## Backtrace: ## 1. litr (local) getCssPreds(...) ## 2. stats::predict.lm(model, newdata = df_test) "],["other-useful.html", "6 Other useful functions", " 6 Other useful functions The following are some other functions that are useful for specific tasks. genClusteredData() generates jointly Gaussian data sets that include clusters of features that are correlated with a latent feature (the latent features themselves are also provided), as in the simulation in Example 1, Section 5.1, and Section 5.2 of Faletto and Bien (2022). genClusteredDataWeighted() generates jointly Gaussian data sets that include clusters of features that are correlated with a latent feature with unequal correlations (the latent features themselves are also provided), as in the simulation Section 5.3 of Faletto and Bien (2022). genClusteredDataWeightedRandom() generates jointly Gaussian data sets that include clusters of features that are correlated with a latent feature with unequal correlations (the latent features themselves are also provided) that are determined at random. getLassoLambda() uses a data set to choose a good value of lambda for subsamples of size n/2 (as in cluster stability selection) by cross-validation. getModelSize() estimates the best size for a lasso model on a provided data set. printCssDf() converts the output of the css() function (an object of class cssr) to a data.frame that is ready to be printed. We provide end-user access to printCssDf() because this data.frame itself may be useful as an object that summarizes the output from css(). print.cssr() is the print function for objects of class cssr. genClusteredData() checkGenClusteredDataInputs() checks that the inputs to genClusteredData() are as expected. genZmuY() generates the latent Z, the weak signal and noise features in X, the latent mu, and the observed y from the specified parameters. getNoiseVar() calculates the variance of the noise to add to Z so that the proxies have the specified correlation with each other. genClusteredDataWeighted() checkGenClusteredDataWeightedInputs() verifies the inputs to genClusteredDataWeighted(). getLassoLambda() getModelSize() printCssDf() getSelectionPrototypes() identifies the prototypes from selected clusters (the feature in each cluster that is most correlated with the response) print.cssr() genClusteredData() #&#39; Generate randomly sampled data including noisy observations of latent #&#39; variables #&#39; #&#39; Generate a data set including latent features Z, observed features X (which #&#39; may include noisy or noiseless observations of the latent features in Z), #&#39; an observed response y which is a linear model of features from Z and X as #&#39; well as independent mean zero noise, and mu (the responses from y without #&#39; the added noise). Data is generated in the same way as in the simulations #&#39; from Faletto and Bien (2022). #&#39; @param n Integer or numeric; the number of observations to generate. (The #&#39; generated X and Z will have n rows, and the generated y and mu will have #&#39; length n.) #&#39; @param p Integer or numeric; the number of features to generate. The #&#39; generated X will have p columns. #&#39; @param k_unclustered Integer or numeric; the number of features in X that #&#39; will have nonzero coefficients in the true model for y among those features #&#39; not generated from the n_clusters latent variables (called &quot;weak signal&quot; #&#39; features in the simulations from Faletto and Bien 2022). The coefficients on #&#39; these features will be determined by beta_unclustered. Must be at least 1. #&#39; @param cluster_size Integer or numeric; for each of the n_clusters latent #&#39; variables, X will contain cluster_size noisy proxies that are correlated with #&#39; the latent variable. Must be at least 2. #&#39; @param n_clusters Integer or numeric; the number of latent variables to #&#39; generate, each of which will be associated with an observed cluster in X. #&#39; Must be at least 1. Default is 1. #&#39; @param sig_clusters Integer or numeric; the number of generated latent #&#39; features that will have nonzero coefficients in the true model for y (all of #&#39; them will have coefficient beta_latent). Must be less than or equal to #&#39; n_clusters. Default is 1. #&#39; @param rho Integer or numeric; the correlation of the proxies in each cluster #&#39; with the latent variable. Must be greater than 0. Default is 0.9. #&#39; @param beta_latent Integer or numeric; the coefficient used for all #&#39; sig_clusters latent variables that have nonzero coefficients in the true #&#39; model for y. Can&#39;t equal 0. Default is 1.5. #&#39; @param beta_unclustered Integer or numeric; the maximum coefficient in the #&#39; model for y among the k_unclustered features in X not generated from the #&#39; latent variables. The coefficients of the features will be #&#39; beta_unclustered/sqrt(1:k_unclustered). Can&#39;t equal 0. Default is 1. #&#39; @param snr Integer or numeric; the signal-to-noise ratio of the response #&#39; y. If sigma_eps_sq is not specified, the variance of the noise in y will be #&#39; calculated using the formula sigma_eps_sq = sum(mu^2)/(n * snr). Only one of #&#39; snr and sigma_eps_sq must be specified. Default is NA. #&#39; @param sigma_eps_sq Integer or numeric; the variance on the noise added #&#39; to y. Only one of snr and sigma_eps_sq must be specified. Default is NA. #&#39; @return A list of the following elements. \\item{X}{An n x p numeric matrix of #&#39; n observations from a p-dimensional multivariate normal distribution #&#39; generated using the specified parameters. The first n_clusters times #&#39; cluster_size features will be the clusters of features correlated with the #&#39; n_clusters latent variables. The next k_unclustered features will be the #&#39; &quot;weak signal&quot; features, and the remaining p - n_clusters*cluster_size - #&#39; k_unclustered features will be the unclustered noise features.} \\item{y}{A #&#39; length n numeric vector; the response generated from X, the latent features #&#39; from Z, and the coefficient vector, along with additive noise.} \\item{Z}{The #&#39; latent features; either a numeric vector (if n_clusters &gt; 1) or a numeric #&#39; matrix (if n_clusters &gt; 1). Note that (X, Z) is multivariate Gaussian.} #&#39; item{mu}{A length `n` numeric vector; the expected response given X, Z, and #&#39; the true coefficient vector (equal to y minus the added noise).} #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references &lt;&lt;faletto2022&gt;&gt; #&#39; @export genClusteredData &lt;- function(n, p, k_unclustered, cluster_size, n_clusters=1, sig_clusters=1, rho=0.9, beta_latent=1.5, beta_unclustered=1, snr=as.numeric(NA), sigma_eps_sq=as.numeric(NA)){ # Check inputs checkGenClusteredDataInputs(p, k_unclustered, cluster_size, n_clusters, sig_clusters, rho, beta_latent, beta_unclustered, snr, sigma_eps_sq) ret &lt;- genZmuY(n=n, p=p, k_unclustered=k_unclustered, cluster_size=cluster_size, n_clusters=n_clusters, sig_clusters=sig_clusters, beta_latent=beta_latent, beta_unclustered=beta_unclustered, snr=snr, sigma_eps_sq=sigma_eps_sq) Z &lt;- ret$Z y &lt;- ret$y mu &lt;- ret$mu other_X &lt;- ret$other_X # Finally, generate clusters of proxies to complete X. First, get needed # variances of noise to add noise_var &lt;- getNoiseVar(rho) # Generate these noise features noise_mat &lt;- matrix(stats::rnorm(n*n_clusters*cluster_size, mean=0, sd=sqrt(noise_var)), n, n_clusters*cluster_size) # Create matrix of proxies proxy_mat &lt;- matrix(as.numeric(NA), n, n_clusters*cluster_size) if(n_clusters &gt; 1){ for(i in 1:n_clusters){ first_ind &lt;- (i - 1)*cluster_size + 1 last_ind &lt;- i*cluster_size proxy_mat[, first_ind:last_ind] &lt;- Z[, i] + noise_mat[, first_ind:last_ind] } } else{ stopifnot(ncol(noise_mat) == cluster_size) proxy_mat[, 1:cluster_size] &lt;- Z + noise_mat } X &lt;- cbind(proxy_mat, other_X) Z &lt;- as.matrix(Z) # Check output stopifnot(length(mu) == n) stopifnot(nrow(X) == n) stopifnot(ncol(X) == p) if(any(!is.na(Z))){ stopifnot(nrow(Z) == n) stopifnot(ncol(Z) == n_clusters) } return(list(X=X, y=y, Z=Z, mu=mu)) } checkGenClusteredDataInputs() #&#39; Check inputs to genClusteredData #&#39; #&#39; @param p Integer or numeric; the number of features to generate. The #&#39; generated X will have p columns. #&#39; @param k_unclustered Integer or numeric; the number of features in X that #&#39; will have nonzero coefficients in the true model for y among those features #&#39; not generated from the n_clusters latent variables (called &quot;weak signal&quot; #&#39; features in the simulations from Faletto and Bien 2022). The coefficients on #&#39; these features will be determined by beta_unclustered. #&#39; @param cluster_size Integer or numeric; for each of the n_clusters latent #&#39; variables, X will contain cluster_size noisy proxies that are correlated with #&#39; the latent variable. #&#39; @param n_clusters Integer or numeric; the number of latent variables to #&#39; generate, each of which will be associated with an observed cluster in X. #&#39; Must be at least 1. Default is 1. #&#39; @param sig_clusters Integer or numeric; the number of generated latent #&#39; features that will have nonzero coefficients in the true model for y (all of #&#39; them will have coefficient beta_latent). Must be less than or equal to #&#39; n_clusters. Default is 1. #&#39; @param rho Integer or numeric; the covariance of the proxies in each cluster #&#39; with the latent variable (and each other). Note that the correlation between #&#39; the features in the cluster will be rho/var. Can&#39;t equal 0. Default is 0.9. #&#39; @param beta_latent Integer or numeric; the coefficient used for all #&#39; sig_clusters latent variables that have nonzero coefficients in the true #&#39; model for y. Can&#39;t equal 0. Default is 1.5. #&#39; @param beta_unclustered Integer or numeric; the maximum coefficient in the #&#39; model for y among the k_unclustered features in X not generated from the #&#39; latent variables. The coefficients of the features will be #&#39; beta_unclustered/sqrt(1:k_unclustered). Can&#39;t equal 0. Default is 1. #&#39; @param snr Integer or numeric; the signal-to-noise ratio of the response #&#39; y. If sigma_eps_sq is not specified, the variance of the noise in y will be #&#39; calculated using the formula sigma_eps_sq = sum(mu^2)/(n * snr). Only one of #&#39; snr and sigma_eps_sq must be specified. Default is NA. #&#39; @param sigma_eps_sq Integer or numeric; the variance on the noise added #&#39; to y. Only one of snr and sigma_eps_sq must be specified. Default is NA. #&#39; @return A list of the following elements. \\item{X}{An n x p numeric matrix of #&#39; n observations from a p-dimensional multivariate normal distribution #&#39; generated using the specified parameters. The first n_clusters times #&#39; cluster_size features will be the clusters of features correlated with the #&#39; n_clusters latent variables. The next k_unclustered features will be the #&#39; &quot;weak signal&quot; features, and the remaining p - n_clusters*cluster_size - #&#39; k_unclustered features will be the unclustered noise features.} \\item{y}{A #&#39; length n numeric vector; the response generated from X, the latent features #&#39; from Z, and the coefficient vector, along with additive noise.} \\item{Z}{The #&#39; latent features; either a numeric vector (if n_clusters &gt; 1) or a numeric #&#39; matrix (if n_clusters &gt; 1). Note that (X, Z) is multivariate Gaussian.} #&#39; item{mu}{A length `n` numeric vector; the expected response given X, Z, and #&#39; the true coefficient vector (equal to y minus the added noise).} #&#39; @author Gregory Faletto, Jacob Bien checkGenClusteredDataInputs &lt;- function(p, k_unclustered, cluster_size, n_clusters, sig_clusters, rho, beta_latent, beta_unclustered, snr, sigma_eps_sq){ stopifnot(is.numeric(sig_clusters) | is.integer(sig_clusters)) stopifnot(sig_clusters &lt;= n_clusters) stopifnot(sig_clusters &gt;= 0) stopifnot(sig_clusters == round(sig_clusters)) stopifnot(is.numeric(n_clusters) | is.integer(n_clusters)) stopifnot(n_clusters == round(n_clusters)) # TODO(gregfaletto): is it easy to remove the requirement that n_clusters is # at least 1 (so that it&#39;s possible to generate data with no latent # features)? If so, should only check that cluster_size &gt;= 1 if n_clusters # &gt;= 1, and in makeCovarianceMatrix function only need block_size &gt;= 1 # rather than 2. stopifnot(n_clusters &gt;= 1) stopifnot(cluster_size &gt;= 2) stopifnot(rho &gt; 0) stopifnot(beta_latent != 0) stopifnot(beta_unclustered != 0) stopifnot(is.numeric(k_unclustered) | is.integer(k_unclustered)) stopifnot(k_unclustered &gt;= 2) stopifnot(k_unclustered == round(k_unclustered)) stopifnot(p &gt;= n_clusters*cluster_size + k_unclustered) # Same as make_sparse_blocked_linear_model_random, but ith coefficient # of weak signal features is beta_unclustered/sqrt(i) in order to have # a definitive ranking of weak signal features. if(is.na(snr) &amp; is.na(sigma_eps_sq)){ stop(&quot;Must specify one of snr or sigma_eps_sq&quot;) } if(is.na(snr)){ stopifnot(all(!is.na(sigma_eps_sq))) stopifnot(is.numeric(sigma_eps_sq) | is.integer(sigma_eps_sq)) stopifnot(length(sigma_eps_sq) == 1) stopifnot(sigma_eps_sq &gt;= 0) } else{ stopifnot(is.numeric(snr) | is.integer(snr)) stopifnot(length(snr) == 1) stopifnot(snr &gt; 0) } } Tests for checkGenClusteredDataInputs() testthat::test_that(&quot;checkGenClusteredDataInputs works&quot;, { set.seed(7612) # Should get no error checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=NA, sigma_eps_sq=.5) checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA) # sig_clusters testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=&quot;2&quot;, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;is.numeric(sig_clusters) | is.integer(sig_clusters) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=4, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;sig_clusters &lt;= n_clusters is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=-1, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;sig_clusters &gt;= 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=.6, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;sig_clusters == round(sig_clusters) is not TRUE&quot;, fixed=TRUE) # n_clusters testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=&quot;3&quot;, sig_clusters=2, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;is.numeric(n_clusters) | is.integer(n_clusters) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3.2, sig_clusters=2, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;n_clusters == round(n_clusters) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=0, sig_clusters=0, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;n_clusters &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=.3, n_clusters=3, sig_clusters=2, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;cluster_size &gt;= 2 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=16, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;p &gt;= n_clusters * cluster_size + k_unclustered is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;rho &gt; 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=0, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;beta_latent != 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=0, snr=1, sigma_eps_sq=NA), &quot;beta_unclustered != 0 is not TRUE&quot;, fixed=TRUE) # k_unclustered testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=&quot;2&quot;, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;is.numeric(k_unclustered) | is.integer(k_unclustered) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=-2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;k_unclustered &gt;= 2 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2.2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;k_unclustered == round(k_unclustered) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=-2, snr=NA, sigma_eps_sq=NA), &quot;Must specify one of snr or sigma_eps_sq&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=-2, snr=-.2, sigma_eps_sq=NA), &quot;snr &gt; 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGenClusteredDataInputs(p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=-2, snr=NA, sigma_eps_sq=-.3), &quot;sigma_eps_sq &gt;= 0 is not TRUE&quot;, fixed=TRUE) }) ## Test passed 😀 genZmuY() #&#39; Generates Z, weak signal features in X, noise features in X, mu, and y #&#39; from provided parameters #&#39; #&#39; @param n Integer or numeric; the number of observations to generate. (The #&#39; generated X and Z will have n rows, and the generated y and mu will have #&#39; length n.) #&#39; @param p Integer or numeric; the number of features to generate. The #&#39; generated X will have p columns. #&#39; @param k_unclustered Integer or numeric; the number of features in X that #&#39; will have nonzero coefficients in the true model for y among those features #&#39; not generated from the n_clusters latent variables (called &quot;weak signal&quot; #&#39; features in the simulations from Faletto and Bien 2022). The coefficients on #&#39; these features will be determined by beta_unclustered. Must be at least 1. #&#39; @param cluster_size Integer or numeric; for each of the n_clusters latent #&#39; variables, X will contain cluster_size noisy proxies that are correlated with #&#39; the latent variable. Must be at least 2. #&#39; @param n_clusters Integer or numeric; the number of latent variables to #&#39; generate, each of which will be associated with an observed cluster in X. #&#39; Must be at least 1. Default is 1. #&#39; @param sig_clusters Integer or numeric; the number of generated latent #&#39; features that will have nonzero coefficients in the true model for y (all of #&#39; them will have coefficient beta_latent). Must be less than or equal to #&#39; n_clusters. Default is 1. #&#39; @param beta_latent Integer or numeric; the coefficient used for all #&#39; sig_clusters latent variables that have nonzero coefficients in the true #&#39; model for y. Can&#39;t equal 0. Default is 1.5. #&#39; @param beta_unclustered Integer or numeric; the maximum coefficient in the #&#39; model for y among the k_unclustered features in X not generated from the #&#39; latent variables. The coefficients of the features will be #&#39; beta_unclustered/sqrt(1:k_unclustered). Can&#39;t equal 0. Default is 1. #&#39; @param snr Integer or numeric; the signal-to-noise ratio of the response #&#39; y. If sigma_eps_sq is not specified, the variance of the noise in y will be #&#39; calculated using the formula sigma_eps_sq = sum(mu^2)/(n * snr). Only one of #&#39; snr and sigma_eps_sq must be specified. Default is NA. #&#39; @param sigma_eps_sq Integer or numeric; the variance on the noise added #&#39; to y. Only one of snr and sigma_eps_sq must be specified. Default is NA. #&#39; @return A list of the following elements. \\item{Z}{The #&#39; latent features; either a numeric vector (if n_clusters &gt; 1) or a numeric #&#39; matrix (if n_clusters &gt; 1). Note that (X, Z) is multivariate Gaussian.} #&#39; item{mu}{A length `n` numeric vector; the expected response given X, Z, and #&#39; the true coefficient vector (equal to y minus the added noise).} \\item{y}{A #&#39; length n numeric vector; the response generated from X, the latent features #&#39; from Z, and the coefficient vector, along with additive noise.} #&#39; \\item{other_X}{A numeric matrix of n observations from a multivariate normal #&#39; distribution generated using the specified parameters, containing the weak #&#39; signal features and the noise features that will eventually be in X. (The #&#39; only missing features are the proxies for the latent features Z.) #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references &lt;&lt;faletto2022&gt;&gt; genZmuY &lt;- function(n, p, k_unclustered, cluster_size, n_clusters, sig_clusters, beta_latent, beta_unclustered, snr, sigma_eps_sq){ # Generate Z, weak signal features, and noise features (total of # p - n_clusters*(cluster_size - 1)) features) p_orig_feat_mat &lt;- p - n_clusters*(cluster_size - 1) stopifnot(p_orig_feat_mat &gt;= k_unclustered + n_clusters) orig_feat_mat &lt;- matrix(stats::rnorm(n*p_orig_feat_mat), n, p_orig_feat_mat) # First n_clusters features are Z. Next k_unclustered features are weak # signal features. Any remaining features are noise features. Z &lt;- orig_feat_mat[, 1:n_clusters] other_X &lt;- orig_feat_mat[, (n_clusters + 1):p_orig_feat_mat] # Ready to create mu and y if(n_clusters &gt; 1){ if(sig_clusters &gt; 1){ mu &lt;- Z[, 1:sig_clusters] %*% rep(beta_latent, sig_clusters) } else{ mu &lt;- Z[, 1:sig_clusters] * beta_latent } } else{ mu &lt;- Z*beta_latent } for(j in 1:k_unclustered){ mu &lt;- mu + beta_unclustered/sqrt(j)*other_X[, j] } mu &lt;- as.numeric(mu) # If SNR is null, use sigma_eps_sq if(!is.na(sigma_eps_sq)){ sd &lt;- sqrt(sigma_eps_sq) }else{ sd &lt;- sqrt(sum(mu^2) / (n * snr)) # taking snr = ||mu||^2 /(n * sigma^2) } stopifnot(is.numeric(sd) | is.integer(sd)) stopifnot(length(sd) == 1) stopifnot(!is.na(sd)) stopifnot(sd &gt;= 0) y &lt;- as.numeric(mu + rnorm(n, mean=0, sd=sd)) return(list(Z=Z, mu=mu, y=y, other_X=other_X)) } No tests for genZmuY(). getNoiseVar(): #&#39; Get variance of noise to add to Z in order to yield proxies X with desired #&#39; correlations with Z #&#39; #&#39; @param cor A numeric vector of desired correlations for each proxy to have #&#39; with Z. Note: correlations must be positive. #&#39; @return A vector of variances of independent Gaussian random variables to add #&#39; to Z in order to yield proxies with the desired correlations with Z. #&#39; @author Gregory Faletto, Jacob Bien #&#39; @export getNoiseVar &lt;- function(cor){ # Correlation between standard normal Z and X = Z + epsilon where epsilon # is normal, independent of Z, and has mean 0 and variance sig_eps_sq: # # E[Z X]/sqrt{Var(Z) Var(X)} # = (E[Z^2] + E[Z*epsilon])/sqrt{1*(1 + sig_eps_sq)} # = (1 + 0)/sqrt{1 + sig_eps_sq} # # So we have # cor = 1/sqrt{1 + sig_eps_sq} # \\iff 1 + sig_eps_sq = 1/cor^2 # \\iff sig_eps_sq = 1/cor^2 - 1 stopifnot(is.numeric(cor) | is.integer(cor)) stopifnot(all(!is.na(cor))) stopifnot(length(cor) &gt;= 1) stopifnot(all(cor &gt; 0)) stopifnot(all(cor &lt;= 1)) return(1/cor^2 - 1) } No tests for getNoiseVar(). Finally, tests for genClusteredData() testthat::test_that(&quot;genClusteredData works&quot;, { set.seed(23478) ret &lt;- genClusteredData(n=25, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=.99, beta_latent=1.5, beta_unclustered=-2, snr=NA, sigma_eps_sq=.5) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;X&quot;, &quot;y&quot;, &quot;Z&quot;, &quot;mu&quot;)) testthat::expect_true(is.numeric(ret$X)) testthat::expect_true(is.matrix(ret$X)) testthat::expect_equal(ncol(ret$X), 19) testthat::expect_equal(nrow(ret$X), 25) # X is Gaussian with mean 0 and variance 4; expect all observations to lie # within 5 standard deviations of mean testthat::expect_true(all(abs(ret$X) &lt; 5*2)) # Test that clusters are correlated--within-cluster correlation should be # high, correlation with other features should be low testthat::expect_true(min(cor(ret$X[, 1:5])) &gt; .9) testthat::expect_true(max(abs(cor(ret$X[, 1:5], ret$X[, 6:19]))) &lt; .6) testthat::expect_true(min(cor(ret$X[, 6:10])) &gt; .9) testthat::expect_true(max(abs(cor(ret$X[, 6:10], ret$X[, c(1:5, 11:19)]))) &lt; .6) testthat::expect_true(min(cor(ret$X[, 11:15])) &gt; .9) testthat::expect_true(max(abs(cor(ret$X[, 11:15], ret$X[, c(1:10, 16:19)]))) &lt; .6) cor_indeps &lt;- cor(ret$X[, 16:19]) testthat::expect_true(max(abs(cor_indeps[lower.tri(cor_indeps)])) &lt; .6) testthat::expect_true(is.numeric(ret$y)) testthat::expect_equal(length(ret$y), 25) testthat::expect_true(is.numeric(ret$Z)) testthat::expect_true(is.matrix(ret$Z)) testthat::expect_equal(nrow(ret$Z), 25) testthat::expect_equal(ncol(ret$Z), 3) testthat::expect_true(is.numeric(ret$mu)) testthat::expect_equal(length(ret$mu), 25) # Because y is Gaussian with mean mu and standard deviation .5 conditional on # mu, expect all observations to lie within 5 sds of mu testthat::expect_true(all(abs(ret$y - ret$mu) &lt; 5*.5)) # Specify SNR instead of sigma_eps_sq ret &lt;- genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;X&quot;, &quot;y&quot;, &quot;Z&quot;, &quot;mu&quot;)) # If sigma_eps_sq is specified, snr should be ignored. (Set an SNR that # implies a very large noise variance to test this) ret &lt;- genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=.01, sigma_eps_sq=.25) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;X&quot;, &quot;y&quot;, &quot;Z&quot;, &quot;mu&quot;)) # Because y is Gaussian with mean mu and standard deviation .5 conditional on # mu, expect all observations to lie within 5 sds of mu testthat::expect_true(all(abs(ret$y - ret$mu) &lt; 5*.25)) # Try a single latent variable (z should be a one-column matrix) ret &lt;- genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=1, sig_clusters=1, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=NA, sigma_eps_sq=.5) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;X&quot;, &quot;y&quot;, &quot;Z&quot;, &quot;mu&quot;)) testthat::expect_true(is.numeric(ret$Z)) testthat::expect_true(is.matrix(ret$Z)) testthat::expect_equal(nrow(ret$Z), 5) testthat::expect_equal(ncol(ret$Z), 1) # Bad inputs testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=&quot;2&quot;, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;is.numeric(sig_clusters) | is.integer(sig_clusters) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=4, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;sig_clusters &lt;= n_clusters is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=-1, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;sig_clusters &gt;= 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=.6, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;sig_clusters == round(sig_clusters) is not TRUE&quot;, fixed=TRUE) # n_clusters testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=&quot;3&quot;, sig_clusters=2, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;is.numeric(n_clusters) | is.integer(n_clusters) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3.2, sig_clusters=2, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;n_clusters == round(n_clusters) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=0, sig_clusters=0, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;n_clusters &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=.3, n_clusters=3, sig_clusters=2, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;cluster_size &gt;= 2 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(p=16, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;p &gt;= n_clusters * cluster_size + k_unclustered is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;rho &gt; 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=0, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;beta_latent != 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=0, snr=1, sigma_eps_sq=NA), &quot;beta_unclustered != 0 is not TRUE&quot;, fixed=TRUE) # k_unclustered testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=&quot;2&quot;, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;is.numeric(k_unclustered) | is.integer(k_unclustered) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=-2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;k_unclustered &gt;= 2 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2.2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA), &quot;k_unclustered == round(k_unclustered) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=-2, snr=NA, sigma_eps_sq=NA), &quot;Must specify one of snr or sigma_eps_sq&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=-2, snr=-.2, sigma_eps_sq=NA), &quot;snr &gt; 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(genClusteredData(n=5, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho=0.8, beta_latent=1.5, beta_unclustered=-2, snr=NA, sigma_eps_sq=-.3), &quot;sigma_eps_sq &gt;= 0 is not TRUE&quot;, fixed=TRUE) }) ## Test passed 😀 genClusteredDataWeighted() #&#39; Generate randomly sampled data including noisy observations of latent #&#39; variables, where proxies differ in their relevance (noise level) #&#39; #&#39; Generate a data set including latent features Z, observed features X (which #&#39; may include noisy or noiseless observations of the latent features in Z), #&#39; an observed response y which is a linear model of features from Z and X as #&#39; well as independent mean zero noise, and mu (the responses from y without #&#39; the added noise). Data is generated in the same way as in the simulations #&#39; from Section 5.3 of Faletto and Bien (2022). #&#39; @param n Integer or numeric; the number of observations to generate. (The #&#39; generated X and Z will have n rows, and the generated y and mu will have #&#39; length n.) #&#39; @param p Integer or numeric; the number of features to generate. The #&#39; generated X will have p columns. #&#39; @param k_unclustered Integer or numeric; the number of features in X that #&#39; will have nonzero coefficients in the true model for y among those features #&#39; not generated from the n_clusters latent variables (called &quot;weak signal&quot; #&#39; features in the simulations from Faletto and Bien 2022). The coefficients on #&#39; these features will be determined by beta_unclustered. #&#39; @param cluster_size Integer or numeric; for each of the n_clusters latent #&#39; variables, X will contain cluster_size noisy proxies that are correlated with #&#39; the latent variable. #&#39; @param n_strong_cluster_vars Integer or numeric; among the cluster_size #&#39; proxies in each cluster, the first n_strong_cluster_vars will have a high #&#39; covariance (rho_high) with the latent variable and the next cluster_size - #&#39; n_strong_cluster_vars will have a low covariance (rho_low) with the latent #&#39; variable. #&#39; @param n_clusters Integer or numeric; the number of latent variables to #&#39; generate, each of which will be associated with an observed cluster in X. #&#39; Must be at least 1. Default is 1. #&#39; @param sig_clusters Integer or numeric; the number of generated latent #&#39; features that will have nonzero coefficients in the true model for y (all of #&#39; them will have coefficient beta_latent). Must be less than or equal to #&#39; n_clusters. Default is 1. #&#39; @param rho_high Integer or numeric; the covariance of the &quot;strong proxies&quot; in #&#39; each cluster with the latent variable (and each other). Note that the #&#39; correlation between the &quot;strong proxy&quot; features in the cluster will be #&#39; rho_high/var. rho_high cannot equal 0 and must be at least as large as #&#39; rho_low. Default is 0.9. #&#39; @param rho_low Integer or numeric; the covariance of the &quot;weak proxies&quot; in #&#39; each cluster with the latent variable (and each other). Note that the #&#39; correlation between the &quot;weak proxy&quot; features in the cluster will be #&#39; rho_low/var. rho_low cannot equal 0 and must be no larger than rho_high. #&#39; Default is 0.5. #&#39; @param var Integer or numeric; the variance of all of the observed features #&#39; in X (both the proxies for the latent variables and the k_unclustered other #&#39; features). Can&#39;t equal 0. Default is 1. #&#39; @param beta_latent Integer or numeric; the coefficient used for all #&#39; sig_clusters latent variables that have nonzero coefficients in the true #&#39; model for y. Can&#39;t equal 0. Default is 1.5. #&#39; @param beta_unclustered Integer or numeric; the maximum coefficient in the #&#39; model for y among the k_unclustered features in X not generated from the #&#39; latent variables. The coefficients of the features will be #&#39; beta_unclustered/sqrt(1:k_unclustered). Can&#39;t equal 0. Default is 1. #&#39; @param snr Integer or numeric; the signal-to-noise ratio of the response #&#39; y. If sigma_eps_sq is not specified, the variance of the noise in y will be #&#39; calculated using the formula sigma_eps_sq = sum(mu^2)/(n * snr). Only one of #&#39; snr and sigma_eps_sq must be specified. Default is NA. #&#39; @param sigma_eps_sq Integer or numeric; the variance on the noise added #&#39; to y. Only one of snr and sigma_eps_sq must be specified. Default is NA. #&#39; @return A list of the following elements. \\item{X}{An n x p numeric matrix of #&#39; n observations from a p-dimensional multivariate normal distribution #&#39; generated using the specified parameters. The first n_clusters times #&#39; cluster_size features will be the clusters of features correlated with the #&#39; n_clusters latent variables. The next k_unclustered features will be the #&#39; &quot;weak signal&quot; features, and the remaining p - n_clusters*cluster_size - #&#39; k_unclustered features will be the unclustered noise features.} \\item{y}{A #&#39; length n numeric vector; the response generated from X, the latent features #&#39; from Z, and the coefficient vector, along with additive noise.} \\item{Z}{The #&#39; latent features; either a numeric vector (if n_clusters &gt; 1) or a numeric #&#39; matrix (if n_clusters &gt; 1). Note that (X, Z) is multivariate Gaussian.} #&#39; \\item{mu}{A length `n` numeric vector; the expected response given X, Z, and #&#39; the true coefficient vector (equal to y minus the added noise).} #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references &lt;&lt;faletto2022&gt;&gt; #&#39; @export genClusteredDataWeighted &lt;- function(n, p, k_unclustered, cluster_size, n_strong_cluster_vars, n_clusters=1, sig_clusters=1, rho_high=0.9, rho_low=0.5, beta_latent=1.5, beta_unclustered=1, snr=as.numeric(NA), sigma_eps_sq=as.numeric(NA)){ # Check inputs checkGenClusteredDataWeightedInputs(p, k_unclustered, cluster_size, n_strong_cluster_vars, n_clusters, sig_clusters, rho_high, rho_low, beta_latent, beta_unclustered, snr, sigma_eps_sq) ret &lt;- genZmuY(n=n, p=p, k_unclustered=k_unclustered, cluster_size=cluster_size, n_clusters=n_clusters, sig_clusters=sig_clusters, beta_latent=beta_latent, beta_unclustered=beta_unclustered, snr=snr, sigma_eps_sq=sigma_eps_sq) Z &lt;- ret$Z y &lt;- ret$y mu &lt;- ret$mu other_X &lt;- ret$other_X # Finally, generate clusters of proxies to complete X. noise_var_high &lt;- getNoiseVar(rho_high) noise_var_low &lt;- getNoiseVar(rho_low) # Create matrix of proxies Z &lt;- as.matrix(Z) proxy_mat &lt;- matrix(as.numeric(NA), n, n_clusters*cluster_size) for(i in 1:n_clusters){ for(j in 1:n_strong_cluster_vars){ proxy_mat[, (i - 1)*cluster_size + j] &lt;- Z[, i] + rnorm(n, mean=0, sd=sqrt(noise_var_high)) } for(j in (n_strong_cluster_vars + 1):cluster_size){ proxy_mat[, (i - 1)*cluster_size + j] &lt;- Z[, i] + rnorm(n, mean=0, sd=sqrt(noise_var_low)) } } X &lt;- cbind(proxy_mat, other_X) # Check output stopifnot(length(mu) == n) stopifnot(nrow(X) == n) stopifnot(ncol(X) == p) if(any(!is.na(Z))){ stopifnot(nrow(Z) == n) stopifnot(ncol(Z) == n_clusters) } return(list(X=X, y=y, Z=Z, mu=mu)) } checkGenClusteredDataWeightedInputs() #&#39; Check inputs to genClusteredDataWeighted #&#39; #&#39; @param n Integer or numeric; the number of observations to generate. (The #&#39; generated X and Z will have n rows, and the generated y and mu will have #&#39; length n.) #&#39; @param p Integer or numeric; the number of features to generate. The #&#39; generated X will have p columns. #&#39; @param k_unclustered Integer or numeric; the number of features in X that #&#39; will have nonzero coefficients in the true model for y among those features #&#39; not generated from the n_clusters latent variables (called &quot;weak signal&quot; #&#39; features in the simulations from Faletto and Bien 2022). The coefficients on #&#39; these features will be determined by beta_unclustered. #&#39; @param cluster_size Integer or numeric; for each of the n_clusters latent #&#39; variables, X will contain cluster_size noisy proxies that are correlated with #&#39; the latent variable. #&#39; @param n_strong_cluster_vars Integer or numeric; among the cluster_size #&#39; proxies in each cluster, n_strong_cluster_vars will have a high covariance #&#39; (rho_high) with the latent variable and cluster_size - n_strong_cluster_vars #&#39; will have a low covariance (rho_low) with the latent variable. #&#39; @param n_clusters Integer or numeric; the number of latent variables to #&#39; generate, each of which will be associated with an observed cluster in X. #&#39; Must be at least 1. Default is 1. #&#39; @param sig_clusters Integer or numeric; the number of generated latent #&#39; features that will have nonzero coefficients in the true model for y (all of #&#39; them will have coefficient beta_latent). Must be less than or equal to #&#39; n_clusters. Default is 1. #&#39; @param rho_high Integer or numeric; the covariance of the &quot;strong proxies&quot; in #&#39; each cluster with the latent variable (and each other). Note that the #&#39; correlation between the &quot;strong proxy&quot; features in the cluster will be #&#39; rho_high/var. rho_high cannot equal 0 and must be at least as large as #&#39; rho_low. Default is 0.9. #&#39; @param rho_low Integer or numeric; the covariance of the &quot;weak proxies&quot; in #&#39; each cluster with the latent variable (and each other). Note that the #&#39; correlation between the &quot;weak proxy&quot; features in the cluster will be #&#39; rho_low/var. rho_low cannot equal 0 and must be no larger than rho_high. #&#39; Default is 0.5. #&#39; @param beta_latent Integer or numeric; the coefficient used for all #&#39; sig_clusters latent variables that have nonzero coefficients in the true #&#39; model for y. Can&#39;t equal 0. Default is 1.5. #&#39; @param beta_unclustered Integer or numeric; the maximum coefficient in the #&#39; model for y among the k_unclustered features in X not generated from the #&#39; latent variables. The coefficients of the features will be #&#39; beta_unclustered/sqrt(1:k_unclustered). Can&#39;t equal 0. Default is 1. #&#39; @param snr Integer or numeric; the signal-to-noise ratio of the response #&#39; y. If sigma_eps_sq is not specified, the variance of the noise in y will be #&#39; calculated using the formula sigma_eps_sq = sum(mu^2)/(n * snr). Only one of #&#39; snr and sigma_eps_sq must be specified. Default is NA. #&#39; @param sigma_eps_sq Integer or numeric; the variance on the noise added #&#39; to y. Only one of snr and sigma_eps_sq must be specified. Default is NA. #&#39; @return A list of the following elements. \\item{X}{An n x p numeric matrix of #&#39; n observations from a p-dimensional multivariate normal distribution #&#39; generated using the specified parameters. The first n_clusters times #&#39; cluster_size features will be the clusters of features correlated with the #&#39; n_clusters latent variables. The next k_unclustered features will be the #&#39; &quot;weak signal&quot; features, and the remaining p - n_clusters*cluster_size - #&#39; k_unclustered features will be the unclustered noise features.} \\item{y}{A #&#39; length n numeric vector; the response generated from X, the latent features #&#39; from Z, and the coefficient vector, along with additive noise.} \\item{Z}{The #&#39; latent features; either a numeric vector (if n_clusters &gt; 1) or a numeric #&#39; matrix (if n_clusters &gt; 1). Note that (X, Z) is multivariate Gaussian.} #&#39; \\item{mu}{A length `n` numeric vector; the expected response given X, Z, and #&#39; the true coefficient vector (equal to y minus the added noise).} #&#39; @author Gregory Faletto, Jacob Bien checkGenClusteredDataWeightedInputs &lt;- function(p, k_unclustered, cluster_size, n_strong_cluster_vars, n_clusters, sig_clusters, rho_high, rho_low, beta_latent, beta_unclustered, snr, sigma_eps_sq){ stopifnot(is.numeric(sig_clusters) | is.integer(sig_clusters)) stopifnot(sig_clusters &lt;= n_clusters) stopifnot(sig_clusters &gt;= 0) stopifnot(sig_clusters == round(sig_clusters)) stopifnot(is.numeric(n_clusters) | is.integer(n_clusters)) stopifnot(n_clusters == round(n_clusters)) # TODO(gregfaletto): is it easy to remove the requirement that n_clusters is # at least 1 (so that it&#39;s possible to generate data with no latent # features)? If so, should only check that cluster_size &gt;= 1 if n_clusters # &gt;= 1, and in makeCovarianceMatrix function only need block_size &gt;= 1 # rather than 2. stopifnot(n_clusters &gt;= 1) stopifnot(cluster_size &gt;= 2) stopifnot(is.integer(n_strong_cluster_vars) | is.numeric(n_strong_cluster_vars)) stopifnot(!is.na(n_strong_cluster_vars)) stopifnot(length(n_strong_cluster_vars) == 1) stopifnot(n_strong_cluster_vars == round(n_strong_cluster_vars)) stopifnot(n_strong_cluster_vars &gt;= 1) stopifnot(n_strong_cluster_vars &lt; cluster_size) stopifnot(rho_high &lt;= 1) stopifnot(rho_high &gt; 0) stopifnot(rho_low &gt; 0) stopifnot(rho_high &gt;= rho_low) stopifnot(beta_latent != 0) stopifnot(beta_unclustered != 0) stopifnot(is.numeric(k_unclustered) | is.integer(k_unclustered)) stopifnot(k_unclustered &gt;= 2) stopifnot(k_unclustered == round(k_unclustered)) stopifnot(p &gt;= n_clusters*cluster_size + k_unclustered) # Same as make_sparse_blocked_linear_model_random, but ith coefficient # of weak signal features is beta_unclustered/sqrt(i) in order to have # a definitive ranking of weak signal features. if(is.na(snr) &amp; is.na(sigma_eps_sq)){ stop(&quot;Must specify one of snr or sigma_eps_sq&quot;) } if(!is.na(snr)){ stopifnot(snr &gt; 0) } if(!is.na(sigma_eps_sq)){ stopifnot(sigma_eps_sq &gt; 0) } } No tests for checkGenClusteredDataWeightedInputs() Tests for genClusteredDataWeighted() testthat::test_that(&quot;genClusteredDataWeighted works&quot;, { set.seed(23478) ret &lt;- genClusteredDataWeighted(n=25, p=19, k_unclustered=2, cluster_size=5, n_strong_cluster_vars=3, n_clusters=3, sig_clusters=2, rho_high=.99, rho_low=.5, beta_latent=1.5, beta_unclustered=-2, snr=NA, sigma_eps_sq=.5) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;X&quot;, &quot;y&quot;, &quot;Z&quot;, &quot;mu&quot;)) testthat::expect_true(is.numeric(ret$X)) testthat::expect_true(is.matrix(ret$X)) testthat::expect_equal(ncol(ret$X), 19) testthat::expect_equal(nrow(ret$X), 25) # X is Gaussian with mean 0 and variance 4; expect all observations to lie # within 5 standard deviations of mean testthat::expect_true(all(abs(ret$X) &lt; 5*2)) # Test that clusters are correlated--within-cluster correlation should be # high, correlation with other features should be low testthat::expect_true(min(cor(ret$X[, 1:3])) &gt; .9) testthat::expect_true(max(abs(cor(ret$X[, 1:5], ret$X[, 6:19]))) &lt; .6) testthat::expect_true(min(cor(ret$X[, 6:8])) &gt; .9) testthat::expect_true(max(abs(cor(ret$X[, 6:10], ret$X[, c(1:5, 11:19)]))) &lt; .6) testthat::expect_true(min(cor(ret$X[, 11:13])) &gt; .9) testthat::expect_true(max(abs(cor(ret$X[, 11:15], ret$X[, c(1:10, 16:19)]))) &lt; .7) cor_indeps &lt;- cor(ret$X[, 16:19]) testthat::expect_true(max(abs(cor_indeps[lower.tri(cor_indeps)])) &lt; .6) testthat::expect_true(is.numeric(ret$y)) testthat::expect_equal(length(ret$y), 25) testthat::expect_true(is.numeric(ret$Z)) testthat::expect_true(is.matrix(ret$Z)) testthat::expect_equal(nrow(ret$Z), 25) testthat::expect_equal(ncol(ret$Z), 3) testthat::expect_true(is.numeric(ret$mu)) testthat::expect_equal(length(ret$mu), 25) # Because y is Gaussian with mean mu and standard deviation .5 conditional on # mu, expect all observations to lie within 5 sds of mu testthat::expect_true(all(abs(ret$y - ret$mu) &lt; 5*.5)) # Specify SNR instead of sigma_eps_sq ret &lt;- genClusteredDataWeighted(n=25, p=19, k_unclustered=2, cluster_size=5, n_strong_cluster_vars=3, n_clusters=3, sig_clusters=2, rho_high=.99, rho_low=.5, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;X&quot;, &quot;y&quot;, &quot;Z&quot;, &quot;mu&quot;)) # If sigma_eps_sq is specified, snr should be ignored. (Set an SNR that # implies a very large noise variance to test this) ret &lt;- genClusteredDataWeighted(n=25, p=19, k_unclustered=2, cluster_size=5, n_strong_cluster_vars=3, n_clusters=3, sig_clusters=2, rho_high=.99, rho_low=.5, beta_latent=1.5, beta_unclustered=-2, snr=.01, sigma_eps_sq=.25) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;X&quot;, &quot;y&quot;, &quot;Z&quot;, &quot;mu&quot;)) # Because y is Gaussian with mean mu and standard deviation .5 conditional on # mu, expect all observations to lie within 5 sds of mu testthat::expect_true(all(abs(ret$y - ret$mu) &lt; 5*sqrt(.25))) # Try a single latent variable (z should be a one-column matrix) ret &lt;- genClusteredDataWeighted(n=25, p=19, k_unclustered=2, cluster_size=5, n_strong_cluster_vars=3, n_clusters=1, sig_clusters=1, rho_high=.99, rho_low=.5, beta_latent=1.5, beta_unclustered=-2, snr=NA, sigma_eps_sq=.5) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;X&quot;, &quot;y&quot;, &quot;Z&quot;, &quot;mu&quot;)) testthat::expect_true(is.numeric(ret$Z)) testthat::expect_true(is.matrix(ret$Z)) testthat::expect_equal(nrow(ret$Z), 25) testthat::expect_equal(ncol(ret$Z), 1) }) ## Test passed 🥳 genClusteredDataWeightedRandom() #&#39; Generate randomly sampled data including noisy observations of latent #&#39; variables, where proxies differ in their relevance (noise level) #&#39; #&#39; Generate a data set including latent features Z, observed features X (which #&#39; may include noisy or noiseless observations of the latent features in Z), #&#39; an observed response y which is a linear model of features from Z and X as #&#39; well as independent mean zero noise, and mu (the responses from y without #&#39; the added noise). #&#39; @param n Integer or numeric; the number of observations to generate. (The #&#39; generated X and Z will have n rows, and the generated y and mu will have #&#39; length n.) #&#39; @param p Integer or numeric; the number of features to generate. The #&#39; generated X will have p columns. #&#39; @param k_unclustered Integer or numeric; the number of features in X that #&#39; will have nonzero coefficients in the true model for y among those features #&#39; not generated from the n_clusters latent variables (called &quot;weak signal&quot; #&#39; features in the simulations from Faletto and Bien 2022). The coefficients on #&#39; these features will be determined by beta_unclustered. #&#39; @param cluster_size Integer or numeric; for each of the n_clusters latent #&#39; variables, X will contain cluster_size noisy proxies that are correlated with #&#39; the latent variable. #&#39; @param n_clusters Integer or numeric; the number of latent variables to #&#39; generate, each of which will be associated with an observed cluster in X. #&#39; Must be at least 1. Default is 1. #&#39; @param sig_clusters Integer or numeric; the number of generated latent #&#39; features that will have nonzero coefficients in the true model for y (all of #&#39; them will have coefficient beta_latent). Must be less than or equal to #&#39; n_clusters. Default is 1. #&#39; @param rho_high Integer or numeric; the maximum correlation of the proxies #&#39; each cluster with each other. Default is 1. #&#39; @param rho_low Integer or numeric; the minimum correlation of the proxies in #&#39; each cluster with each other. rho_low cannot equal 0 and must be no larger #&#39; than rho_high. Default is 0.5. #&#39; @param beta_latent Integer or numeric; the coefficient used for all #&#39; sig_clusters latent variables that have nonzero coefficients in the true #&#39; model for y. Can&#39;t equal 0. Default is 1.5. #&#39; @param beta_unclustered Integer or numeric; the maximum coefficient in the #&#39; model for y among the k_unclustered features in X not generated from the #&#39; latent variables. The coefficients of the features will be #&#39; beta_unclustered/sqrt(1:k_unclustered). Can&#39;t equal 0. Default is 1. #&#39; @param snr Integer or numeric; the signal-to-noise ratio of the response #&#39; y. If sigma_eps_sq is not specified, the variance of the noise in y will be #&#39; calculated using the formula sigma_eps_sq = sum(mu^2)/(n * snr). Only one of #&#39; snr and sigma_eps_sq must be specified. Default is NA. #&#39; @param sigma_eps_sq Integer or numeric; the variance on the noise added #&#39; to y. Only one of snr and sigma_eps_sq must be specified. Default is NA. #&#39; @return A list of the following elements. \\item{X}{An n x p numeric matrix of #&#39; n observations from a p-dimensional multivariate normal distribution #&#39; generated using the specified parameters. The first n_clusters times #&#39; cluster_size features will be the clusters of features correlated with the #&#39; n_clusters latent variables. The next k_unclustered features will be the #&#39; &quot;weak signal&quot; features, and the remaining p - n_clusters*cluster_size - #&#39; k_unclustered features will be the unclustered noise features.} \\item{y}{A #&#39; length n numeric vector; the response generated from X, the latent features #&#39; from Z, and the coefficient vector, along with additive noise.} \\item{Z}{The #&#39; latent features; either a numeric vector (if n_clusters &gt; 1) or a numeric #&#39; matrix (if n_clusters &gt; 1). Note that (X, Z) is multivariate Gaussian.} #&#39; \\item{mu}{A length `n` numeric vector; the expected response given X, Z, and #&#39; the true coefficient vector (equal to y minus the added noise).} #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references &lt;&lt;faletto2022&gt;&gt; #&#39; @export genClusteredDataWeightedRandom &lt;- function(n, p, k_unclustered, cluster_size, n_clusters=1, sig_clusters=1, rho_high=1, rho_low=0.5, beta_latent=1.5, beta_unclustered=1, snr=as.numeric(NA), sigma_eps_sq=as.numeric(NA)){ # Check inputs checkGenClusteredDataWeightedRandomInputs(p, k_unclustered, cluster_size, n_clusters, sig_clusters, rho_high, rho_low, beta_latent, beta_unclustered, snr, sigma_eps_sq) ret &lt;- genZmuY(n=n, p=p, k_unclustered=k_unclustered, cluster_size=cluster_size, n_clusters=n_clusters, sig_clusters=sig_clusters, beta_latent=beta_latent, beta_unclustered=beta_unclustered, snr=snr, sigma_eps_sq=sigma_eps_sq) Z &lt;- ret$Z y &lt;- ret$y mu &lt;- ret$mu other_X &lt;- ret$other_X # Finally, generate clusters of proxies to complete X. # Create matrix of proxies Z &lt;- as.matrix(Z) proxy_mat &lt;- matrix(as.numeric(NA), n, n_clusters*cluster_size) for(i in 1:n_clusters){ for(j in 1:cluster_size){ # Choose correlation at random rho_ij &lt;- runif(n=1, min=rho_low, max=rho_high) # Get noise variance noise_var_ij &lt;- getNoiseVar(rho_ij) proxy_mat[, (i - 1)*cluster_size + j] &lt;- Z[, i] + rnorm(n, mean=0, sd=sqrt(noise_var_ij)) } } X &lt;- cbind(proxy_mat, other_X) # Check output stopifnot(length(mu) == n) stopifnot(nrow(X) == n) stopifnot(ncol(X) == p) if(any(!is.na(Z))){ stopifnot(nrow(Z) == n) stopifnot(ncol(Z) == n_clusters) } return(list(X=X, y=y, Z=Z, mu=mu)) } checkGenClusteredDataWeightedRandomInputs() #&#39; Check inputs to genClusteredDataWeightedRandom #&#39; #&#39; @param n Integer or numeric; the number of observations to generate. (The #&#39; generated X and Z will have n rows, and the generated y and mu will have #&#39; length n.) #&#39; @param p Integer or numeric; the number of features to generate. The #&#39; generated X will have p columns. #&#39; @param k_unclustered Integer or numeric; the number of features in X that #&#39; will have nonzero coefficients in the true model for y among those features #&#39; not generated from the n_clusters latent variables (called &quot;weak signal&quot; #&#39; features in the simulations from Faletto and Bien 2022). The coefficients on #&#39; these features will be determined by beta_unclustered. #&#39; @param cluster_size Integer or numeric; for each of the n_clusters latent #&#39; variables, X will contain cluster_size noisy proxies that are correlated with #&#39; the latent variable. #&#39; @param n_clusters Integer or numeric; the number of latent variables to #&#39; generate, each of which will be associated with an observed cluster in X. #&#39; Must be at least 1. Default is 1. #&#39; @param sig_clusters Integer or numeric; the number of generated latent #&#39; features that will have nonzero coefficients in the true model for y (all of #&#39; them will have coefficient beta_latent). Must be less than or equal to #&#39; n_clusters. Default is 1. #&#39; @param rho_high Integer or numeric; the maximum correlation of the proxies #&#39; each cluster with each other. Default is 1. #&#39; @param rho_low Integer or numeric; the minimum correlation of the proxies in #&#39; each cluster with each other. rho_low cannot equal 0 and must be no larger #&#39; than rho_high. Default is 0.5. #&#39; @param beta_latent Integer or numeric; the coefficient used for all #&#39; sig_clusters latent variables that have nonzero coefficients in the true #&#39; model for y. Can&#39;t equal 0. Default is 1.5. #&#39; @param beta_unclustered Integer or numeric; the maximum coefficient in the #&#39; model for y among the k_unclustered features in X not generated from the #&#39; latent variables. The coefficients of the features will be #&#39; beta_unclustered/sqrt(1:k_unclustered). Can&#39;t equal 0. Default is 1. #&#39; @param snr Integer or numeric; the signal-to-noise ratio of the response #&#39; y. If sigma_eps_sq is not specified, the variance of the noise in y will be #&#39; calculated using the formula sigma_eps_sq = sum(mu^2)/(n * snr). Only one of #&#39; snr and sigma_eps_sq must be specified. Default is NA. #&#39; @param sigma_eps_sq Integer or numeric; the variance on the noise added #&#39; to y. Only one of snr and sigma_eps_sq must be specified. Default is NA. #&#39; @return A list of the following elements. \\item{X}{An n x p numeric matrix of #&#39; n observations from a p-dimensional multivariate normal distribution #&#39; generated using the specified parameters. The first n_clusters times #&#39; cluster_size features will be the clusters of features correlated with the #&#39; n_clusters latent variables. The next k_unclustered features will be the #&#39; &quot;weak signal&quot; features, and the remaining p - n_clusters*cluster_size - #&#39; k_unclustered features will be the unclustered noise features.} \\item{y}{A #&#39; length n numeric vector; the response generated from X, the latent features #&#39; from Z, and the coefficient vector, along with additive noise.} \\item{Z}{The #&#39; latent features; either a numeric vector (if n_clusters &gt; 1) or a numeric #&#39; matrix (if n_clusters &gt; 1). Note that (X, Z) is multivariate Gaussian.} #&#39; \\item{mu}{A length `n` numeric vector; the expected response given X, Z, and #&#39; the true coefficient vector (equal to y minus the added noise).} #&#39; @author Gregory Faletto, Jacob Bien checkGenClusteredDataWeightedRandomInputs &lt;- function(p, k_unclustered, cluster_size, n_clusters, sig_clusters, rho_high, rho_low, beta_latent, beta_unclustered, snr, sigma_eps_sq){ stopifnot(is.numeric(sig_clusters) | is.integer(sig_clusters)) stopifnot(sig_clusters &lt;= n_clusters) stopifnot(sig_clusters &gt;= 0) stopifnot(sig_clusters == round(sig_clusters)) stopifnot(is.numeric(n_clusters) | is.integer(n_clusters)) stopifnot(n_clusters == round(n_clusters)) # TODO(gregfaletto): is it easy to remove the requirement that n_clusters is # at least 1 (so that it&#39;s possible to generate data with no latent # features)? If so, should only check that cluster_size &gt;= 1 if n_clusters # &gt;= 1, and in makeCovarianceMatrix function only need block_size &gt;= 1 # rather than 2. stopifnot(n_clusters &gt;= 1) stopifnot(cluster_size &gt;= 2) stopifnot(rho_high &lt;= 1) stopifnot(rho_high &gt; 0) stopifnot(rho_low &gt; 0) stopifnot(rho_high &gt;= rho_low) stopifnot(beta_latent != 0) stopifnot(beta_unclustered != 0) stopifnot(is.numeric(k_unclustered) | is.integer(k_unclustered)) stopifnot(k_unclustered &gt;= 2) stopifnot(k_unclustered == round(k_unclustered)) stopifnot(p &gt;= n_clusters*cluster_size + k_unclustered) # Same as make_sparse_blocked_linear_model_random, but ith coefficient # of weak signal features is beta_unclustered/sqrt(i) in order to have # a definitive ranking of weak signal features. if(is.na(snr) &amp; is.na(sigma_eps_sq)){ stop(&quot;Must specify one of snr or sigma_eps_sq&quot;) } if(!is.na(snr)){ stopifnot(snr &gt; 0) } if(!is.na(sigma_eps_sq)){ stopifnot(sigma_eps_sq &gt; 0) } } No tests for checkGenClusteredDataWeightedRandomInputs() Tests for genClusteredDataWeightedRandom() testthat::test_that(&quot;genClusteredDataWeightedRandom works&quot;, { set.seed(23478) ret &lt;- genClusteredDataWeightedRandom(n=25, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho_high=1, rho_low=.5, beta_latent=1.5, beta_unclustered=-2, snr=NA, sigma_eps_sq=.5) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;X&quot;, &quot;y&quot;, &quot;Z&quot;, &quot;mu&quot;)) testthat::expect_true(is.numeric(ret$X)) testthat::expect_true(is.matrix(ret$X)) testthat::expect_equal(ncol(ret$X), 19) testthat::expect_equal(nrow(ret$X), 25) # X is Gaussian with mean 0 and variance 4; expect all observations to lie # within 5 standard deviations of mean testthat::expect_true(all(abs(ret$X) &lt; 5*2)) # Test that clusters are correlated--within-cluster correlation should be # high, correlation with other features should be low testthat::expect_true(min(cor(ret$X[, 1:3])) &gt; .2) testthat::expect_true(max(abs(cor(ret$X[, 1:5], ret$X[, 6:19]))) &lt; .6) testthat::expect_true(min(cor(ret$X[, 6:8])) &gt; .2) testthat::expect_true(max(abs(cor(ret$X[, 6:10], ret$X[, c(1:5, 11:19)]))) &lt; .6) testthat::expect_true(min(cor(ret$X[, 11:13])) &gt; .2) testthat::expect_true(max(abs(cor(ret$X[, 11:15], ret$X[, c(1:10, 16:19)]))) &lt; .7) cor_indeps &lt;- cor(ret$X[, 16:19]) testthat::expect_true(max(abs(cor_indeps[lower.tri(cor_indeps)])) &lt; .6) testthat::expect_true(is.numeric(ret$y)) testthat::expect_equal(length(ret$y), 25) testthat::expect_true(is.numeric(ret$Z)) testthat::expect_true(is.matrix(ret$Z)) testthat::expect_equal(nrow(ret$Z), 25) testthat::expect_equal(ncol(ret$Z), 3) testthat::expect_true(is.numeric(ret$mu)) testthat::expect_equal(length(ret$mu), 25) # Because y is Gaussian with mean mu and standard deviation .5 conditional on # mu, expect all observations to lie within 5 sds of mu testthat::expect_true(all(abs(ret$y - ret$mu) &lt; 5*.5)) # Specify SNR instead of sigma_eps_sq ret &lt;- genClusteredDataWeightedRandom(n=25, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho_high=1, rho_low=.5, beta_latent=1.5, beta_unclustered=-2, snr=1, sigma_eps_sq=NA) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;X&quot;, &quot;y&quot;, &quot;Z&quot;, &quot;mu&quot;)) # If sigma_eps_sq is specified, snr should be ignored. (Set an SNR that # implies a very large noise variance to test this) ret &lt;- genClusteredDataWeightedRandom(n=25, p=19, k_unclustered=2, cluster_size=5, n_clusters=3, sig_clusters=2, rho_high=.99, rho_low=.5, beta_latent=1.5, beta_unclustered=-2, snr=.01, sigma_eps_sq=.25) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;X&quot;, &quot;y&quot;, &quot;Z&quot;, &quot;mu&quot;)) # Because y is Gaussian with mean mu and standard deviation .5 conditional on # mu, expect all observations to lie within 5 sds of mu testthat::expect_true(all(abs(ret$y - ret$mu) &lt; 5*sqrt(.25))) # Try a single latent variable (z should be a one-column matrix) ret &lt;- genClusteredDataWeightedRandom(n=25, p=19, k_unclustered=2, cluster_size=5, n_clusters=1, sig_clusters=1, rho_high=1, rho_low=.5, beta_latent=1.5, beta_unclustered=-2, snr=NA, sigma_eps_sq=.5) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;X&quot;, &quot;y&quot;, &quot;Z&quot;, &quot;mu&quot;)) testthat::expect_true(is.numeric(ret$Z)) testthat::expect_true(is.matrix(ret$Z)) testthat::expect_equal(nrow(ret$Z), 25) testthat::expect_equal(ncol(ret$Z), 1) }) ## Test passed 😸 getLassoLambda(): #&#39; Get lambda value for lasso #&#39; #&#39; Chooses a lambda value for the lasso used on a subsample of size n/2 (as in #&#39; cluster stability selection) by cross-validation. #&#39; @param X An n x p numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; the p &gt;= 2 features/predictors that will be used by cluster stability #&#39; selection. #&#39; @param y The response; an n-dimensional numeric or integer vector. (Unlike #&#39; in the more general css setup, this response must be real-valued since #&#39; lambda will be determined using the lasso with cross-validation.) #&#39; @param lambda_choice Character; either &quot;min&quot; or &quot;1se&quot;. If &quot;min&quot;, chooses #&#39; the lambda that minimizes the cross-validated error; if &quot;1se&quot;, chooses the #&#39; largest lambda within one standard error of the minimum error lambda #&#39; (resulting in a smaller selected set, which may be desirable because the #&#39; model size corresponding to the minimum error lambda tends to be larger #&#39; than optimal. See, for example, Bühlmann and Meinshausen 2006, Prop. 1 and #&#39; Bühlmann and van de Geer 2011, Section 2.5.1.). Default is &quot;1se&quot;. #&#39; @param nfolds Numeric or integer; the number of folds for cross-validation. #&#39; Must be at least 4 (as specified by cv.glmnet). Default is 10. #&#39; @param alpha Numeric; the elastic net mixing parameter. Default is 1 (in #&#39; which case the penalty is for lasso) #&#39; @return A numeric; the selected value of lambda. #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references Bühlmann, P., &amp; Meinshausen, N. (2006). High-Dimensional Graphs #&#39; and Variable Selection With the Lasso. \\emph{The Annals of Statistics}, #&#39; 34(3), 1436–1462. \\url{https://doi.org/10.1214/009053606000000281}. #&#39; \\cr Peter Bühlmann and Sara van de Geer. Statistics for High-Dimensional #&#39; Data. \\emph{Springer Series in Statistics}. Springer, Heidelberg, 2011. ISBN #&#39; 978-3-642-20191-2. \\url{http://dx.doi.org/10.1007/978-3-642-20192-9}. \\cr #&#39; Jerome Friedman, Trevor Hastie, Robert Tibshirani (2010). Regularization #&#39; Paths for Generalized Linear Models via Coordinate Descent. \\emph{Journal of #&#39; Statistical Software}, 33(1), 1-22. URL \\url{https://www.jstatsoft.org/v33/i01/}. #&#39; @export getLassoLambda &lt;- function(X, y, lambda_choice=&quot;1se&quot;, nfolds=10, alpha=1){ stopifnot(is.character(lambda_choice)) stopifnot(length(lambda_choice) == 1) stopifnot(!is.na(lambda_choice)) stopifnot(lambda_choice %in% c(&quot;min&quot;, &quot;1se&quot;)) stopifnot(is.matrix(X)) stopifnot(is.numeric(X) | is.integer(X)) n &lt;- nrow(X) stopifnot(is.numeric(nfolds) | is.integer(nfolds)) stopifnot(length(nfolds) == 1) stopifnot(nfolds == round(nfolds)) stopifnot(nfolds &gt; 3) stopifnot(is.numeric(alpha) | is.integer(alpha)) stopifnot(length(alpha) == 1) stopifnot(!is.na(alpha)) stopifnot(alpha &gt;= 0) stopifnot(alpha &lt;= 1) # Since we are using the lasso, we require y to be a real-valued response # (unlike for the general cluster stability selection procedure, where y # can have a more general format as long as a suitable feature selection # function is provided by the user) stopifnot(is.numeric(y) | is.integer(y)) stopifnot(n == length(y)) # Sample size to use: inflate n/2 by a factor of nfolds/(nfolds - 1), # so that each individual lasso fit is of size floor(n/2) n_sample &lt;- min(round(n/2*nfolds/(nfolds - 1)), n) nfolds &lt;- min(nfolds, n_sample) inds_size &lt;- sample(1:n, n_sample) size_results &lt;- glmnet::cv.glmnet(x=X[inds_size, ], y=y[inds_size], family=&quot;gaussian&quot;, nfolds=nfolds, alpha=alpha) lambda_ret &lt;- size_results[[paste(&quot;lambda.&quot;, lambda_choice, sep=&quot;&quot;)]] # Check output stopifnot(length(lambda_ret) == 1) stopifnot(is.numeric(lambda_ret) | is.integer(lambda_ret)) stopifnot(lambda_ret &gt;= 0) return(lambda_ret) } Tests for getLassoLambda(): testthat::test_that(&quot;getLassoLambda works&quot;, { set.seed(7252) x &lt;- matrix(stats::rnorm(10*6), nrow=10, ncol=6) y &lt;- stats::rnorm(10) ret &lt;- getLassoLambda(X=x, y=y, lambda_choice=&quot;1se&quot;, nfolds=4) testthat::expect_true(is.numeric(ret) | is.integer(ret)) testthat::expect_true(!is.na(ret)) testthat::expect_equal(length(ret), 1) testthat::expect_true(ret &gt;= 0) ret &lt;- getLassoLambda(X=x, y=y, lambda_choice=&quot;min&quot;, nfolds=5) testthat::expect_true(is.numeric(ret) | is.integer(ret)) testthat::expect_true(!is.na(ret)) testthat::expect_equal(length(ret), 1) testthat::expect_true(ret &gt;= 0) # Different mixing parameter ret &lt;- getLassoLambda(X=x, y=y, lambda_choice=&quot;min&quot;, nfolds=5, alpha=0.5) testthat::expect_true(is.numeric(ret) | is.integer(ret)) testthat::expect_true(!is.na(ret)) testthat::expect_equal(length(ret), 1) testthat::expect_true(ret &gt;= 0) # Bad inputs testthat::expect_error(getLassoLambda(X=&quot;x&quot;, y=y), &quot;is.matrix(X) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getLassoLambda(X=x[1:9, ], y=y), &quot;n == length(y) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getLassoLambda(X=x, y=TRUE), &quot;is.numeric(y) | is.integer(y) is not TRUE&quot;, fixed=TRUE) # Error has quotation marks in it testthat::expect_error(getLassoLambda(X=x, y=y, lambda_choice=&quot;mni&quot;)) testthat::expect_error(getLassoLambda(X=x, y=y, lambda_choice=c(&quot;min&quot;, &quot;1se&quot;)), &quot;length(lambda_choice) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getLassoLambda(X=x, y=y, lambda_choice=1), &quot;is.character(lambda_choice) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getLassoLambda(X=x, y=y, nfolds=&quot;5&quot;), &quot;is.numeric(nfolds) | is.integer(nfolds) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getLassoLambda(X=x, y=y, nfolds=1:4), &quot;length(nfolds) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getLassoLambda(X=x, y=y, nfolds=3.2), &quot;nfolds == round(nfolds) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getLassoLambda(X=x, y=y, nfolds=3), &quot;nfolds &gt; 3 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getLassoLambda(X=x, y=y, nfolds=4, alpha=1.2), &quot;alpha &lt;= 1 is not TRUE&quot;, fixed=TRUE) }) ## ── Warning (&#39;&lt;text&gt;:7&#39;): getLassoLambda works ────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) getLassoLambda(X = x, y = y, lambda_choice = &quot;1se&quot;, nfolds = 4) ## 2. glmnet::cv.glmnet(...) ## 3. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:14&#39;): getLassoLambda works ───────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) getLassoLambda(X = x, y = y, lambda_choice = &quot;min&quot;, nfolds = 5) ## 2. glmnet::cv.glmnet(...) ## 3. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:23&#39;): getLassoLambda works ───────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) getLassoLambda(...) ## 2. glmnet::cv.glmnet(...) ## 3. glmnet:::cv.glmnet.raw(...) getModelSize(): #&#39; Automated estimation of model size #&#39; #&#39; This function is uses the lasso with cross-validation to estimate the #&#39; model size. Before using the lasso, in each cluster all features will be #&#39; dropped from X except the one feature with the highest marginal correlation #&#39; with y, as in the protolasso (Reid and Tibshirani 2016). #&#39; #&#39; @param X An n x p numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; the p &gt;= 2 features/predictors. #&#39; @param y A length-n numeric vector containing the responses; `y[i]` is the #&#39; response corresponding to observation `X[i, ]`. (Note that for the css #&#39; function, y does not have to be a numeric response, but for this function, #&#39; the underlying selection procedure is the lasso, so y must be a real-valued #&#39; response.) #&#39; @param clusters A named list where each entry is an integer vector of indices #&#39; of features that are in a common cluster, as in the output of css. #&#39; (The length of list clusters is equal to the number of clusters.) All #&#39; identified clusters must be non-overlapping, and all features must appear in #&#39; exactly one cluster (any unclustered features should be in their own #&#39; &quot;cluster&quot; of size 1). CAUTION: if the provided X is a data.frame that #&#39; contains a categorical feature with more than two levels, then the resulting #&#39; matrix made from model.matrix will have a different number of columns than #&#39; the provided data.frame, some of the feature numbers will change, and the #&#39; clusters argument will not work properly (in the current version of the #&#39; package). To get correct results in this case, please use model.matrix to #&#39; convert the data.frame to a numeric matrix on your own, then provide this #&#39; matrix and cluster assignments with respect to this matrix. #&#39; @return An integer; the estimated size of the model. The minimum returned #&#39; value is 1, even if the lasso with cross-validation chose no features. #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references Reid, S., &amp; Tibshirani, R. (2016). Sparse regression and marginal #&#39; testing using cluster prototypes. \\emph{Biostatistics}, 17(2), 364–376. #&#39; \\url{https://doi.org/10.1093/biostatistics/kxv049}. #&#39; @export getModelSize &lt;- function(X, y, clusters){ stopifnot(is.matrix(X) | is.data.frame(X)) # Check if x is a matrix; if it&#39;s a data.frame, convert to matrix. if(is.data.frame(X)){ p &lt;- ncol(X) X &lt;- stats::model.matrix(~ ., X) X &lt;- X[, colnames(X) != &quot;(Intercept)&quot;] if(length(clusters) &gt; 0 &amp; (p != ncol(X))){ stop(&quot;When stats::model.matrix converted the provided data.frame X to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert X to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;) } } stopifnot(is.matrix(X)) stopifnot(all(!is.na(X))) stopifnot(is.numeric(X) | is.integer(X)) n &lt;- nrow(X) # Since the model size will be determined by cross-validation, the provided # y must be real-valued (this should be checked internally in other # functions before getModelSize is called, but this check is here just in # case). if(!is.numeric(y) &amp; !is.integer(y)){ stop(&quot;getModelSize is trying to determine max_num_clusts using the lasso with cross-validation, but the y provided to getModelSize was not real-valued.&quot;) } stopifnot(length(y) == n) # Check clusters argument clusters &lt;- checkCssClustersInput(clusters) ### Format clusters into a list where all features are in exactly one # cluster (any unclustered features are put in their own &quot;cluster&quot; of size # 1). clust_names &lt;- as.character(NA) if(!is.null(names(clusters)) &amp; is.list(clusters)){ clust_names &lt;- names(clusters) } clusters &lt;- formatClusters(clusters, p=ncol(X), clust_names=clust_names)$clusters X_size &lt;- X if(length(clusters) &gt; 0){ # Create modified design matrix by dropping all but one feature from # each cluster feats_to_drop &lt;- integer() for(i in 1:length(clusters)){ cluster_i &lt;- clusters[[i]] if(length(cluster_i) &gt; 1){ feat_to_keep &lt;- identifyPrototype(cluster_i, X, y) feats_to_drop &lt;- c(feats_to_drop, setdiff(cluster_i, feat_to_keep)) } } if(length(feats_to_drop) &gt; 0){ X_size &lt;- X_size[, -1*feats_to_drop] } } size_results &lt;- glmnet::cv.glmnet(x=X_size, y=y, family=&quot;gaussian&quot;) coefs &lt;- as.numeric(glmnet::coef.glmnet(size_results, s=&quot;lambda.1se&quot;)) # Number of nonzero coefficients (subtract one in order to ignore intercept) size &lt;- length(coefs[coefs != 0]) - 1 # Check output stopifnot(is.numeric(size) | is.integer(size)) stopifnot(!is.na(size)) stopifnot(length(size) == 1) stopifnot(size == round(size)) return(as.integer(max(size, 1))) } Tests for getModelSize(): testthat::test_that(&quot;getModelSize works&quot;, { set.seed(1723) data &lt;- genClusteredData(n=15, p=11, k_unclustered=2, cluster_size=3, n_clusters=2, sigma_eps_sq=10^(-6)) x &lt;- data$X y &lt;- data$y good_clusters &lt;- list(red_cluster=1L:3L, green_cluster=4L:6L) ret &lt;- getModelSize(X=x, y=y, clusters=good_clusters) testthat::expect_true(is.numeric(ret) | is.integer(ret)) testthat::expect_true(!is.na(ret)) testthat::expect_equal(length(ret), 1) testthat::expect_equal(ret, round(ret)) testthat::expect_true(ret &gt;= 1) # 11 features, but two clusters of size 3, so maximum size should # be 11 - 2 - 2 = 7 testthat::expect_true(ret &lt;= 7) ## Trying other inputs unnamed_clusters &lt;- list(1L:3L, 5L:8L) ret &lt;- getModelSize(X=x, y=y, clusters=unnamed_clusters) testthat::expect_true(is.numeric(ret) | is.integer(ret)) testthat::expect_true(!is.na(ret)) testthat::expect_equal(length(ret), 1) testthat::expect_equal(ret, round(ret)) testthat::expect_true(ret &gt;= 1) # 11 features, but 3 in one cluster and 4 in another, so maximum size should # be 11 - 2 - 3 = 6 testthat::expect_true(ret &lt;= 6) # Single cluster ret &lt;- getModelSize(X=x, y=y, clusters=2:5) testthat::expect_true(is.numeric(ret) | is.integer(ret)) testthat::expect_true(!is.na(ret)) testthat::expect_equal(length(ret), 1) testthat::expect_equal(ret, round(ret)) testthat::expect_true(ret &gt;= 1) # 11 features, but 4 in one cluster, so maximum size should be 11 - 3 = 8 testthat::expect_true(ret &lt;= 8) # Intentionally don&#39;t provide clusters for all feature, mix up formatting, # etc. good_clusters &lt;- list(red_cluster=1:3, 5:8) ret &lt;- getModelSize(X=x, y=y, clusters=good_clusters) testthat::expect_true(is.numeric(ret) | is.integer(ret)) testthat::expect_true(!is.na(ret)) testthat::expect_equal(length(ret), 1) testthat::expect_equal(ret, round(ret)) testthat::expect_true(ret &gt;= 1) # 11 features, but 3 in one cluster and 4 in another, so maximum size should # be 11 - 2 - 3 = 6 testthat::expect_true(ret &lt;= 6) ## Trying bad inputs testthat::expect_error(getModelSize(X=&quot;x&quot;, y=y, clusters=good_clusters), &quot;is.matrix(X) | is.data.frame(X) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getModelSize(X=x[1:5, ], y=y, clusters=good_clusters), &quot;length(y) == n is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getModelSize(X=x, y=FALSE, clusters=good_clusters), &quot;getModelSize is trying to determine max_num_clusts using the lasso with cross-validation, but the y provided to getModelSize was not real-valued.&quot;, fixed=TRUE) testthat::expect_error(getModelSize(X=x, y=y, clusters=list(3:7, 7:10)), &quot;Overlapping clusters detected; clusters must be non-overlapping. Overlapping clusters: 1, 2.&quot;, fixed=TRUE) testthat::expect_error(getModelSize(X=x, y=y, clusters=list(5:8, 5:8)), &quot;length(clusters) == length(unique(clusters)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getModelSize(X=x, y=y, clusters=6:50), &quot;length(all_clustered_feats) == p is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getModelSize(X=x, y=y, clusters=list(2:3, as.integer(NA))), &quot;!is.na(clusters) are not all TRUE&quot;, fixed=TRUE) testthat::expect_error(getModelSize(X=x, y=y, clusters=list(2:3, c(4, 4, 5))), &quot;length(clusters[[i]]) == length(unique(clusters[[i]])) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getModelSize(X=x, y=y, clusters=list(1:4, -1)), &quot;all(clusters[[i]] &gt;= 1) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getModelSize(X=x, y=y, clusters=list(1:4, c(2.3, 1.2))), &quot;all(clusters[[i]] == round(clusters[[i]])) is not TRUE&quot;, fixed=TRUE) }) ## ── Warning (&#39;&lt;text&gt;:12&#39;): getModelSize works ─────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) getModelSize(X = x, y = y, clusters = good_clusters) ## 2. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 3. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:27&#39;): getModelSize works ─────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) getModelSize(X = x, y = y, clusters = unnamed_clusters) ## 2. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 3. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:39&#39;): getModelSize works ─────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) getModelSize(X = x, y = y, clusters = 2:5) ## 2. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 3. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:54&#39;): getModelSize works ─────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) getModelSize(X = x, y = y, clusters = good_clusters) ## 2. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 3. glmnet:::cv.glmnet.raw(...) printCssDf(): #&#39; Prepares a data.frame summarazing cluster stability selection output to print #&#39; #&#39; Print a summary of the information from the css function. #&#39; @param css_results An object of class &quot;cssr&quot; (the output of the function #&#39; css). #&#39; @param cutoff Numeric; the outputted data.frame will display only those #&#39; clusters with selection proportions equal to at least cutoff. Must be between #&#39; 0 and 1. Default is 0 (in which case either all clusters are displayed, or #&#39; max_num_clusts are, if max_num_clusts is specified). #&#39; @param min_num_clusts Integer or numeric; the minimum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns fewer than #&#39; min_num_clusts clusters, the cutoff will be increased until at least #&#39; min_num_clusts clusters are selected.) Default is 1. #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) Default is NA (in which case #&#39; max_num_clusts is ignored). #&#39; @return A data.frame; each row contains a cluster, arranged in decreasing #&#39; order of cluster selection proportion from top to bottom. The columns are #&#39; ClustName (the name of the cluster that was either provided to css or made by #&#39; css if no name was provided); ClustProtoName (the name of the selection #&#39; prototype from the cluster, which is the feature with the greatest individual #&#39; selection proportion among all the cluster members, with ties broken by #&#39; choosing the feature with the highest correlation with the response if the #&#39; response is real-valued; only returned if the features are named), #&#39; ClustProtoNum (the column number of the prototype in the X matrix provided to #&#39; css), and ClustSize (the size of the cluster). #&#39; @author Gregory Faletto, Jacob Bien #&#39; @export printCssDf &lt;- function(css_results, cutoff=0, min_num_clusts=1, max_num_clusts=NA){ # Check inputs stopifnot(class(css_results) == &quot;cssr&quot;) checkCutoff(cutoff) p &lt;- ncol(css_results$feat_sel_mat) checkMinNumClusts(min_num_clusts, p, length(css_results$clusters)) max_num_clusts &lt;- checkMaxNumClusts(max_num_clusts, min_num_clusts, p, length(css_results$clusters)) sel_clusts &lt;- getCssSelections(css_results, cutoff=cutoff, min_num_clusts=min_num_clusts, max_num_clusts=max_num_clusts)$selected_clusts # sel_clusts is guaranteed to have length at least 1 by # getCssSelections # Get prototypes (feature from each cluster with highest selection # proportion, breaking ties by using marginal correlations of features with # y from data provided to css if y is real-valued) prototypes &lt;- getSelectionPrototypes(css_results, sel_clusts) # Cluster selection proportions if(length(sel_clusts) &gt; 1){ sel_clust_sel_props &lt;- colMeans(css_results$clus_sel_mat[, names(sel_clusts)]) } else{ sel_clust_sel_props &lt;- mean(css_results$clus_sel_mat[, names(sel_clusts)]) } # Data.frame: name of cluster, cluster prototype, selection proportion, # cluster size if(!is.null(names(prototypes))){ print_df &lt;- data.frame(ClustName=names(sel_clusts), ClustProtoName=names(prototypes), ClustProtoNum=unname(prototypes), ClustSelProp=sel_clust_sel_props, ClustSize=lengths(sel_clusts)) } else{ print_df &lt;- data.frame(ClustName=names(sel_clusts), ClustProtoNum=unname(prototypes), ClustSelProp=sel_clust_sel_props, ClustSize=lengths(sel_clusts)) } print_df &lt;- print_df[order(print_df$ClustSelProp, decreasing=TRUE), ] rownames(print_df) &lt;- NULL stopifnot(is.data.frame(print_df)) stopifnot(nrow(print_df) &gt;= 1) return(print_df) } getSelectionPrototypes() #&#39; Identify selection prototypes from selected clusters #&#39; #&#39; Takes in list of selected clusters and returns an integer vector of the #&#39; indices of the features that were most frequently selected from each cluster #&#39; #&#39; @param css_results An object of class &quot;cssr&quot; (the output of the function #&#39; css). #&#39; @param selected_clusts A list of integer vectors; each vector must contain #&#39; the indices of features in a cluster. #&#39; @return An integer vector (of length equal to the number of clusters) of the #&#39; indices of the feature prototypes (the features from each cluster that were #&#39; selected the most often individually by the base method in cluster stability #&#39; selection). In the case of a tie, the tie is broken by choosing the feature #&#39; most correlated with the response in the full data set provided to css. #&#39; @author Gregory Faletto, Jacob Bien getSelectionPrototypes &lt;- function(css_results, selected_clusts){ # Check inputs stopifnot(class(css_results) == &quot;cssr&quot;) stopifnot(is.list(selected_clusts)) n_selected_clusts &lt;- length(selected_clusts) stopifnot(n_selected_clusts &gt;= 1) stopifnot(all(lengths(selected_clusts) &gt;= 1)) prototypes &lt;- rep(as.integer(NA), n_selected_clusts) for(i in 1:n_selected_clusts){ clust_i &lt;- selected_clusts[[i]] sel_props_i &lt;- colMeans(css_results$feat_sel_mat)[clust_i] proto_i &lt;- clust_i[sel_props_i == max(sel_props_i)] stopifnot(length(proto_i) &gt;= 1) if(length(proto_i) &gt; 1){ if(is.numeric(css_results$y) | is.integer(css_results$y)){ # Break tie by looking at marginal correlations corrs_i &lt;- stats::cor(css_results$X[, proto_i], css_results$y)[, 1] corrs_i &lt;- abs(corrs_i) proto_i &lt;- proto_i[corrs_i == max(corrs_i)] } } # If there is still a tie, break by choosing the first feature of those # remaining prototypes[i] &lt;- proto_i[1] names(prototypes)[i] &lt;- colnames(css_results$X)[proto_i] } # Check output stopifnot(is.integer(prototypes)) stopifnot(all(!is.na(prototypes))) stopifnot(length(prototypes) == length(unique(prototypes))) return(prototypes) } Tests for getSelectionPrototypes(): testthat::test_that(&quot;getSelectionPrototypes works&quot;, { set.seed(67234) data &lt;- genClusteredData(n=15, p=11, k_unclustered=2, cluster_size=3, n_clusters=2, sig_clusters=1, sigma_eps_sq=10^(-6)) x &lt;- data$X y &lt;- data$y good_clusters &lt;- list(red_cluster=1L:3L, green_cluster=4L:6L) css_results &lt;- css(X=x, y=y, lambda=0.01, clusters=good_clusters) ret &lt;- getSelectionPrototypes(css_results, selected_clusts=good_clusters) testthat::expect_true(is.integer(ret)) testthat::expect_true(all(!is.na(ret))) testthat::expect_equal(length(ret), length(good_clusters)) testthat::expect_equal(length(ret), length(unique(ret))) for(i in 1:length(ret)){ testthat::expect_true(ret[i] %in% good_clusters[[i]]) # Find the largest selection proportion of any feature in cluster i max_prop &lt;- max(colMeans(css_results$feat_sel_mat[, good_clusters[[i]]])) # Find the selection proportion of the identified prototype proto_prop &lt;- colMeans(css_results$feat_sel_mat)[ret[i]] testthat::expect_equal(max_prop, proto_prop) } # Try with only one selected cluster (still should be in a list) ret &lt;- getSelectionPrototypes(css_results, selected_clusts=list(red_cluster=1L:3L)) testthat::expect_true(is.integer(ret)) testthat::expect_true(!is.na(ret)) testthat::expect_equal(length(ret), 1) testthat::expect_true(ret %in% 1L:3L) # Find the largest selection proportion of any feature in the cluster max_prop &lt;- max(colMeans(css_results$feat_sel_mat[, 1L:3L])) # Find the selection proportion of the identified prototype proto_prop &lt;- colMeans(css_results$feat_sel_mat)[ret] testthat::expect_equal(max_prop, proto_prop) ## Trying bad inputs # Error contains quotation marks testthat::expect_error(getSelectionPrototypes(x, good_clusters)) testthat::expect_error(getSelectionPrototypes(css_results, 1L:3L), &quot;is.list(selected_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getSelectionPrototypes(css_results, list()), &quot;n_selected_clusts &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getSelectionPrototypes(css_results, list(red_cluster=1L:3L, green_cluster=4L:6L, bad_cluster=integer())), &quot;all(lengths(selected_clusts) &gt;= 1) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 😸 Tests for printCssDf(): testthat::test_that(&quot;printCssDf works&quot;, { set.seed(67234) data &lt;- genClusteredData(n=15, p=11, k_unclustered=2, cluster_size=3, n_clusters=2, sig_clusters=1, sigma_eps_sq=10^(-6)) x &lt;- data$X y &lt;- data$y good_clusters &lt;- list(red_cluster=1L:3L, green_cluster=4L:6L) css_results &lt;- css(X=x, y=y, lambda=0.01, clusters=good_clusters, B=10) ret &lt;- printCssDf(css_results) testthat::expect_true(is.data.frame(ret)) testthat::expect_identical(colnames(ret), c(&quot;ClustName&quot;, &quot;ClustProtoNum&quot;, &quot;ClustSelProp&quot;, &quot;ClustSize&quot;)) # Total number of clusters is 11 - (3 - 1) - (3 - 1) = 7 testthat::expect_equal(nrow(ret), 7) testthat::expect_true(is.character(ret$ClustName)) testthat::expect_true(all(names(good_clusters) %in% ret$ClustName)) testthat::expect_equal(length(ret$ClustName), length(unique(ret$ClustName))) testthat::expect_true(is.integer(ret$ClustProtoNum)) testthat::expect_true(ret[ret$ClustName==&quot;red_cluster&quot;, &quot;ClustProtoNum&quot;] %in% 1L:3L) testthat::expect_true(ret[ret$ClustName==&quot;green_cluster&quot;, &quot;ClustProtoNum&quot;] %in% 4L:6L) other_rows &lt;- !(ret$ClustName %in% c(&quot;red_cluster&quot;, &quot;green_cluster&quot;)) testthat::expect_true(all(ret[other_rows, &quot;ClustProtoNum&quot;] %in% 7L:11L)) testthat::expect_true(length(ret[other_rows, &quot;ClustProtoNum&quot;]) == length(unique(ret[other_rows, &quot;ClustProtoNum&quot;]))) testthat::expect_true(is.numeric(ret$ClustSelProp)) testthat::expect_identical(ret$ClustSelProp, sort(ret$ClustSelProp, decreasing=TRUE)) testthat::expect_true(is.integer(ret$ClustSize)) testthat::expect_equal(ret[ret$ClustName==&quot;red_cluster&quot;, &quot;ClustSize&quot;], 3) testthat::expect_equal(ret[ret$ClustName==&quot;green_cluster&quot;, &quot;ClustSize&quot;], 3) testthat::expect_true(all(ret[other_rows, &quot;ClustSize&quot;] == 1)) # Try again naming features x_named &lt;- x colnames(x_named) &lt;- LETTERS[1:11] css_results_name_feats &lt;- css(X=x_named, y=y, lambda=0.01, clusters=good_clusters, B=10) ret &lt;- printCssDf(css_results_name_feats) testthat::expect_true(is.data.frame(ret)) testthat::expect_identical(colnames(ret), c(&quot;ClustName&quot;, &quot;ClustProtoName&quot;, &quot;ClustProtoNum&quot;, &quot;ClustSelProp&quot;, &quot;ClustSize&quot;)) # Total number of clusters is 11 - (3 - 1) - (3 - 1) = 7 testthat::expect_equal(nrow(ret), 7) testthat::expect_true(is.character(ret$ClustName)) testthat::expect_true(all(names(good_clusters) %in% ret$ClustName)) testthat::expect_equal(length(ret$ClustName), length(unique(ret$ClustName))) testthat::expect_true(is.character(ret$ClustProtoName)) testthat::expect_true(ret[ret$ClustName==&quot;red_cluster&quot;, &quot;ClustProtoName&quot;] %in% LETTERS[1:3]) testthat::expect_true(ret[ret$ClustName==&quot;green_cluster&quot;, &quot;ClustProtoName&quot;] %in% LETTERS[4:6]) other_rows &lt;- !(ret$ClustName %in% c(&quot;red_cluster&quot;, &quot;green_cluster&quot;)) testthat::expect_true(all(ret[other_rows, &quot;ClustProtoName&quot;] %in% LETTERS[7:11])) testthat::expect_true(length(ret[other_rows, &quot;ClustProtoName&quot;]) == length(unique(ret[other_rows, &quot;ClustProtoName&quot;]))) testthat::expect_true(is.integer(ret$ClustProtoNum)) testthat::expect_true(ret[ret$ClustName==&quot;red_cluster&quot;, &quot;ClustProtoNum&quot;] %in% 1L:3L) testthat::expect_true(ret[ret$ClustName==&quot;green_cluster&quot;, &quot;ClustProtoNum&quot;] %in% 4L:6L) testthat::expect_true(all(ret[other_rows, &quot;ClustProtoNum&quot;] %in% 7L:11L)) testthat::expect_true(length(ret[other_rows, &quot;ClustProtoNum&quot;]) == length(unique(ret[other_rows, &quot;ClustProtoNum&quot;]))) testthat::expect_true(is.numeric(ret$ClustSelProp)) testthat::expect_identical(ret$ClustSelProp, sort(ret$ClustSelProp, decreasing=TRUE)) testthat::expect_true(is.integer(ret$ClustSize)) testthat::expect_equal(ret[ret$ClustName==&quot;red_cluster&quot;, &quot;ClustSize&quot;], 3) testthat::expect_equal(ret[ret$ClustName==&quot;green_cluster&quot;, &quot;ClustSize&quot;], 3) testthat::expect_true(all(ret[other_rows, &quot;ClustSize&quot;] == 1)) # Unnamed clusters unnamed_clusters &lt;- list(1:3, 4:6) css_results_unnamed &lt;- css(X=x, y=y, lambda=0.01, clusters=unnamed_clusters, B=10) ret &lt;- printCssDf(css_results_unnamed) testthat::expect_true(is.data.frame(ret)) testthat::expect_identical(colnames(ret), c(&quot;ClustName&quot;, &quot;ClustProtoNum&quot;, &quot;ClustSelProp&quot;, &quot;ClustSize&quot;)) # Total number of clusters is 11 - (3 - 1) - (3 - 1) = 7 testthat::expect_equal(nrow(ret), 7) testthat::expect_true(is.character(ret$ClustName)) testthat::expect_equal(length(ret$ClustName), length(unique(ret$ClustName))) testthat::expect_true(is.integer(ret$ClustProtoNum)) testthat::expect_true(is.numeric(ret$ClustSelProp)) testthat::expect_identical(ret$ClustSelProp, sort(ret$ClustSelProp, decreasing=TRUE)) testthat::expect_true(is.integer(ret$ClustSize)) # Try other settings for cutoff, min_num_clusts, max_num_clusts, etc. ret &lt;- printCssDf(css_results, max_num_clusts=3) testthat::expect_true(is.data.frame(ret)) testthat::expect_identical(colnames(ret), c(&quot;ClustName&quot;, &quot;ClustProtoNum&quot;, &quot;ClustSelProp&quot;, &quot;ClustSize&quot;)) testthat::expect_true(nrow(ret) &lt;= 3) testthat::expect_true(is.character(ret$ClustName)) testthat::expect_equal(length(ret$ClustName), length(unique(ret$ClustName))) testthat::expect_true(is.integer(ret$ClustProtoNum)) other_rows &lt;- !(ret$ClustName %in% c(&quot;red_cluster&quot;, &quot;green_cluster&quot;)) testthat::expect_true(all(ret[other_rows, &quot;ClustProtoNum&quot;] %in% 7L:11L)) testthat::expect_true(length(ret[other_rows, &quot;ClustProtoNum&quot;]) == length(unique(ret[other_rows, &quot;ClustProtoNum&quot;]))) testthat::expect_true(is.numeric(ret$ClustSelProp)) testthat::expect_identical(ret$ClustSelProp, sort(ret$ClustSelProp, decreasing=TRUE)) testthat::expect_true(is.integer(ret$ClustSize)) testthat::expect_true(all(ret[other_rows, &quot;ClustSize&quot;] == 1)) if(&quot;red_cluster&quot; %in% ret$ClustName){ testthat::expect_true(ret[ret$ClustName==&quot;red_cluster&quot;, &quot;ClustProtoNum&quot;] %in% 1L:3L) testthat::expect_equal(ret[ret$ClustName==&quot;red_cluster&quot;, &quot;ClustSize&quot;], 3) } if(&quot;green_cluster&quot; %in% ret$ClustName){ testthat::expect_true(ret[ret$ClustName==&quot;green_cluster&quot;, &quot;ClustProtoNum&quot;] %in% 4L:6L) testthat::expect_equal(ret[ret$ClustName==&quot;green_cluster&quot;, &quot;ClustSize&quot;], 3) } ret &lt;- printCssDf(css_results, min_num_clusts=2, cutoff=1) testthat::expect_true(is.data.frame(ret)) testthat::expect_identical(colnames(ret), c(&quot;ClustName&quot;, &quot;ClustProtoNum&quot;, &quot;ClustSelProp&quot;, &quot;ClustSize&quot;)) # Total number of clusters is 11 - (3 - 1) - (3 - 1) = 7 testthat::expect_true(nrow(ret) &gt;= 2) testthat::expect_true(nrow(ret) &lt;= 7) testthat::expect_true(is.character(ret$ClustName)) testthat::expect_equal(length(ret$ClustName), length(unique(ret$ClustName))) testthat::expect_true(is.integer(ret$ClustProtoNum)) other_rows &lt;- !(ret$ClustName %in% c(&quot;red_cluster&quot;, &quot;green_cluster&quot;)) testthat::expect_true(all(ret[other_rows, &quot;ClustProtoNum&quot;] %in% 7L:11L)) testthat::expect_true(length(ret[other_rows, &quot;ClustProtoNum&quot;]) == length(unique(ret[other_rows, &quot;ClustProtoNum&quot;]))) testthat::expect_true(is.numeric(ret$ClustSelProp)) testthat::expect_identical(ret$ClustSelProp, sort(ret$ClustSelProp, decreasing=TRUE)) testthat::expect_true(is.integer(ret$ClustSize)) testthat::expect_true(all(ret[other_rows, &quot;ClustSize&quot;] == 1)) if(&quot;red_cluster&quot; %in% ret$ClustName){ testthat::expect_true(ret[ret$ClustName==&quot;red_cluster&quot;, &quot;ClustProtoNum&quot;] %in% 1L:3L) testthat::expect_equal(ret[ret$ClustName==&quot;red_cluster&quot;, &quot;ClustSize&quot;], 3) } if(&quot;green_cluster&quot; %in% ret$ClustName){ testthat::expect_true(ret[ret$ClustName==&quot;green_cluster&quot;, &quot;ClustProtoNum&quot;] %in% 4L:6L) testthat::expect_equal(ret[ret$ClustName==&quot;green_cluster&quot;, &quot;ClustSize&quot;], 3) } # ret &lt;- printCssDf(css_results, cutoff=1) testthat::expect_true(is.data.frame(ret)) testthat::expect_identical(colnames(ret), c(&quot;ClustName&quot;, &quot;ClustProtoNum&quot;, &quot;ClustSelProp&quot;, &quot;ClustSize&quot;)) testthat::expect_true(nrow(ret) &gt;= 1) testthat::expect_true(nrow(ret) &lt;= 7) testthat::expect_true(is.character(ret$ClustName)) testthat::expect_equal(length(ret$ClustName), length(unique(ret$ClustName))) testthat::expect_true(is.integer(ret$ClustProtoNum)) other_rows &lt;- !(ret$ClustName %in% c(&quot;red_cluster&quot;, &quot;green_cluster&quot;)) testthat::expect_true(all(ret[other_rows, &quot;ClustProtoNum&quot;] %in% 7L:11L)) testthat::expect_true(length(ret[other_rows, &quot;ClustProtoNum&quot;]) == length(unique(ret[other_rows, &quot;ClustProtoNum&quot;]))) testthat::expect_true(is.numeric(ret$ClustSelProp)) testthat::expect_identical(ret$ClustSelProp, sort(ret$ClustSelProp, decreasing=TRUE)) testthat::expect_true(is.integer(ret$ClustSize)) testthat::expect_true(all(ret[other_rows, &quot;ClustSize&quot;] == 1)) if(&quot;red_cluster&quot; %in% ret$ClustName){ testthat::expect_true(ret[ret$ClustName==&quot;red_cluster&quot;, &quot;ClustProtoNum&quot;] %in% 1L:3L) testthat::expect_equal(ret[ret$ClustName==&quot;red_cluster&quot;, &quot;ClustSize&quot;], 3) } if(&quot;green_cluster&quot; %in% ret$ClustName){ testthat::expect_true(ret[ret$ClustName==&quot;green_cluster&quot;, &quot;ClustProtoNum&quot;] %in% 4L:6L) testthat::expect_equal(ret[ret$ClustName==&quot;green_cluster&quot;, &quot;ClustSize&quot;], 3) } ## Trying bad inputs # Error has quotation marks in it testthat::expect_error(printCssDf(&quot;css_results&quot;)) testthat::expect_error(printCssDf(css_results, cutoff=-.1), &quot;cutoff &gt;= 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(printCssDf(css_results, min_num_clusts=3.2), &quot;min_num_clusts == round(min_num_clusts) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(printCssDf(css_results, max_num_clusts=&quot;5&quot;), &quot;is.numeric(max_num_clusts) | is.integer(max_num_clusts) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🎉 print.cssr() #&#39; Print cluster stability selection output #&#39; #&#39; Print a summary of the information from the css function (using output from #&#39; printCssDf function). #&#39; @param x An object of class &quot;cssr&quot; (the output of the function css). #&#39; @param cutoff Numeric; print.cssr will display only those #&#39; clusters with selection proportions equal to at least cutoff. Must be between #&#39; 0 and 1. Default is 0 (in which case either all clusters are displayed, or #&#39; max_num_clusts are, if max_num_clusts is specified). #&#39; @param min_num_clusts Integer or numeric; the minimum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns fewer than #&#39; min_num_clusts clusters, the cutoff will be increased until at least #&#39; min_num_clusts clusters are selected.) Default is 1. #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) Default is NA (in which case #&#39; max_num_clusts is ignored). #&#39; @param ... Additional arguments to generic print.data.frame function #&#39; @return A data.frame; each row contains a cluster, arranged in decreasing #&#39; order of cluster selection proportion from top to bottom. The columns are #&#39; ClustName (the name of the cluster that was either provided to css or made by #&#39; css if no name was provided); ClustProtoName (the name of the selection #&#39; prototype from the cluster, which is the feature with the greatest individual #&#39; selection proportion among all the cluster members, with ties broken by #&#39; choosing the feature with the highest correlation with the response if the #&#39; response is real-valued; only returned if the features are named), #&#39; ClustProtoNum (the column number of the prototype in the X matrix provided to #&#39; css), and ClustSize (the size of the cluster). #&#39; @author Gregory Faletto, Jacob Bien #&#39; @export print.cssr &lt;- function(x, cutoff=0, min_num_clusts=1, max_num_clusts=NA, ...){ df &lt;- printCssDf(css_results=x, cutoff=cutoff, min_num_clusts=min_num_clusts, max_num_clusts=max_num_clusts) print.data.frame(df, ...) } "],["wrapper-functions.html", "7 Convenient wrapper functions", " 7 Convenient wrapper functions Finally, we provide convenient wrapper functions which yield user-desired output in a single step at the price of flexibility and efficiency. cssSelect() yields a selected set of clusters and features (the same output as getCssSelections()) in a single function call. cssPredict() takes in a training/selection data set as well as a test X. It uses the labeled data to select a set of features and train an OLS model on the selected features, and then it generates predictions on the test set using the fitted model. Besides requiring only a single function call to yield desired output, these wrapper functions also automatically select hyperparameters (lambda used for the lasso, a desired model size, and even selection and training splits for cssPredict()) in a sensible way if these values are not provided by the user. So these functions are very convenient for an end user who wants quick results without getting “under the hood.” The two main disadvantages of these functions are flexibility and computational efficiency. For simplicity of use, these functions do not provide as many options as the component functions they call (for example, min_num_clusts is not an available argument for these models). Further, both of these functions make (computationally intensive) calls to css() internally every time they are called, so these functions are not recommended for users who want to tinker with the model size and other parameters. Instead, it would be more efficient to call css once and then work with the output as desired using the other package functions, which are very efficient given the stored output from css(). cssSelect() and cssPredict() have no new dependencies; they rely only on already-defined functions. cssSelect(): #&#39; Obtain a selected set of clusters and features using cluster stability #&#39; selection #&#39; #&#39; Takes in data X and y and returns a set of clusters (and a set of features) #&#39; that are useful for predicting y from the data in X. This is a wrapper #&#39; function for css and getCssSelections. Using cssSelect is simpler, but it #&#39; has fewer options, and it executes the full (computationally expensive) #&#39; subsampling procedured every time it is called. In contrast, css can be #&#39; called just once, and then getCssSelections can quickly return results using #&#39; different values of cutoff, max_num_clusts, etc. from the calculations done #&#39; in one call to css. #&#39; @param X An n x p numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; the p &gt;= 2 features/predictors. #&#39; @param y A length-n numeric vector containing the responses; `y[i]` is the #&#39; response corresponding to observation `X[i, ]`. (Note that for the css #&#39; function, y does not have to be a numeric response, but for this function, #&#39; the underlying selection procedure is the lasso, so y must be a real-valued #&#39; response.) #&#39; @param clusters Optional; either an integer vector of a list of integer #&#39; vectors; each vector should contain the indices of a cluster of features (a #&#39; subset of 1:p). (If there is only one cluster, clusters can either be a list #&#39; of length 1 or an integer vector.) All of the provided clusters must be #&#39; non-overlapping. Every feature not appearing in any cluster will be assumed #&#39; to be unclustered (that is, they will be treated as if they are in a #&#39; &quot;cluster&quot; containing only themselves). If clusters is a list of length 0 (or #&#39; a list only containing clusters of length 1), then css() returns the same #&#39; results as stability selection (so feat_sel_mat will be identical to #&#39; clus_sel_mat). Names for the clusters will be needed later; any clusters that #&#39; are not given names in the list clusters will be given names automatically by #&#39; css. CAUTION: if the provided X is a data.frame that contains a categorical #&#39; feature with more than two levels, then the resulting matrix made from #&#39; model.matrix will have a different number of columns than the provided #&#39; data.frame, some of the feature numbers will change, and the clusters #&#39; argument will not work properly (in the current version of the package). To #&#39; get correct results in this case, please use model.matrix to convert the #&#39; data.frame to a numeric matrix on your own, then provide this matrix and #&#39; cluster assignments with respect to this matrix. Default is list() (so no #&#39; clusters are specified, and every feature is assumed to be in a &quot;cluster&quot; #&#39; containing only itself). #&#39; @param lambda Optional; the tuning parameter to be used by the lasso for #&#39; feature selection in each subsample. If lambda is not provided, cssSelect #&#39; will choose one automatically by cross-validation. Default is NA. #&#39; @param cutoff Numeric; cssSelect will only select those clusters with #&#39; selection proportions equal to at least cutoff. Must be between 0 and 1. #&#39; Default is NA (in which case max_num_clusts are used). #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) Default is NA (in which case #&#39; either cutoff is used to choose the number of clusters, or if cutoff was also #&#39; unspecified, cssSelect chooses max_num_clusts by cross-validation). #&#39; @param auto_select_size Logical; if TRUE, then max_num_clusts will be #&#39; automatically estimated using the lasso with cross-validation. Default is #&#39; TRUE, though his argument is ignored if either cutoff or max_num_clusts is #&#39; provided. (If desired output is to return all clusters, you should set #&#39; auto_select_size to FALSE and do not provide cutoff or max_num_clusts.) #&#39; @return A named list with two items. \\item{selected_clusts}{A list of #&#39; integer vectors; each vector contains the indices of one of the selected #&#39; clusters.} \\item{selected_feats}{An integer vector; the indices of the #&#39; all of the selected features within all of the selected clusters (typically #&#39; only one feature is selected from each cluster).} #&#39; @author Gregory Faletto, Jacob Bien #&#39; @export cssSelect &lt;- function(X, y, clusters = list(), lambda=NA, cutoff=NA, max_num_clusts=NA, auto_select_size=TRUE){ # Check inputs (most inputs will be checked by called functions) stopifnot(!is.na(auto_select_size)) stopifnot(length(auto_select_size) == 1) stopifnot(is.logical(auto_select_size)) stopifnot(is.matrix(X) | is.data.frame(X)) stopifnot(all(!is.na(X))) # Check if x is a matrix; if it&#39;s a data.frame, convert to matrix. if(is.data.frame(X)){ p &lt;- ncol(X) X &lt;- stats::model.matrix(~ ., X) X &lt;- X[, colnames(X) != &quot;(Intercept)&quot;] if(length(clusters) &gt; 0 &amp; (p != ncol(X))){ stop(&quot;When stats::model.matrix converted the provided data.frame X to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert the data.frame X to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;) } } stopifnot(is.matrix(X)) stopifnot(all(!is.na(X))) if(!is.numeric(y) &amp; !is.integer(y)){ stop(&quot;The provided y must be real-valued, because cssSelect uses the lasso for feature selection. (In order to use a different form of response, use the css function and provide your own selection function accommodating your choice of y.)&quot;) } stopifnot(length(lambda) == 1) if(is.na(lambda)){ lambda &lt;- getLassoLambda(X, y) } css_results &lt;- css(X, y, lambda, clusters) # If no indication of how to select model size was provided, choose model # size by cross-validation if(is.na(cutoff) &amp; is.na(max_num_clusts)){ if(auto_select_size){ max_num_clusts &lt;- getModelSize(X, y, css_results$clusters) } } if(is.na(cutoff)){ cutoff &lt;- 0 } # Get selected features getCssSelections(css_results, weighting=&quot;sparse&quot;, cutoff=cutoff, min_num_clusts=1, max_num_clusts=max_num_clusts) } Tests for cssSelect(): testthat::test_that(&quot;cssSelect works&quot;, { set.seed(73212) data &lt;- genClusteredData(n=15, p=11, k_unclustered=2, cluster_size=3, n_clusters=2, sig_clusters=1, sigma_eps_sq=1) x &lt;- data$X y &lt;- data$y # Intentionally don&#39;t provide clusters for all features, mix up formatting, # etc. good_clusters &lt;- list(red_cluster=1L:3L, 4:6) res &lt;- cssSelect(X=x, y=y, clusters=good_clusters) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) testthat::expect_true(!is.null(names(res$selected_clusts))) testthat::expect_true(is.character(names(res$selected_clusts))) testthat::expect_true(length(res$selected_clusts) &lt;= length(res$selected_feats)) # Total of 11 - 2*(3 - 1) = 7 clusters testthat::expect_true(length(res$selected_clusts) &lt;= 7) testthat::expect_true(length(res$selected_clusts) &gt;= 1) testthat::expect_true(is.list(res$selected_clusts)) testthat::expect_equal(length(names(res$selected_clusts)), length(unique(names(res$selected_clusts)))) already_used_feats &lt;- integer() for(i in 1:length(res$selected_clusts)){ sels_i &lt;- res$selected_clusts[[i]] testthat::expect_true(length(sels_i) &gt;= 1) testthat::expect_true(is.integer(sels_i)) testthat::expect_true(all(sels_i %in% 1:11)) testthat::expect_equal(length(sels_i), length(unique(sels_i))) testthat::expect_equal(length(intersect(already_used_feats, sels_i)), 0) already_used_feats &lt;- c(already_used_feats, sels_i) } testthat::expect_true(length(already_used_feats) &lt;= 11) testthat::expect_equal(length(already_used_feats), length(unique(already_used_feats))) testthat::expect_true(all(already_used_feats %in% 1:11)) testthat::expect_true(length(res$selected_feats) &lt;= 11) testthat::expect_true(is.integer(res$selected_feats)) testthat::expect_true(length(res$selected_feats) &gt;= 1) testthat::expect_equal(length(names(res$selected_feats)), length(unique(names(res$selected_feats)))) testthat::expect_true(all(res$selected_feats &gt;= 1)) testthat::expect_true(all(res$selected_feats &lt;= 11)) testthat::expect_equal(length(res$selected_feats), length(unique(res$selected_feats))) # No provided clusters res &lt;- cssSelect(X=x, y=y) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) testthat::expect_true(!is.null(names(res$selected_clusts))) testthat::expect_true(is.character(names(res$selected_clusts))) testthat::expect_true(length(res$selected_clusts) &lt;= length(res$selected_feats)) testthat::expect_true(length(res$selected_clusts) &lt;= 11) testthat::expect_true(length(res$selected_clusts) &gt;= 1) testthat::expect_true(is.list(res$selected_clusts)) testthat::expect_equal(length(names(res$selected_clusts)), length(unique(names(res$selected_clusts)))) already_used_feats &lt;- integer() for(i in 1:length(res$selected_clusts)){ sels_i &lt;- res$selected_clusts[[i]] testthat::expect_true(length(sels_i) &gt;= 1) testthat::expect_true(is.integer(sels_i)) testthat::expect_true(all(sels_i %in% 1:11)) testthat::expect_equal(length(sels_i), length(unique(sels_i))) testthat::expect_equal(length(intersect(already_used_feats, sels_i)), 0) already_used_feats &lt;- c(already_used_feats, sels_i) } testthat::expect_true(length(already_used_feats) &lt;= 11) testthat::expect_equal(length(already_used_feats), length(unique(already_used_feats))) testthat::expect_true(all(already_used_feats %in% 1:11)) testthat::expect_true(length(res$selected_feats) &lt;= 11) testthat::expect_true(is.integer(res$selected_feats)) testthat::expect_true(length(res$selected_feats) &gt;= 1) testthat::expect_equal(length(names(res$selected_feats)), length(unique(names(res$selected_feats)))) testthat::expect_true(all(res$selected_feats &gt;= 1)) testthat::expect_true(all(res$selected_feats &lt;= 11)) testthat::expect_equal(length(res$selected_feats), length(unique(res$selected_feats))) ## Trying other inputs # X as a data.frame X_df &lt;- datasets::mtcars res &lt;- cssSelect(X=X_df, y=stats::rnorm(nrow(X_df)), clusters=1:3) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) testthat::expect_true(!is.null(names(res$selected_clusts))) testthat::expect_true(is.character(names(res$selected_clusts))) testthat::expect_true(length(res$selected_clusts) &lt;= length(res$selected_feats)) # Total of ncol(X_df) - (3 - 1) clusters testthat::expect_true(length(res$selected_clusts) &lt;= ncol(X_df) - 2) testthat::expect_true(length(res$selected_clusts) &gt;= 1) testthat::expect_true(is.list(res$selected_clusts)) testthat::expect_equal(length(names(res$selected_clusts)), length(unique(names(res$selected_clusts)))) already_used_feats &lt;- integer() for(i in 1:length(res$selected_clusts)){ sels_i &lt;- res$selected_clusts[[i]] testthat::expect_true(length(sels_i) &gt;= 1) testthat::expect_true(is.integer(sels_i)) testthat::expect_true(all(sels_i %in% 1:ncol(X_df))) testthat::expect_equal(length(sels_i), length(unique(sels_i))) testthat::expect_equal(length(intersect(already_used_feats, sels_i)), 0) already_used_feats &lt;- c(already_used_feats, sels_i) } testthat::expect_true(length(already_used_feats) &lt;= ncol(X_df)) testthat::expect_equal(length(already_used_feats), length(unique(already_used_feats))) testthat::expect_true(all(already_used_feats %in% 1:ncol(X_df))) testthat::expect_true(length(res$selected_feats) &lt;= ncol(X_df)) testthat::expect_true(is.integer(res$selected_feats)) testthat::expect_true(length(res$selected_feats) &gt;= 1) testthat::expect_equal(length(names(res$selected_feats)), length(unique(names(res$selected_feats)))) testthat::expect_true(all(res$selected_feats &gt;= 1)) testthat::expect_true(all(res$selected_feats &lt;= ncol(X_df))) testthat::expect_equal(length(res$selected_feats), length(unique(res$selected_feats))) # X as a dataframe with factors (number of columns of final design matrix # after one-hot encoding factors won&#39;t match number of columns of df2) # cyl, gear, and carb are factors with more than 2 levels df2 &lt;- X_df df2$cyl &lt;- as.factor(df2$cyl) df2$vs &lt;- as.factor(df2$vs) df2$am &lt;- as.factor(df2$am) df2$gear &lt;- as.factor(df2$gear) df2$carb &lt;- as.factor(df2$carb) # Should get error if I try to use data.frame with clusters, since data.frame # has factors with more than two levels testthat::expect_error(cssSelect(X=df2, y=stats::rnorm(nrow(X_df)), clusters=1:3), &quot;When stats::model.matrix converted the provided data.frame X to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert the data.frame X to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;, fixed=TRUE) # Should be fine if I don&#39;t use clusters res &lt;- cssSelect(X=df2, y=stats::rnorm(nrow(X_df))) X_df_mat &lt;- stats::model.matrix(~ ., df2) X_df_mat &lt;- X_df_mat[, colnames(X_df_mat) != &quot;(Intercept)&quot;] p &lt;- ncol(X_df_mat) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) testthat::expect_true(!is.null(names(res$selected_clusts))) testthat::expect_true(is.character(names(res$selected_clusts))) testthat::expect_true(length(res$selected_clusts) &lt;= length(res$selected_feats)) # Total of p - (3 - 1) clusters testthat::expect_true(length(res$selected_clusts) &lt;= p - 2) testthat::expect_true(length(res$selected_clusts) &gt;= 1) testthat::expect_true(is.list(res$selected_clusts)) testthat::expect_equal(length(names(res$selected_clusts)), length(unique(names(res$selected_clusts)))) already_used_feats &lt;- integer() for(i in 1:length(res$selected_clusts)){ sels_i &lt;- res$selected_clusts[[i]] testthat::expect_true(length(sels_i) &gt;= 1) testthat::expect_true(is.integer(sels_i)) testthat::expect_true(all(sels_i %in% 1:p)) testthat::expect_equal(length(sels_i), length(unique(sels_i))) testthat::expect_equal(length(intersect(already_used_feats, sels_i)), 0) already_used_feats &lt;- c(already_used_feats, sels_i) } testthat::expect_true(length(already_used_feats) &lt;= p) testthat::expect_equal(length(already_used_feats), length(unique(already_used_feats))) testthat::expect_true(all(already_used_feats %in% 1:p)) testthat::expect_true(length(res$selected_feats) &lt;= p) testthat::expect_true(is.integer(res$selected_feats)) testthat::expect_true(length(res$selected_feats) &gt;= 1) testthat::expect_equal(length(names(res$selected_feats)), length(unique(names(res$selected_feats)))) testthat::expect_true(all(res$selected_feats &gt;= 1)) testthat::expect_true(all(res$selected_feats &lt;= p)) testthat::expect_equal(length(res$selected_feats), length(unique(res$selected_feats))) # X as a matrix with column names x2 &lt;- x colnames(x2) &lt;- LETTERS[1:11] res &lt;- cssSelect(X=x2, y=y, clusters=good_clusters) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) testthat::expect_true(!is.null(names(res$selected_clusts))) testthat::expect_true(is.character(names(res$selected_clusts))) testthat::expect_true(length(res$selected_clusts) &lt;= length(res$selected_feats)) # Total of 11 - 2*(3 - 1) = 7 clusters testthat::expect_true(length(res$selected_clusts) &lt;= 7) testthat::expect_true(length(res$selected_clusts) &gt;= 1) testthat::expect_true(is.list(res$selected_clusts)) testthat::expect_equal(length(names(res$selected_clusts)), length(unique(names(res$selected_clusts)))) already_used_feats &lt;- integer() for(i in 1:length(res$selected_clusts)){ sels_i &lt;- res$selected_clusts[[i]] testthat::expect_true(length(sels_i) &gt;= 1) testthat::expect_true(is.integer(sels_i)) testthat::expect_true(all(sels_i %in% 1:11)) testthat::expect_equal(length(sels_i), length(unique(sels_i))) testthat::expect_equal(length(intersect(already_used_feats, sels_i)), 0) already_used_feats &lt;- c(already_used_feats, sels_i) } testthat::expect_true(length(already_used_feats) &lt;= 11) testthat::expect_equal(length(already_used_feats), length(unique(already_used_feats))) testthat::expect_true(all(already_used_feats %in% 1:11)) testthat::expect_true(length(res$selected_feats) &lt;= 11) testthat::expect_true(is.integer(res$selected_feats)) testthat::expect_true(length(res$selected_feats) &gt;= 1) testthat::expect_equal(length(names(res$selected_feats)), length(unique(names(res$selected_feats)))) testthat::expect_true(all(res$selected_feats &gt;= 1)) testthat::expect_true(all(res$selected_feats &lt;= 11)) testthat::expect_equal(length(res$selected_feats), length(unique(res$selected_feats))) # Vary inputs res &lt;- cssSelect(X=x, y=y, clusters=good_clusters, lambda=0.01) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) res &lt;- cssSelect(X=x, y=y, clusters=good_clusters, cutoff=0.6) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) res &lt;- cssSelect(X=x, y=y, clusters=good_clusters, max_num_clusts=6) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) testthat::expect_true(length(res$selected_clusts) &lt;= 6) res &lt;- cssSelect(X=x, y=y, clusters=good_clusters, auto_select_size=FALSE) testthat::expect_true(is.list(res)) testthat::expect_equal(length(res), 3) testthat::expect_identical(names(res), c(&quot;selected_clusts&quot;, &quot;selected_feats&quot;, &quot;weights&quot;)) # Total of 11 - 2*(3 - 1) = 7 clusters testthat::expect_equal(length(res$selected_clusts), 7) # Bad inputs testthat::expect_error(cssSelect(X=x[1:10, ], y=y), &quot;n == length(y) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssSelect(X=character(5), y=y), &quot;is.matrix(X) | is.data.frame(X) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssSelect(X=x, y=matrix(1:15, 5, 3)), &quot;!is.matrix(y) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssSelect(X=x, y=factor(rbinom(15, size=1, prob=.5))), &quot;The provided y must be real-valued, because cssSelect uses the lasso for feature selection. (In order to use a different form of response, use the css function and provide your own selection function accommodating your choice of y.)&quot;, fixed=TRUE) testthat::expect_error(cssSelect(X=x, y=y, clusters=&quot;clusters&quot;), &quot;is.numeric(clusters) | is.integer(clusters) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssSelect(X=x, y=y, lambda=-.1), &quot;For method cssLasso, lambda must be nonnegative.&quot;, fixed=TRUE) testthat::expect_error(cssSelect(X=x, y=y, cutoff=1.1), &quot;cutoff &lt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssSelect(X=x, y=y, max_num_clusts=1000), &quot;max_num_clusts &lt;= p is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssSelect(X=x, y=y, auto_select_size=1), &quot;is.logical(auto_select_size) is not TRUE&quot;, fixed=TRUE) }) ## ── Warning (&#39;&lt;text&gt;:14&#39;): cssSelect works ────────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssSelect(X = x, y = y, clusters = good_clusters) ## 2. litr (local) getLassoLambda(X, y) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:14&#39;): cssSelect works ────────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssSelect(X = x, y = y, clusters = good_clusters) ## 2. litr (local) getModelSize(X, y, css_results$clusters) ## 3. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:59&#39;): cssSelect works ────────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssSelect(X = x, y = y) ## 2. litr (local) getLassoLambda(X, y) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:59&#39;): cssSelect works ────────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssSelect(X = x, y = y) ## 2. litr (local) getModelSize(X, y, css_results$clusters) ## 3. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:107&#39;): cssSelect works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssSelect(X = X_df, y = stats::rnorm(nrow(X_df)), clusters = 1:3) ## 2. litr (local) getLassoLambda(X, y) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:107&#39;): cssSelect works ───────────────────────────────────── ## Returning more than max_num_clusts = 1 clusters because increasing the cutoff any further would require returning 0 clusters ## Backtrace: ## 1. litr (local) cssSelect(X = X_df, y = stats::rnorm(nrow(X_df)), clusters = 1:3) ## 2. litr (local) getCssSelections(...) ## 3. litr (local) getSelectedClusters(...) ## 4. litr (local) checkSelectedClusters(...) ## ## ── Warning (&#39;&lt;text&gt;:167&#39;): cssSelect works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssSelect(X = df2, y = stats::rnorm(nrow(X_df))) ## 2. litr (local) getLassoLambda(X, y) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:219&#39;): cssSelect works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssSelect(X = x2, y = y, clusters = good_clusters) ## 2. litr (local) getLassoLambda(X, y) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:219&#39;): cssSelect works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssSelect(X = x2, y = y, clusters = good_clusters) ## 2. litr (local) getModelSize(X, y, css_results$clusters) ## 3. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:263&#39;): cssSelect works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssSelect(X = x, y = y, clusters = good_clusters, lambda = 0.01) ## 2. litr (local) getModelSize(X, y, css_results$clusters) ## 3. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:270&#39;): cssSelect works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssSelect(X = x, y = y, clusters = good_clusters, cutoff = 0.6) ## 2. litr (local) getLassoLambda(X, y) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:277&#39;): cssSelect works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssSelect(X = x, y = y, clusters = good_clusters, max_num_clusts = 6) ## 2. litr (local) getLassoLambda(X, y) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:285&#39;): cssSelect works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssSelect(X = x, y = y, clusters = good_clusters, auto_select_size = FALSE) ## 2. litr (local) getLassoLambda(X, y) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:302&#39;): cssSelect works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. testthat::expect_error(...) ## 7. litr (local) cssSelect(X = x, y = matrix(1:15, 5, 3)) ## 8. litr (local) getLassoLambda(X, y) ## 9. glmnet::cv.glmnet(...) ## 10. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:309&#39;): cssSelect works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. testthat::expect_error(...) ## 7. litr (local) cssSelect(X = x, y = y, clusters = &quot;clusters&quot;) ## 8. litr (local) getLassoLambda(X, y) ## 9. glmnet::cv.glmnet(...) ## 10. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:317&#39;): cssSelect works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. testthat::expect_error(...) ## 7. litr (local) cssSelect(X = x, y = y, cutoff = 1.1) ## 8. litr (local) getLassoLambda(X, y) ## 9. glmnet::cv.glmnet(...) ## 10. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:320&#39;): cssSelect works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. testthat::expect_error(...) ## 7. litr (local) cssSelect(X = x, y = y, max_num_clusts = 1000) ## 8. litr (local) getLassoLambda(X, y) ## 9. glmnet::cv.glmnet(...) ## 10. glmnet:::cv.glmnet.raw(...) cssPredict(): #&#39; Wrapper function to generate predictions from cluster stability selected #&#39; model in one step #&#39; #&#39; Select clusters using cluster stability selection, form cluster #&#39; representatives, fit a linear model, and generate predictions from a matrix #&#39; of unlabeled data. This is a wrapper function for css and getCssPreds. Using #&#39; cssPredict is simpler, but it has fewer options, and it executes the full #&#39; (computationally expensive) subsampling procedured every time it is called. #&#39; In contrast, css can be called just once, and then cssPredict can quickly #&#39; return results for different matrices of new data or using different values #&#39; of cutoff, max_num_clusts, etc. by using the calculations done in one call to #&#39; css. #&#39; #&#39; @param X_train_selec An n x p numeric matrix (preferably) or a data.frame #&#39; (which will be coerced internally to a matrix by the function model.matrix) #&#39; containing the p &gt;= 2 features/predictors. The data from X_train_selec and #&#39; y_train_selec will be split into two parts; half of the data will be used for #&#39; feature selection by cluster stability selection, and half will be used for #&#39; estimating a linear model on the selected cluster representatives. #&#39; @param y_train_selec A length-n numeric vector containing the responses; #&#39; `y[i]` is the response corresponding to observation `X[i, ]`. Unlke the more #&#39; general setup of css, y_train_selec must be real-valued because predictions #&#39; will be generated by ordinary least squares. #&#39; @param X_test A numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; the data that will be used to generate predictions. Must contain the same #&#39; features (in the same number of columns) as X_train_selec, and if the columns #&#39; of X_test are named, they must match the names of X_train_selec. #&#39; @param clusters Optional; either an integer vector of a list of integer #&#39; vectors; each vector should contain the indices of a cluster of features (a #&#39; subset of 1:p). (If there is only one cluster, clusters can either be a list #&#39; of length 1 or an integer vector.) All of the provided clusters must be #&#39; non-overlapping. Every feature not appearing in any cluster will be assumed #&#39; to be unclustered (that is, they will be treated as if they are in a #&#39; &quot;cluster&quot; containing only themselves). If clusters is a list of length 0 (or #&#39; a list only containing clusters of length 1), then css() returns the same #&#39; results as stability selection (so feat_sel_mat will be identical to #&#39; clus_sel_mat). Names for the clusters will be needed later; any clusters that #&#39; are not given names in the list clusters will be given names automatically by #&#39; css. CAUTION: if the provided X is a data.frame that contains a categorical #&#39; feature with more than two levels, then the resulting matrix made from #&#39; model.matrix will have a different number of columns than the provided #&#39; data.frame, some of the feature numbers will change, and the clusters #&#39; argument will not work properly (in the current version of the package). To #&#39; get correct results in this case, please use model.matrix to convert the #&#39; data.frame to a numeric matrix on your own, then provide this matrix and #&#39; cluster assignments with respect to this matrix.Default is list() (so no #&#39; clusters are specified, and every feature is assumed to be in a &quot;cluster&quot; #&#39; containing only itself). #&#39; @param lambda Optional; the tuning parameter to be used by the lasso for #&#39; feature selection in each subsample. If lambda is not provided, cssPredict #&#39; will choose one automatically by cross-validation. Default is NA. #&#39; @param cutoff Numeric; getCssPreds will make use only of those clusters with #&#39; selection proportions equal to at least cutoff. Must be between 0 and 1. #&#39; Default is 0 (in which case either all clusters are used, or max_num_clusts #&#39; are used, if max_num_clusts is specified). #&#39; @param max_num_clusts Integer or numeric; the maximum number of clusters to #&#39; use regardless of cutoff. (That is, if the chosen cutoff returns more than #&#39; max_num_clusts clusters, the cutoff will be decreased until at most #&#39; max_num_clusts clusters are selected.) Default is NA (in which case #&#39; max_num_clusts is ignored). #&#39; @param train_inds Optional; an integer or numeric vector containing the #&#39; indices of observations in X and y to set aside for model training after #&#39; feature selection. If train_inds is not provided, half of the data will be #&#39; used for feature selection and half for model estimation (chosen at random). #&#39; @param auto_select_size Logical; if TRUE, then max_num_clusts will be #&#39; automatically estimated using the lasso with cross-validation. Default is #&#39; TRUE, though his argument is ignored if either cutoff or max_num_clusts is #&#39; provided. (If desired output is to generate predictions using all clusters, #&#39; you should set auto_select_size to FALSE and do not provide cutoff or #&#39; max_num_clusts.) #&#39; @return A numeric vector of length nrow(X_test) of predictions #&#39; corresponding to the observations from X_test. #&#39; @author Gregory Faletto, Jacob Bien #&#39; @export cssPredict &lt;- function(X_train_selec, y_train_selec, X_test, clusters=list(), lambda=NA, cutoff=NA, max_num_clusts=NA, train_inds=NA, auto_select_size=TRUE){ # Check inputs (most inputs will be checked by called functions) if(!is.numeric(y_train_selec) &amp; !is.integer(y_train_selec)){ stop(&quot;The provided y_train_selec must be real-valued, because predictions will be generated by ordinary least squares regression.&quot;) } stopifnot(!is.na(auto_select_size)) stopifnot(length(auto_select_size) == 1) stopifnot(is.logical(auto_select_size)) stopifnot(is.matrix(X_train_selec) | is.data.frame(X_train_selec)) stopifnot(all(!is.na(X_train_selec))) # Check if x is a matrix; if it&#39;s a data.frame, convert to matrix. if(is.data.frame(X_train_selec)){ p &lt;- ncol(X_train_selec) X_train_selec &lt;- stats::model.matrix(~ ., X_train_selec) X_train_selec &lt;- X_train_selec[, colnames(X_train_selec) != &quot;(Intercept)&quot;] if(length(clusters) &gt; 0 &amp; (p != ncol(X_train_selec))){ stop(&quot;When stats::model.matrix converted the provided data.frame X_train_selec to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert X_train_selec to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;) } } stopifnot(is.matrix(X_train_selec)) stopifnot(all(!is.na(X_train_selec))) n &lt;- nrow(X_train_selec) if(any(is.na(train_inds))){ train_inds &lt;- sample(n, size=round(n/2)) } stopifnot(length(lambda) == 1) if(is.na(lambda)){ lambda &lt;- getLassoLambda(X_train_selec[setdiff(1:n, train_inds), ], y_train_selec[setdiff(1:n, train_inds)]) } css_results &lt;- css(X=X_train_selec, y=y_train_selec, lambda=lambda, clusters=clusters, train_inds=train_inds) # If no indication of how to select model size was provided, choose model # size by cross-validation if(is.na(cutoff) &amp; is.na(max_num_clusts)){ if(auto_select_size){ max_num_clusts &lt;- getModelSize(X_train_selec[train_inds, ], y_train_selec[train_inds], css_results$clusters) } } if(is.na(cutoff)){ cutoff &lt;- 0 } # Get predictions getCssPreds(css_results, testX=X_test, weighting=&quot;weighted_avg&quot;, cutoff=cutoff, max_num_clusts=max_num_clusts) } Tests for cssPredict(): testthat::test_that(&quot;cssPredict works&quot;, { set.seed(84231) train_data &lt;- genClusteredData(n=30, p=11, k_unclustered=2, cluster_size=3, n_clusters=2, sig_clusters=1, sigma_eps_sq=1) x &lt;- train_data$X y &lt;- train_data$y test_x &lt;- genClusteredData(n=5, p=11, k_unclustered=2, cluster_size=3, n_clusters=2, sig_clusters=1, sigma_eps_sq=1)$X # Intentionally don&#39;t provide clusters for all features, mix up formatting, # etc. good_clusters &lt;- list(red_cluster=1L:3L, 4:6) res &lt;- cssPredict(X_train_selec=x, y_train_selec=y, X_test=test_x, clusters=good_clusters) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), 5) # No provided clusters res &lt;- cssPredict(X_train_selec=x, y_train_selec=y, X_test=test_x) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), 5) # Provide training indices res &lt;- cssPredict(X_train_selec=x, y_train_selec=y, X_test=test_x, train_inds=13:28) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), 5) ## Trying other inputs # X as a data.frame X_df &lt;- datasets::mtcars n &lt;- nrow(X_df) test_inds &lt;- 1:round(n/3) n_test &lt;- length(test_inds) selec_train_inds &lt;- setdiff(1:n, test_inds) n_selec_train &lt;- length(selec_train_inds) res &lt;- cssPredict(X_train_selec=X_df[selec_train_inds, ], y_train_selec=stats::rnorm(n_selec_train), X_test=X_df[test_inds, ]) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), n_test) # X as a dataframe with factors (number of columns of final design matrix # after one-hot encoding factors won&#39;t match number of columns of df2) # cyl, gear, and carb are factors with more than 2 levels df2 &lt;- X_df df2$cyl &lt;- as.factor(df2$cyl) df2$vs &lt;- as.factor(df2$vs) df2$am &lt;- as.factor(df2$am) df2$gear &lt;- as.factor(df2$gear) df2$carb &lt;- as.factor(df2$carb) # Should get error if clusters are provided because df2 contains factors with # more than two levels testthat::expect_error(cssPredict(X_train_selec=df2[selec_train_inds, ], y_train_selec=stats::rnorm(n_selec_train), X_test=df2[test_inds, ], clusters=1:3), &quot;When stats::model.matrix converted the provided data.frame X_train_selec to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert X_train_selec to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;, fixed=TRUE) # Should be fine if no clusters are provided res &lt;- cssPredict(X_train_selec=df2[selec_train_inds, ], y_train_selec=stats::rnorm(n_selec_train), X_test=df2[test_inds, ]) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), n_test) # X as a matrix with column names x2 &lt;- x colnames(x2) &lt;- LETTERS[1:11] test_x2 &lt;- test_x colnames(test_x2) &lt;- LETTERS[1:11] res &lt;- cssPredict(X_train_selec=x2, y_train_selec=y, X_test=test_x2, clusters=good_clusters) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), 5) # Vary inputs res &lt;- cssPredict(X_train_selec=x, y_train_selec=y, X_test=test_x, lambda=0.01) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), 5) res &lt;- cssPredict(X_train_selec=x, y_train_selec=y, X_test=test_x, cutoff=0.6) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), 5) res &lt;- cssPredict(X_train_selec=x, y_train_selec=y, X_test=test_x, max_num_clusts=6) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), 5) res &lt;- cssPredict(X_train_selec=x, y_train_selec=y, X_test=test_x, auto_select_size=FALSE) testthat::expect_true(all(!is.na(res))) testthat::expect_true(is.numeric(res)) testthat::expect_equal(length(res), 5) # Bad inputs testthat::expect_error(cssPredict(X_train_selec=x[1:10, ], y_train_selec=y, X_test=test_x), &quot;length(y) == n is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssPredict(X_train_selec=character(30), y_train_selec=y, X_test=test_x), &quot;is.matrix(X_train_selec) | is.data.frame(X_train_selec) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssPredict(X_train_selec=x, y_train_selec=matrix(1:30, 10, 3), X_test=test_x), &quot;!is.matrix(y) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssPredict(X_train_selec=x, y_train_selec=factor(rbinom(30, size=1, prob=.5)), X_test=test_x), &quot;The provided y_train_selec must be real-valued, because predictions will be generated by ordinary least squares regression.&quot;, fixed=TRUE) testthat::expect_error(cssPredict(X_train_selec=x, y_train_selec=y, X_test=test_x, clusters=&quot;clusters&quot;), &quot;is.numeric(clusters) | is.integer(clusters) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssPredict(X_train_selec=x, y_train_selec=y, X_test=test_x, lambda=&quot;lambda&quot;), &quot;For method cssLasso, lambda must be a numeric.&quot;, fixed=TRUE) testthat::expect_error(cssPredict(X_train_selec=x, y_train_selec=y, X_test=test_x, cutoff=-.1), &quot;cutoff &gt;= 0 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssPredict(X_train_selec=x, y_train_selec=y, X_test=test_x, max_num_clusts=0), &quot;max_num_clusts &gt;= 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(cssPredict(X_train_selec=x, y_train_selec=y, X_test=test_x, auto_select_size=c(TRUE, FALSE)), &quot;length(auto_select_size) == 1 is not TRUE&quot;, fixed=TRUE) }) ## ── Warning (&#39;&lt;text&gt;:17&#39;): cssPredict works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getLassoLambda(...) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:17&#39;): cssPredict works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getModelSize(...) ## 3. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:26&#39;): cssPredict works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(X_train_selec = x, y_train_selec = y, X_test = test_x) ## 2. litr (local) getLassoLambda(...) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:26&#39;): cssPredict works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(X_train_selec = x, y_train_selec = y, X_test = test_x) ## 2. litr (local) getModelSize(...) ## 3. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:34&#39;): cssPredict works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getLassoLambda(...) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:34&#39;): cssPredict works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getModelSize(...) ## 3. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:52&#39;): cssPredict works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getLassoLambda(...) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:52&#39;): cssPredict works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getModelSize(...) ## 3. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:79&#39;): cssPredict works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getLassoLambda(...) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:79&#39;): cssPredict works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getModelSize(...) ## 3. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:93&#39;): cssPredict works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getLassoLambda(...) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:93&#39;): cssPredict works ───────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getModelSize(...) ## 3. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:101&#39;): cssPredict works ──────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getModelSize(...) ## 3. glmnet::cv.glmnet(x = X_size, y = y, family = &quot;gaussian&quot;) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:108&#39;): cssPredict works ──────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getLassoLambda(...) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:114&#39;): cssPredict works ──────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getLassoLambda(...) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:121&#39;): cssPredict works ──────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. litr (local) cssPredict(...) ## 2. litr (local) getLassoLambda(...) ## 3. glmnet::cv.glmnet(...) ## 4. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:129&#39;): cssPredict works ──────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. testthat::expect_error(...) ## 7. litr (local) cssPredict(X_train_selec = x[1:10, ], y_train_selec = y, X_test = test_x) ## 8. litr (local) getLassoLambda(...) ## 9. glmnet::cv.glmnet(...) ## 10. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:138&#39;): cssPredict works ──────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. testthat::expect_error(...) ## 7. litr (local) cssPredict(...) ## 8. litr (local) getLassoLambda(...) ## 9. glmnet::cv.glmnet(...) ## 10. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:150&#39;): cssPredict works ──────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. testthat::expect_error(...) ## 7. litr (local) cssPredict(...) ## 8. litr (local) getLassoLambda(...) ## 9. glmnet::cv.glmnet(...) ## 10. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:160&#39;): cssPredict works ──────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. testthat::expect_error(...) ## 7. litr (local) cssPredict(...) ## 8. litr (local) getLassoLambda(...) ## 9. glmnet::cv.glmnet(...) ## 10. glmnet:::cv.glmnet.raw(...) ## ## ── Warning (&#39;&lt;text&gt;:164&#39;): cssPredict works ──────────────────────────────────── ## Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold ## Backtrace: ## 1. testthat::expect_error(...) ## 7. litr (local) cssPredict(...) ## 8. litr (local) getLassoLambda(...) ## 9. glmnet::cv.glmnet(...) ## 10. glmnet:::cv.glmnet.raw(...) "],["competitor-methods.html", "8 Competitor Methods", " 8 Competitor Methods We also provide implementations of some competitor feature selection methods. We used these in the simulation studies in our paper to compare cluster stability selection to the protolasso (Reid and Tibshirani, 2016) and the cluster representative lasso (Bühlmann et. al. 2013), two other feature selection methods that are designed for data with clustered features. These feature selection methods are in some ways closely related, so their implementations share helper functions. protolasso() processClusterLassoInputs() checks and formats the function inputs getXglmnet() formats the provided design matrix Xglmnet for the lasso as implemented by glmnet (for the protolasso, this means discarding all features from each cluster except the one most highly correlated with the response; for the cluster representative lasso, this means replacing the clustered features with a simple average of the cluster members). checkGetXglmnetInputs() verifies the inputs to getXglmnet() Finally, getClusterSelsFromGlmnet() extracts the relevant output from the results yielded by a glmnet lasso fit. getSelectedSets() takes in a single selected set from Xglmnet and yields a selected feature set in the original feature space (with each selected cluster from Xglmnet replaced by its prototype) as well as a selected set of clusters. clusterRepLasso() protolasso(): #&#39; Select features via the protolasso (Reid and Tibshirani 2016) #&#39; #&#39; @param X An n x p numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; p &gt;= 2 features/predictors #&#39; @param y The response; A length n numeric (or integer) real-valued vector. #&#39; @param clusters A list of integer vectors; each vector should contain the #&#39; indices of a cluster of features (a subset of 1:p). (If there is only one #&#39; cluster, clusters can either be a list of length 1 or an integer vector.) #&#39; All of the provided clusters must be non-overlapping. Every feature not #&#39; appearing in any cluster will be assumed to be unclustered (that is, they #&#39; will be treated as if they are in a &quot;cluster&quot; containing only themselves). #&#39; #&#39; CAUTION: if the provided X is a data.frame that contains a categorical #&#39; feature with more than two levels, then the resulting matrix made from #&#39; model.matrix will have a different number of columns than the provided #&#39; data.frame, some of the feature numbers will change, and the clusters #&#39; argument will not work properly (in the current version of the package). #&#39; To get correct results in this case, please use model.matrix to convert #&#39; the data.frame to a numeric matrix on your own, then provide this matrix #&#39; and cluster assignments with respect to this matrix. Default is list() (so no #&#39; clusters are specified). #&#39; @param nlambda Integer; the number of lambda values to use in the lasso fit #&#39; for the protolasso. Default is 100 (following the default for glmnet). For #&#39; now, nlambda must be at least 2 (using a single lambda is not supported). #&#39; @return A list with three elements. \\item{selected_sets}{A list of integer #&#39; vectors. Entry k of this list contains a selected set (an integer vector) of #&#39; size k yielded by the protolasso (If no set of size k was selected, entry k #&#39; will be empty.)} \\item{selected_clusts_list}{A list; each element of the list #&#39; is a named list of selected clusters. (That is, if a selected set of size k #&#39; was yielded by the protolasso, then selected_clusts_list[[k]] is a named #&#39; list of length k, where each member of the list is an integer vector #&#39; of cluster members. In particular, selected_clusts_lists[[k]][[j]] will be #&#39; the cluster that contains feature selected_sets[[k]][j].)} \\item{beta}{The #&#39; beta output from glmnet when the lasso was estimated on a matrix of #&#39; prototypes. (See documentation for the function glmnet from the glmnet #&#39; package for details.)} #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references Reid, S., &amp; Tibshirani, R. (2016). Sparse regression and marginal #&#39; testing using cluster prototypes. \\emph{Biostatistics}, 17(2), 364–376. #&#39; \\url{https://doi.org/10.1093/biostatistics/kxv049}. #&#39; @export protolasso &lt;- function(X, y, clusters=list(), nlambda=100){ # Handle and format inputs; get cluster prototypes ret &lt;- processClusterLassoInputs(X, y, clusters, nlambda) x &lt;- ret$x clusters &lt;- ret$clusters prototypes &lt;- ret$prototypes feat_names &lt;- ret$var_names rm(ret) # Format the design matrix for glmnet according to the protolasso procedure X_glmnet &lt;- getXglmnet(x, clusters, type=&quot;protolasso&quot;, prototypes=prototypes) # Estimate the lasso on the cluster prototypes fit &lt;- glmnet::glmnet(x=X_glmnet, y=y, family=&quot;gaussian&quot;, nlambda=nlambda) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) # Finally, obtain a tidy list of selected sets--one for each model size cluster_sel_results &lt;- getClusterSelsFromGlmnet(lasso_sets, clusters, prototypes, feat_names) return(list(selected_sets=cluster_sel_results$selected_sets, selected_clusts_list=cluster_sel_results$selected_clusts_list, beta=fit$beta)) } processClusterLassoInputs(): #&#39; Check the inputs to protolasso and clusterRepLasso, format clusters, and #&#39; identify prototypes for each cluster #&#39; #&#39; @param X An n x p numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; p &gt;= 2 features/predictors #&#39; @param y The response; A length n numeric (or integer) real-valued vector. #&#39; @param clusters A list of integer vectors; each vector should contain the #&#39; indices of a cluster of features (a subset of 1:p). (If there is only one #&#39; cluster, clusters can either be a list of length 1 or an integer vector.) #&#39; All of the provided clusters must be non-overlapping. Every feature not #&#39; appearing in any cluster will be assumed to be unclustered (that is, they #&#39; will be treated as if they are in a &quot;cluster&quot; containing only themselves). #&#39; Default is list() (so no clusters are specified). #&#39; @param nlambda Integer; the number of lambda values to use in the lasso fit #&#39; for the protolasso. Default is 100 (following the default for glmnet). For #&#39; now, nlambda must be at least 2 (using a single lambda is not supported). #&#39; @return A list with four elements. \\item{x}{The provided X, converted to a #&#39; matrix if it was provided as a data.frame, and with column names removed.} #&#39; \\item{clusters}{A named list where each entry is an integer vector of indices #&#39; of features that are in a common cluster. (The length of list clusters is #&#39; equal to the number of clusters.) All identified clusters are #&#39; non-overlapping. All features appear in exactly one cluster (any unclustered #&#39; features will be put in their own &quot;cluster&quot; of size 1).} #&#39; \\item{prototypes}{An integer vector whose length is equal to the number of #&#39; clusters. Entry i is the index of the feature belonging to cluster i that is #&#39; most highly correlated with y (that is, the prototype for the cluster, as in #&#39; the protolasso; see Reid and Tibshirani 2016).} \\item{var_names}{If the #&#39; provided X matrix had column names, the names of the featurrs in the provided #&#39; X matrix. If no names were provided, feat_names will be NA.} #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references Reid, S., &amp; Tibshirani, R. (2016). Sparse regression and marginal #&#39; testing using cluster prototypes. \\emph{Biostatistics}, 17(2), 364–376. #&#39; \\url{https://doi.org/10.1093/biostatistics/kxv049}. processClusterLassoInputs &lt;- function(X, y, clusters, nlambda){ stopifnot(is.matrix(X) | is.data.frame(X)) # Check if x is a matrix; if it&#39;s a data.frame, convert to matrix. if(is.data.frame(X)){ p &lt;- ncol(X) X &lt;- stats::model.matrix(~ ., X) X &lt;- X[, colnames(X) != &quot;(Intercept)&quot;] if(p != ncol(X) &amp; length(clusters) &gt; 0){ stop(&quot;When stats::model.matrix converted the provided data.frame X to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert X to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;) } } stopifnot(is.matrix(X)) stopifnot(all(!is.na(X))) feat_names &lt;- as.character(NA) if(!is.null(colnames(X))){ feat_names &lt;- colnames(X) if(any(is.na(feat_names))){ stop(&quot;Some features in provided X matrix had valid names and some had NA names; please neither name all features in X or remove the names altogether.&quot;) } } n &lt;- nrow(X) colnames(X) &lt;- character() stopifnot(is.numeric(y) | is.integer(y)) stopifnot(n == length(y)) stopifnot(all(!is.na(y))) # Check clusters argument clusters &lt;- checkCssClustersInput(clusters) # Format clusters into a list where all features are in exactly one # cluster (any unclustered features are put in their own &quot;cluster&quot; of size # 1). clust_names &lt;- as.character(NA) if(!is.null(names(clusters)) &amp; is.list(clusters)){ clust_names &lt;- names(clusters) } cluster_results &lt;- formatClusters(clusters, p=ncol(X), clust_names=clust_names, get_prototypes=TRUE, x=X, y=y) clusters &lt;- cluster_results$clusters prototypes &lt;- cluster_results$prototypes rm(cluster_results) stopifnot(length(clusters) == length(prototypes)) stopifnot(is.numeric(nlambda) | is.integer(nlambda)) stopifnot(length(nlambda) == 1) stopifnot(!is.na(nlambda)) stopifnot(nlambda &gt;= 2) stopifnot(nlambda == round(nlambda)) return(list(x=X, clusters=clusters, prototypes=prototypes, var_names=feat_names)) } Tests for processClusterLassoInputs(): testthat::test_that(&quot;processClusterLassoInputs works&quot;, { set.seed(82612) x &lt;- matrix(stats::rnorm(15*11), nrow=15, ncol=11) y &lt;- stats::rnorm(15) good_clusters &lt;- list(red_cluster=1L:4L, green_cluster=5L:8L) ret &lt;- processClusterLassoInputs(X=x, y=y, clusters=good_clusters, nlambda=10) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;x&quot;, &quot;clusters&quot;, &quot;prototypes&quot;, &quot;var_names&quot;)) # X testthat::expect_true(is.matrix(ret$x)) testthat::expect_true(all(!is.na(ret$x))) testthat::expect_true(is.numeric(ret$x)) testthat::expect_equal(ncol(ret$x), 11) testthat::expect_equal(nrow(ret$x), 15) testthat::expect_true(all(abs(ret$x - x) &lt; 10^(-9))) # clusters testthat::expect_true(is.list(ret$clusters)) testthat::expect_equal(length(ret$clusters), 5) testthat::expect_equal(5, length(names(ret$clusters))) testthat::expect_equal(5, length(unique(names(ret$clusters)))) testthat::expect_true(&quot;red_cluster&quot; %in% names(ret$clusters)) testthat::expect_true(&quot;green_cluster&quot; %in% names(ret$clusters)) testthat::expect_true(all(!is.na(names(ret$clusters)))) testthat::expect_true(all(!is.null(names(ret$clusters)))) testthat::expect_true(all(names(ret$clusters) != &quot;&quot;)) clust_feats &lt;- integer() true_list &lt;- list(1:4, 5:8, 9, 10, 11) for(i in 1:length(ret$clusters)){ testthat::expect_true(is.integer(ret$clusters[[i]])) testthat::expect_equal(length(intersect(clust_feats, ret$clusters[[i]])), 0) testthat::expect_true(all(ret$clusters[[i]] %in% 1:11)) testthat::expect_equal(length(ret$clusters[[i]]), length(unique(ret$clusters[[i]]))) testthat::expect_true(all(ret$clusters[[i]] == true_list[[i]])) clust_feats &lt;- c(clust_feats, ret$clusters[[i]]) } testthat::expect_equal(length(clust_feats), 11) testthat::expect_equal(11, length(unique(clust_feats))) testthat::expect_equal(11, length(intersect(clust_feats, 1:11))) # prototypes testthat::expect_true(is.integer(ret$prototypes)) testthat::expect_true(all(ret$prototypes %in% 1:11)) testthat::expect_equal(length(ret$prototypes), 5) testthat::expect_true(ret$prototypes[1] %in% 1:4) testthat::expect_true(ret$prototypes[2] %in% 5:8) testthat::expect_equal(ret$prototypes[3], 9) testthat::expect_equal(ret$prototypes[4], 10) testthat::expect_equal(ret$prototypes[5], 11) # var_names testthat::expect_equal(length(ret$var_names), 1) testthat::expect_true(is.na(ret$var_names)) # X as a data.frame X_df &lt;- datasets::mtcars res &lt;- processClusterLassoInputs(X=X_df, y=stats::rnorm(nrow(X_df)), clusters=1:3, nlambda=10) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;x&quot;, &quot;clusters&quot;, &quot;prototypes&quot;, &quot;var_names&quot;)) X_df_model &lt;- stats::model.matrix(~ ., X_df) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] # X testthat::expect_true(is.matrix(res$x)) testthat::expect_true(all(!is.na(res$x))) testthat::expect_true(is.numeric(res$x)) testthat::expect_equal(ncol(res$x), ncol(X_df_model)) testthat::expect_equal(nrow(res$x), nrow(X_df)) testthat::expect_true(all(abs(res$x - X_df_model) &lt; 10^(-9))) # var_names testthat::expect_equal(length(res$var_names), ncol(X_df_model)) testthat::expect_true(is.character(res$var_names)) testthat::expect_identical(res$var_names, colnames(X_df_model)) # X as a dataframe with factors (number of columns of final design matrix # after one-hot encoding factors won&#39;t match number of columns of df2) # cyl, gear, and carb are factors with more than 2 levels df2 &lt;- X_df df2$cyl &lt;- as.factor(df2$cyl) df2$vs &lt;- as.factor(df2$vs) df2$am &lt;- as.factor(df2$am) df2$gear &lt;- as.factor(df2$gear) df2$carb &lt;- as.factor(df2$carb) # Should get error if I try to use clusters because df2 contains factors with # more than two levels testthat::expect_error(processClusterLassoInputs(X=df2, y=stats::rnorm(nrow(df2)), clusters=1:3, nlambda=10), &quot;When stats::model.matrix converted the provided data.frame X to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert X to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;, fixed=TRUE) # Should be fine with no clusters res &lt;- processClusterLassoInputs(X=df2, y=stats::rnorm(nrow(df2)), clusters=list(), nlambda=10) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;x&quot;, &quot;clusters&quot;, &quot;prototypes&quot;, &quot;var_names&quot;)) X_df_model &lt;- stats::model.matrix(~ ., df2) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] # X testthat::expect_true(is.matrix(res$x)) testthat::expect_true(all(!is.na(res$x))) testthat::expect_true(is.numeric(res$x)) testthat::expect_equal(ncol(res$x), ncol(X_df_model)) testthat::expect_equal(nrow(res$x), nrow(X_df)) testthat::expect_true(all(abs(res$x - X_df_model) &lt; 10^(-9))) # var_names testthat::expect_equal(length(res$var_names), ncol(X_df_model)) testthat::expect_true(is.character(res$var_names)) testthat::expect_identical(res$var_names, colnames(X_df_model)) # X as a matrix with column names x2 &lt;- x colnames(x2) &lt;- LETTERS[1:11] ret &lt;- processClusterLassoInputs(X=x2, y=y, clusters=good_clusters, nlambda=10) testthat::expect_true(is.list(ret)) testthat::expect_identical(names(ret), c(&quot;x&quot;, &quot;clusters&quot;, &quot;prototypes&quot;, &quot;var_names&quot;)) # X testthat::expect_true(is.matrix(ret$x)) testthat::expect_true(all(!is.na(ret$x))) testthat::expect_true(is.numeric(ret$x)) testthat::expect_equal(ncol(ret$x), 11) testthat::expect_equal(nrow(ret$x), 15) testthat::expect_true(all(abs(ret$x - x) &lt; 10^(-9))) # var_names testthat::expect_equal(length(ret$var_names), ncol(x2)) testthat::expect_true(is.character(ret$var_names)) testthat::expect_identical(ret$var_names, LETTERS[1:11]) # Bad inputs testthat::expect_error(processClusterLassoInputs(X=&quot;x&quot;, y=y[1:10], clusters=good_clusters, nlambda=10), &quot;is.matrix(X) | is.data.frame(X) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(processClusterLassoInputs(X=x, y=y[1:10], clusters=good_clusters, nlambda=10), &quot;n == length(y) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(processClusterLassoInputs(X=x, y=y, clusters=list(1:4, 4:6), nlambda=10), &quot;Overlapping clusters detected; clusters must be non-overlapping. Overlapping clusters: 1, 2.&quot;, fixed=TRUE) testthat::expect_error(processClusterLassoInputs(X=x, y=y, clusters=list(2:3, 2:3), nlambda=10), &quot;length(clusters) == length(unique(clusters)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(processClusterLassoInputs(X=x, y=y, clusters=list(1:4, as.integer(NA)), nlambda=10), &quot;!is.na(clusters) are not all TRUE&quot;, fixed=TRUE) testthat::expect_error(processClusterLassoInputs(X=x, y=y, clusters=list(2:3, c(4, 4, 5)), nlambda=10), &quot;length(clusters[[i]]) == length(unique(clusters[[i]])) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(processClusterLassoInputs(X=x, y=y, clusters=good_clusters, nlambda=1), &quot;nlambda &gt;= 2 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(processClusterLassoInputs(X=x, y=y, clusters=good_clusters, nlambda=x), &quot;length(nlambda) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(processClusterLassoInputs(X=x, y=y, clusters=good_clusters, nlambda=&quot;nlambda&quot;), &quot;is.numeric(nlambda) | is.integer(nlambda) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(processClusterLassoInputs(X=x, y=y, clusters=good_clusters, nlambda=10.5), &quot;nlambda == round(nlambda) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🥇 getXglmnet(): #&#39; Converts the provided design matrix to an appropriate format for either the #&#39; protolasso or the cluster representative lasso. #&#39; #&#39; Creates design matrix for glmnet by dealing with clusters (for #&#39; type=&quot;protolasso&quot;, discards all cluster members except prototype; for #&#39; type=&quot;clusterRepLasso&quot;, replaces all cluster members with a simple #&#39; average of all the cluster members). #&#39; @param x A numeric matrix; the provided matrix with n observations and p #&#39; features. #&#39; @param clusters A named list where each entry is an integer vector of indices #&#39; of features that are in a common cluster. (The length of list clusters should #&#39; be equal to the number of clusters.) All identified clusters should be #&#39; non-overlapping. All features should appear in exactly one cluster (any #&#39; unclustered features should be put in their own &quot;cluster&quot; of size 1). #&#39; @param type Character; &quot;protolasso&quot; for the protolasso or &quot;clusterRepLasso&quot; #&#39; for the cluster representative lasso. #&#39; @param prototypes Only required for type &quot;protolasso&quot;. An integer vector #&#39; whose length is equal to the number of clusters. Entry i should be the #&#39; prototype for cluster i (the feature belonging to cluster i that is most #&#39; highly correlated with y; see Reid and Tibshirani 2016). #&#39; @return A numeric matrix; the design matrix as required for the protolasso or #&#39; cluster representative lasso, prepared for input to glmnet. #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references Reid, S., &amp; Tibshirani, R. (2016). Sparse regression and marginal #&#39; testing using cluster prototypes. \\emph{Biostatistics}, 17(2), 364–376. #&#39; \\url{https://doi.org/10.1093/biostatistics/kxv049}. getXglmnet &lt;- function(x, clusters, type, prototypes=NA){ # Check inputs checkGetXglmnetInputs(x, clusters, type, prototypes) n &lt;- nrow(x) p &lt;- ncol(x) for(i in 1:length(clusters)){ cluster_i &lt;- clusters[[i]] if(length(cluster_i) == 1){ X_glmnet_i &lt;- x[, cluster_i] } else{ stopifnot(length(cluster_i) &gt; 1) if(type == &quot;protolasso&quot;){ prototype_ind_i &lt;- which(prototypes %in% cluster_i) stopifnot(length(prototype_ind_i) == 1) prototype_i &lt;- prototypes[prototype_ind_i] X_glmnet_i &lt;- x[, prototype_i] } else { stopifnot(type == &quot;clusterRepLasso&quot;) X_glmnet_i &lt;- rowMeans(x[, cluster_i]) } } stopifnot(length(X_glmnet_i) == n) if(i == 1){ X_glmnet &lt;- as.matrix(X_glmnet_i) } else{ X_glmnet &lt;- cbind(X_glmnet, X_glmnet_i) } } stopifnot(ncol(X_glmnet) == length(clusters)) stopifnot(ncol(X_glmnet) == length(clusters)) colnames(X_glmnet) &lt;- character() # Check output stopifnot(is.matrix(X_glmnet)) stopifnot(nrow(X_glmnet) == n) stopifnot(ncol(X_glmnet) &lt;= p) stopifnot(ncol(X_glmnet) &gt;= 1) return(X_glmnet) } checkGetXglmnetInputs(): #&#39; Verifies the inputs for getXglmnet. #&#39; #&#39; @param x A numeric matrix; the provided matrix with n observations and p #&#39; features. #&#39; @param clusters A named list where each entry is an integer vector of indices #&#39; of features that are in a common cluster. (The length of list clusters should #&#39; be equal to the number of clusters.) All identified clusters should be #&#39; non-overlapping. All features should appear in exactly one cluster (any #&#39; unclustered features should be put in their own &quot;cluster&quot; of size 1). #&#39; @param type Character; &quot;protolasso&quot; for the protolasso or &quot;clusterRepLasso&quot; #&#39; for the cluster representative lasso. #&#39; @param prototypes Only required for type &quot;protolasso&quot;. An integer vector #&#39; whose length is equal to the number of clusters. Entry i should be the #&#39; prototype for cluster i (the feature belonging to cluster i that is most #&#39; highly correlated with y; see Reid and Tibshirani 2016). #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references Reid, S., &amp; Tibshirani, R. (2016). Sparse regression and marginal #&#39; testing using cluster prototypes. \\emph{Biostatistics}, 17(2), 364–376. #&#39; \\url{https://doi.org/10.1093/biostatistics/kxv049}. checkGetXglmnetInputs &lt;- function(x, clusters, type, prototypes){ stopifnot(is.matrix(x)) stopifnot(is.list(clusters)) stopifnot(all(lengths(clusters) &gt;= 1)) stopifnot(length(type) == 1) stopifnot(is.character(type)) stopifnot(!is.na(type)) stopifnot(type %in% c(&quot;protolasso&quot;, &quot;clusterRepLasso&quot;)) stopifnot(!is.na(prototypes)) stopifnot(is.integer(prototypes)) stopifnot(all(!is.na(prototypes))) stopifnot(length(prototypes) == length(unique(prototypes))) stopifnot(all(prototypes %in% 1:ncol(x))) for(i in 1:length(clusters)){ cluster_i &lt;- clusters[[i]] stopifnot(sum(prototypes %in% cluster_i) == 1) } } Tests for checkGetXglmnetInputs(): testthat::test_that(&quot;checkGetXglmnetInputs works&quot;, { set.seed(82612) x &lt;- matrix(stats::rnorm(15*11), nrow=15, ncol=11) y &lt;- stats::rnorm(15) good_clusters &lt;- list(red_cluster=1L:4L, green_cluster=5L:8L) process &lt;- processClusterLassoInputs(X=x, y=y, clusters=good_clusters, nlambda=10) checkGetXglmnetInputs(x=process$x, clusters=process$clusters, type=&quot;protolasso&quot;, prototypes=process$prototypes) checkGetXglmnetInputs(x=process$x, clusters=process$clusters, type=&quot;clusterRepLasso&quot;, prototypes=process$prototypes) # X as a data.frame X_df &lt;- datasets::mtcars res &lt;- processClusterLassoInputs(X=X_df, y=stats::rnorm(nrow(X_df)), clusters=1:3, nlambda=10) checkGetXglmnetInputs(x=res$x, clusters=res$clusters, type=&quot;clusterRepLasso&quot;, prototypes=res$prototypes) # X as a dataframe with factors (number of columns of final design matrix # after one-hot encoding factors won&#39;t match number of columns of df2) # cyl, gear, and carb are factors with more than 2 levels df2 &lt;- X_df df2$cyl &lt;- as.factor(df2$cyl) df2$vs &lt;- as.factor(df2$vs) df2$am &lt;- as.factor(df2$am) df2$gear &lt;- as.factor(df2$gear) df2$carb &lt;- as.factor(df2$carb) # Should get an error if clusters are provided since df2 contains factors # with more than two levels testthat::expect_error(processClusterLassoInputs(X=df2, y=stats::rnorm(nrow(df2)), clusters=1:3, nlambda=10), &quot;When stats::model.matrix converted the provided data.frame X to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert X to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;, fixed=TRUE) # Should be fine if no clusters are provided res &lt;- processClusterLassoInputs(X=df2, y=stats::rnorm(nrow(df2)), clusters=list(), nlambda=10) checkGetXglmnetInputs(x=res$x, clusters=res$clusters, type=&quot;protolasso&quot;, prototypes=res$prototypes) # X as a matrix with column names x2 &lt;- x colnames(x2) &lt;- LETTERS[1:11] ret &lt;- processClusterLassoInputs(X=x2, y=y, clusters=good_clusters, nlambda=10) checkGetXglmnetInputs(x=ret$x, clusters=ret$clusters, type=&quot;clusterRepLasso&quot;, prototypes=ret$prototypes) # Bad prototype inputs # Error has quotation marks testthat::expect_error(checkGetXglmnetInputs(x=process$x, clusters=process$clusters, type=&quot;clsterRepLasso&quot;, prototypes=process$prototypes)) testthat::expect_error(checkGetXglmnetInputs(x=process$x, clusters=process$clusters, type=c(&quot;clusterRepLasso&quot;, &quot;protolasso&quot;), prototypes=process$prototypes), &quot;length(type) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetXglmnetInputs(x=process$x, clusters=process$clusters, type=2, prototypes=process$prototypes), &quot;is.character(type) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(checkGetXglmnetInputs(x=process$x, clusters=process$clusters, type=as.character(NA), prototypes=process$prototypes), &quot;!is.na(type) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🥇 Tests for getXglmnet(): testthat::test_that(&quot;getXglmnet works&quot;, { set.seed(82612) x &lt;- matrix(stats::rnorm(15*11), nrow=15, ncol=11) y &lt;- stats::rnorm(15) good_clusters &lt;- list(red_cluster=1L:4L, green_cluster=5L:8L) process &lt;- processClusterLassoInputs(X=x, y=y, clusters=good_clusters, nlambda=10) res &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;protolasso&quot;, prototypes=process$prototypes) testthat::expect_true(is.matrix(res)) testthat::expect_true(is.numeric(res)) testthat::expect_true(is.null(colnames(res))) testthat::expect_true(nrow(res) == 15) # Each column of res should be one of the prototypes. Features 9 - 11 are # in clusters by themselves and are therefore their own prototypes. testthat::expect_true(ncol(res) == 5) for(i in 1:length(good_clusters)){ proto_i_found &lt;- FALSE cluster_i &lt;- good_clusters[[i]] for(j in 1:length(cluster_i)){ proto_i_found &lt;- proto_i_found | all(abs(res[, i] - x[, cluster_i[j]]) &lt; 10^(-9)) } testthat::expect_true(proto_i_found) } testthat::expect_true(all(abs(res[, 3] - x[, 9]) &lt; 10^(-9))) testthat::expect_true(all(abs(res[, 4] - x[, 10]) &lt; 10^(-9))) testthat::expect_true(all(abs(res[, 5] - x[, 11]) &lt; 10^(-9))) res &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;clusterRepLasso&quot;, prototypes=process$prototypes) testthat::expect_true(is.matrix(res)) testthat::expect_true(is.numeric(res)) testthat::expect_true(is.null(colnames(res))) testthat::expect_true(nrow(res) == 15) # Each column of res should be one of the cluster representatives. Features 9 # - 11 are in clusters by themselves and are therefore their own cluster # representatives. testthat::expect_true(ncol(res) == 5) for(i in 1:length(good_clusters)){ cluster_i &lt;- good_clusters[[i]] clus_rep_i &lt;- rowMeans(x[, cluster_i]) testthat::expect_true(all(abs(res[, i] - clus_rep_i) &lt; 10^(-9))) } testthat::expect_true(all(abs(res[, 3] - x[, 9]) &lt; 10^(-9))) testthat::expect_true(all(abs(res[, 4] - x[, 10]) &lt; 10^(-9))) testthat::expect_true(all(abs(res[, 5] - x[, 11]) &lt; 10^(-9))) # X as a data.frame X_df &lt;- datasets::mtcars res &lt;- processClusterLassoInputs(X=X_df, y=stats::rnorm(nrow(X_df)), clusters=1:3, nlambda=10) ret_df &lt;- getXglmnet(x=res$x, clusters=res$clusters, type=&quot;protolasso&quot;, prototypes=res$prototypes) X_df_model &lt;- stats::model.matrix(~ ., X_df) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] testthat::expect_true(is.matrix(ret_df)) testthat::expect_true(is.numeric(ret_df)) testthat::expect_true(is.null(colnames(ret_df))) testthat::expect_true(nrow(ret_df) == nrow(X_df)) # Each column of ret_df should be one of the prototypes. testthat::expect_true(ncol(ret_df) == ncol(X_df_model) - 3 + 1) proto_found &lt;- FALSE for(j in 1:3){ proto_found &lt;- proto_found | all(abs(ret_df[, 1] - X_df_model[, j]) &lt; 10^(-9)) } testthat::expect_true(proto_found) for(j in 4:ncol(X_df_model)){ testthat::expect_true(all(abs(ret_df[, j - 2] - X_df_model[, j]) &lt; 10^(-9))) } ret_df &lt;- getXglmnet(x=res$x, clusters=res$clusters, type=&quot;clusterRepLasso&quot;, prototypes=res$prototypes) testthat::expect_true(is.matrix(ret_df)) testthat::expect_true(is.numeric(ret_df)) testthat::expect_true(is.null(colnames(ret_df))) testthat::expect_true(nrow(ret_df) == nrow(X_df)) # Each column of ret_df should be one of the prototypes. testthat::expect_true(ncol(ret_df) == ncol(X_df_model) - 3 + 1) proto_found &lt;- FALSE clus_rep &lt;- rowMeans(X_df_model[, 1:3]) testthat::expect_true(all(abs(ret_df[, 1] - clus_rep) &lt; 10^(-9))) for(j in 4:ncol(X_df_model)){ testthat::expect_true(all(abs(ret_df[, j - 2] - X_df_model[, j]) &lt; 10^(-9))) } # X as a dataframe with factors (number of columns of final design matrix # after one-hot encoding factors won&#39;t match number of columns of df2) # cyl, gear, and carb are factors with more than 2 levels df2 &lt;- X_df df2$cyl &lt;- as.factor(df2$cyl) df2$vs &lt;- as.factor(df2$vs) df2$am &lt;- as.factor(df2$am) df2$gear &lt;- as.factor(df2$gear) df2$carb &lt;- as.factor(df2$carb) res &lt;- processClusterLassoInputs(X=df2, y=stats::rnorm(nrow(df2)), clusters=list(), nlambda=10) ret_df &lt;- getXglmnet(x=res$x, clusters=res$clusters, type=&quot;protolasso&quot;, prototypes=res$prototypes) X_df_model &lt;- stats::model.matrix(~ ., df2) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] testthat::expect_true(is.matrix(ret_df)) testthat::expect_true(is.numeric(ret_df)) testthat::expect_true(is.null(colnames(ret_df))) testthat::expect_true(nrow(ret_df) == nrow(X_df)) # Each column of ret_df should be one of the prototypes. testthat::expect_true(ncol(ret_df) == ncol(X_df_model)) for(j in 1:ncol(X_df_model)){ testthat::expect_true(all(abs(ret_df[, j] - X_df_model[, j]) &lt; 10^(-9))) } ret_df &lt;- getXglmnet(x=res$x, clusters=res$clusters, type=&quot;clusterRepLasso&quot;, prototypes=res$prototypes) testthat::expect_true(is.matrix(ret_df)) testthat::expect_true(is.numeric(ret_df)) testthat::expect_true(is.null(colnames(ret_df))) testthat::expect_true(nrow(ret_df) == nrow(X_df)) # Each column of ret_df should be one of the prototypes. testthat::expect_true(ncol(ret_df) == ncol(X_df_model)) for(j in 1:ncol(X_df_model)){ testthat::expect_true(all(abs(ret_df[, j] - X_df_model[, j]) &lt; 10^(-9))) } # X as a matrix with column names (returned X shouldn&#39;t have column names) x2 &lt;- x colnames(x2) &lt;- LETTERS[1:11] process &lt;- processClusterLassoInputs(X=x2, y=y, clusters=good_clusters, nlambda=10) res &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;protolasso&quot;, prototypes=process$prototypes) testthat::expect_true(is.matrix(res)) testthat::expect_true(is.numeric(res)) testthat::expect_true(is.null(colnames(res))) testthat::expect_true(nrow(res) == 15) # Each column of res should be one of the prototypes. Features 9 - 11 are # in clusters by themselves and are therefore their own prototypes. testthat::expect_true(ncol(res) == 5) for(i in 1:length(good_clusters)){ proto_i_found &lt;- FALSE cluster_i &lt;- good_clusters[[i]] for(j in 1:length(cluster_i)){ proto_i_found &lt;- proto_i_found | all(abs(res[, i] - x[, cluster_i[j]]) &lt; 10^(-9)) } testthat::expect_true(proto_i_found) } testthat::expect_true(all(abs(res[, 3] - x[, 9]) &lt; 10^(-9))) testthat::expect_true(all(abs(res[, 4] - x[, 10]) &lt; 10^(-9))) testthat::expect_true(all(abs(res[, 5] - x[, 11]) &lt; 10^(-9))) res &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;clusterRepLasso&quot;, prototypes=process$prototypes) testthat::expect_true(is.matrix(res)) testthat::expect_true(is.numeric(res)) testthat::expect_true(is.null(colnames(res))) testthat::expect_true(nrow(res) == 15) # Each column of res should be one of the cluster representatives. Features 9 # - 11 are in clusters by themselves and are therefore their own cluster # representatives. testthat::expect_true(ncol(res) == 5) for(i in 1:length(good_clusters)){ cluster_i &lt;- good_clusters[[i]] clus_rep_i &lt;- rowMeans(x[, cluster_i]) testthat::expect_true(all(abs(res[, i] - clus_rep_i) &lt; 10^(-9))) } testthat::expect_true(all(abs(res[, 3] - x[, 9]) &lt; 10^(-9))) testthat::expect_true(all(abs(res[, 4] - x[, 10]) &lt; 10^(-9))) testthat::expect_true(all(abs(res[, 5] - x[, 11]) &lt; 10^(-9))) # Bad prototype inputs # Error has quotation marks testthat::expect_error(getXglmnet(x=process$x, clusters=process$clusters, type=&quot;clsterRepLasso&quot;, prototypes=process$prototypes)) testthat::expect_error(getXglmnet(x=process$x, clusters=process$clusters, type=c(&quot;clusterRepLasso&quot;, &quot;protolasso&quot;), prototypes=process$prototypes), &quot;length(type) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getXglmnet(x=process$x, clusters=process$clusters, type=2, prototypes=process$prototypes), &quot;is.character(type) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(getXglmnet(x=process$x, clusters=process$clusters, type=as.character(NA), prototypes=process$prototypes), &quot;!is.na(type) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🥇 getClusterSelsFromGlmnet(): #&#39; Extracts selected clusters and cluster prototypes from the glmnet lasso #&#39; output #&#39; #&#39; @param lasso_sets A list of integer vectors. Each vector represents a set of #&#39; features selected by the lasso for a given value of the penalty parameter #&#39; lambda. #&#39; @param clusters A named list where each entry is an integer vector of indices #&#39; of features that are in a common cluster. (The length of list clusters is #&#39; equal to the number of clusters.) All identified clusters must be #&#39; non-overlapping. All features appear in exactly one cluster (any unclustered #&#39; features must be in their own &quot;cluster&quot; of size 1). #&#39; @param prototypes An integer vector whose length must be equal to the number #&#39; of clusters. Entry i should be the index of the feature belonging to cluster #&#39; i that is most highly correlated with y (that is, the prototype for the #&#39; cluster, as in the protolasso; see Reid and Tibshirani 2016). #&#39; @param feat_names Character vector; the names of the features in X. (If the #&#39; X provided to protolasso or clusterRepLasso did not have feature names, #&#39; feat_names will be NA.) #&#39; @return A list containing the following items: \\item{selected_sets}{A list of #&#39; integer vectors. Entry k of this list contains a selected set of size k #&#39; yielded by glmnet--each member of the set is the index of a single feature #&#39; from a cluster selected by either the protolasso or the cluster #&#39; representative lasso (the prototype from that cluster--the cluster member #&#39; most highly correlated with y). (If no set of size k was selected, entry k #&#39; will be NULL.)} \\item{selected_clusts_list}{A list of lists; entry k of this #&#39; list is a list of length k of clusters (the clusters that were selected by #&#39; the cluster representative lasso). Again, if no set of size k was selected, #&#39; entry k will be NULL.} #&#39; @author Gregory Faletto, Jacob Bien #&#39; @references Reid, S., &amp; Tibshirani, R. (2016). Sparse regression and marginal #&#39; testing using cluster prototypes. \\emph{Biostatistics}, 17(2), 364–376. #&#39; \\url{https://doi.org/10.1093/biostatistics/kxv049}. \\cr Bühlmann, P., #&#39; Rütimann, P., van de Geer, S., &amp; Zhang, C. H. (2013). Correlated variables in #&#39; regression: Clustering and sparse estimation. #&#39; \\emph{Journal of Statistical Planning and Inference}, 143(11), 1835–1858. #&#39; \\url{https://doi.org/10.1016/j.jspi.2013.05.019}. getClusterSelsFromGlmnet &lt;- function(lasso_sets, clusters, prototypes, feat_names){ if(any(!is.na(feat_names))){ stopifnot(all(!is.na(feat_names))) } # Largest selected set among all those in lasso_sets max_length &lt;- max(vapply(lasso_sets, length, integer(1))) # Preparing lists to store selected_sets &lt;- list() selected_clusts_list &lt;- list() for(j in 1:max_length){ # Lasso selected set of size j lasso_sets_j &lt;- lasso_sets[lapply(lasso_sets, length) == j] # Are there any lasso selected sets of size j? (If not, we will skip to # the next j, and slot j in the list will be empty.) if(length(lasso_sets_j) &gt; 0){ # Select the first set of size j lasso_set_j &lt;- lasso_sets_j[[1]] stopifnot(length(lasso_set_j) == j) ret &lt;- getSelectedSets(lasso_set=lasso_set_j, clusters=clusters, prototypes=prototypes, feat_names=feat_names) selected_sets[[j]] &lt;- ret$selected_set selected_clusts_list[[j]] &lt;- ret$selected_clusts_list rm(ret) } } stopifnot(length(selected_sets) &lt;= max_length) stopifnot(length(selected_clusts_list) &lt;= max_length) return(list(selected_sets=selected_sets, selected_clusts_list=selected_clusts_list)) } getSelectedSets(): #&#39; Converts a selected set from X_glmnet to selected sets and selected clusters #&#39; from the original feature space of X. #&#39; #&#39; @param lasso_set A vector containing the indices of selected cluster #&#39; representatives or prototypes. #&#39; @param clusters A named list where each entry is an integer vector of indices #&#39; of features that are in a common cluster. (The length of list clusters is #&#39; equal to the number of clusters.) All identified clusters must be #&#39; non-overlapping. All features appear in exactly one cluster (any unclustered #&#39; features must be in their own &quot;cluster&quot; of size 1). #&#39; @param prototypes An integer vector whose length must be equal to the number #&#39; of clusters. Entry i should be the index of the feature belonging to cluster #&#39; i that is most highly correlated with y (that is, the prototype for the #&#39; cluster, as in the protolasso). #&#39; @param feat_names Character vector; the names of the features in X. #&#39; @return A list containing two items: \\item{selected_set}{An integer vector #&#39; with length equal to lasso_set containing a set of selected features in the #&#39; original X matrix. (Selections in lasso_set corresponding to a cluster will #&#39; be replaced by the cluster&#39;s prototype from X.)} #&#39; \\item{selected_clusts_list}{A named list of integer vectors with length equal #&#39; to selected_set. selected_clusts_list[[k]] will be an integer vector #&#39; containing the indices of the features in X that are in the cluster #&#39; containing prototype selected_set[k].} #&#39; @author Gregory Faletto, Jacob Bien getSelectedSets &lt;- function(lasso_set, clusters, prototypes, feat_names){ model_size &lt;- length(lasso_set) stopifnot(model_size &gt; 0) stopifnot(length(unique(lasso_set)) == model_size) stopifnot(all(lasso_set &lt;= length(clusters))) selected_set &lt;- integer() selected_clusts_list &lt;- list() # Recover features from original feature space for(k in 1:model_size){ selected_cluster_k &lt;- clusters[[lasso_set[k]]] stopifnot(is.integer(selected_cluster_k)) selected_clusts_list[[k]] &lt;- selected_cluster_k if(length(selected_cluster_k) == 1){ stopifnot(!(selected_cluster_k %in% selected_set)) selected_set &lt;- c(selected_set, selected_cluster_k) } else{ sel_prototype &lt;- which(prototypes %in% selected_cluster_k) stopifnot(length(sel_prototype) == 1) stopifnot(!(prototypes[sel_prototype] %in% selected_set)) selected_set &lt;- c(selected_set, prototypes[sel_prototype]) } } stopifnot(length(selected_set) == model_size) stopifnot(length(unique(selected_set)) == model_size) if(any(!is.na(feat_names))){ names(selected_set) &lt;- feat_names[selected_set] } stopifnot(length(selected_clusts_list) == model_size) all_feats &lt;- unlist(selected_clusts_list) stopifnot(length(all_feats) == length(unique(all_feats))) return(list(selected_set=selected_set, selected_clusts_list=selected_clusts_list)) } Tests for getSelectedSets(): testthat::test_that(&quot;getSelectedSets works&quot;, { set.seed(82612) x &lt;- matrix(stats::rnorm(15*11), nrow=15, ncol=11) y &lt;- stats::rnorm(15) good_clusters &lt;- list(red_cluster=1L:4L, green_cluster=5L:8L) process &lt;- processClusterLassoInputs(X=x, y=y, clusters=good_clusters, nlambda=100) X_glmnet &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;protolasso&quot;, prototypes=process$prototypes) fit &lt;- glmnet::glmnet(x=X_glmnet, y=y, family=&quot;gaussian&quot;, nlambda=100) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) # Pick an arbitrary lasso set lasso_set &lt;- lasso_sets[[5]] res &lt;- getSelectedSets(lasso_set, process$clusters, process$prototypes, process$var_names) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_set&quot;, &quot;selected_clusts_list&quot;)) # selected_set testthat::expect_true(is.integer(res$selected_set)) testthat::expect_true(all(!is.na(res$selected_set))) testthat::expect_true(all(res$selected_set %in% process$prototypes)) # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) testthat::expect_equal(length(res$selected_set), length(res$selected_clusts_list)) sel_feats &lt;- unlist(res$selected_clusts_list) testthat::expect_true(all(sel_feats %in% 1:11)) n_clusts &lt;- length(res$selected_clusts_list) for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[i]] for(j in 1:length(process$clusters)){ clust_i_found &lt;- clust_i_found | identical(clust_i, process$clusters[[j]]) } testthat::expect_true(clust_i_found) } # Try again with cluster representative lasso X_glmnet &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;clusterRepLasso&quot;, prototypes=process$prototypes) fit &lt;- glmnet::glmnet(x=X_glmnet, y=y, family=&quot;gaussian&quot;, nlambda=100) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) # Pick an arbitrary lasso set lasso_set &lt;- lasso_sets[[5]] res &lt;- getSelectedSets(lasso_set, process$clusters, process$prototypes, process$var_names) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_set&quot;, &quot;selected_clusts_list&quot;)) # selected_set testthat::expect_true(is.integer(res$selected_set)) testthat::expect_true(all(!is.na(res$selected_set))) testthat::expect_true(all(res$selected_set %in% process$prototypes)) # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) testthat::expect_equal(length(res$selected_set), length(res$selected_clusts_list)) sel_feats &lt;- unlist(res$selected_clusts_list) testthat::expect_true(all(sel_feats %in% 1:11)) n_clusts &lt;- length(res$selected_clusts_list) for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[i]] for(j in 1:length(process$clusters)){ clust_i_found &lt;- clust_i_found | identical(clust_i, process$clusters[[j]]) } testthat::expect_true(clust_i_found) } # X as a data.frame X_df &lt;- datasets::mtcars X_df_model &lt;- stats::model.matrix(~ ., X_df) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] process &lt;- processClusterLassoInputs(X=X_df, y=rnorm(nrow(X_df)), clusters=1:3, nlambda=100) X_glmnet &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;protolasso&quot;, prototypes=process$prototypes) fit &lt;- glmnet::glmnet(x=X_glmnet, y=rnorm(nrow(X_df)), family=&quot;gaussian&quot;, nlambda=100) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) # Pick an arbitrary lasso set lasso_set &lt;- lasso_sets[[min(length(lasso_sets), 3)]] res &lt;- getSelectedSets(lasso_set, process$clusters, process$prototypes, process$var_names) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_set&quot;, &quot;selected_clusts_list&quot;)) # selected_set testthat::expect_true(is.integer(res$selected_set)) testthat::expect_true(all(!is.na(res$selected_set))) testthat::expect_true(all(res$selected_set %in% process$prototypes)) # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) testthat::expect_equal(length(res$selected_set), length(res$selected_clusts_list)) sel_feats &lt;- unlist(res$selected_clusts_list) testthat::expect_true(all(sel_feats %in% 1:ncol(X_df_model))) n_clusts &lt;- length(res$selected_clusts_list) for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[i]] for(j in 1:length(process$clusters)){ clust_i_found &lt;- clust_i_found | identical(clust_i, process$clusters[[j]]) } testthat::expect_true(clust_i_found) } # X as a dataframe with factors (number of columns of final design matrix # after one-hot encoding factors won&#39;t match number of columns of df2) # cyl, gear, and carb are factors with more than 2 levels df2 &lt;- X_df df2$cyl &lt;- as.factor(df2$cyl) df2$vs &lt;- as.factor(df2$vs) df2$am &lt;- as.factor(df2$am) df2$gear &lt;- as.factor(df2$gear) df2$carb &lt;- as.factor(df2$carb) X_df_model &lt;- stats::model.matrix(~ ., df2) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] # Should throw an error if we assign clusters because df2 contains factors # with more than two levels testthat::expect_error(processClusterLassoInputs(X=df2, y=rnorm(nrow(df2)), clusters=1:3, nlambda=100), &quot;When stats::model.matrix converted the provided data.frame X to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert X to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;, fixed=TRUE) # Should be fine if no clusters are provided process &lt;- processClusterLassoInputs(X=df2, y=rnorm(nrow(df2)), clusters=list(), nlambda=100) X_glmnet &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;clusterRepLasso&quot;, prototypes=process$prototypes) fit &lt;- glmnet::glmnet(x=X_glmnet, y=rnorm(nrow(df2)), family=&quot;gaussian&quot;, nlambda=100) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) # Pick an arbitrary lasso set lasso_set &lt;- lasso_sets[[min(length(lasso_sets), 3)]] res &lt;- getSelectedSets(lasso_set, process$clusters, process$prototypes, process$var_names) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_set&quot;, &quot;selected_clusts_list&quot;)) # selected_set testthat::expect_true(is.integer(res$selected_set)) testthat::expect_true(all(!is.na(res$selected_set))) testthat::expect_true(all(res$selected_set %in% process$prototypes)) # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) testthat::expect_equal(length(res$selected_set), length(res$selected_clusts_list)) sel_feats &lt;- unlist(res$selected_clusts_list) testthat::expect_true(all(sel_feats %in% 1:ncol(X_df_model))) n_clusts &lt;- length(res$selected_clusts_list) for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[i]] for(j in 1:length(process$clusters)){ clust_i_found &lt;- clust_i_found | identical(clust_i, process$clusters[[j]]) } testthat::expect_true(clust_i_found) } # X as a dataframe with factors (number of columns of final design matrix # after one-hot encoding factors won&#39;t match number of columns of df2) # cyl, gear, and carb are factors with more than 2 levels df2 &lt;- X_df df2$cyl &lt;- as.factor(df2$cyl) df2$vs &lt;- as.factor(df2$vs) df2$am &lt;- as.factor(df2$am) df2$gear &lt;- as.factor(df2$gear) df2$carb &lt;- as.factor(df2$carb) X_df_model &lt;- stats::model.matrix(~ ., df2) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] # Should throw an error if we assign clusters because df2 contains factors # with more than two levels testthat::expect_error(processClusterLassoInputs(X=df2, y=rnorm(nrow(df2)), clusters=1:3, nlambda=100), &quot;When stats::model.matrix converted the provided data.frame X to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert X to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;, fixed=TRUE) # Should be fine if no clusters are provided process &lt;- processClusterLassoInputs(X=df2, y=rnorm(nrow(df2)), clusters=list(), nlambda=100) X_glmnet &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;clusterRepLasso&quot;, prototypes=process$prototypes) fit &lt;- glmnet::glmnet(x=X_glmnet, y=rnorm(nrow(df2)), family=&quot;gaussian&quot;, nlambda=100) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) # Pick an arbitrary lasso set lasso_set &lt;- lasso_sets[[min(length(lasso_sets), 3)]] res &lt;- getSelectedSets(lasso_set, process$clusters, process$prototypes, process$var_names) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_set&quot;, &quot;selected_clusts_list&quot;)) # selected_set testthat::expect_true(is.integer(res$selected_set)) testthat::expect_true(all(!is.na(res$selected_set))) testthat::expect_true(all(res$selected_set %in% process$prototypes)) # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) testthat::expect_equal(length(res$selected_set), length(res$selected_clusts_list)) sel_feats &lt;- unlist(res$selected_clusts_list) testthat::expect_true(all(sel_feats %in% 1:ncol(X_df_model))) n_clusts &lt;- length(res$selected_clusts_list) for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[i]] for(j in 1:length(process$clusters)){ clust_i_found &lt;- clust_i_found | identical(clust_i, process$clusters[[j]]) } testthat::expect_true(clust_i_found) } # X as a matrix with column names x2 &lt;- x colnames(x2) &lt;- LETTERS[1:11] process &lt;- processClusterLassoInputs(X=x2, y=y, clusters=good_clusters, nlambda=100) X_glmnet &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;protolasso&quot;, prototypes=process$prototypes) fit &lt;- glmnet::glmnet(x=X_glmnet, y=y, family=&quot;gaussian&quot;, nlambda=100) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) # Pick an arbitrary lasso set lasso_set &lt;- lasso_sets[[min(length(lasso_sets), 3)]] res &lt;- getSelectedSets(lasso_set, process$clusters, process$prototypes, process$var_names) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_set&quot;, &quot;selected_clusts_list&quot;)) # selected_set testthat::expect_true(is.integer(res$selected_set)) testthat::expect_true(all(!is.na(res$selected_set))) testthat::expect_true(all(res$selected_set %in% process$prototypes)) # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) testthat::expect_equal(length(res$selected_set), length(res$selected_clusts_list)) sel_feats &lt;- unlist(res$selected_clusts_list) testthat::expect_true(all(sel_feats %in% 1:11)) n_clusts &lt;- length(res$selected_clusts_list) for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[i]] for(j in 1:length(process$clusters)){ clust_i_found &lt;- clust_i_found | identical(clust_i, process$clusters[[j]]) } testthat::expect_true(clust_i_found) } }) ## Test passed 😸 Tests for getClusterSelsFromGlmnet(): testthat::test_that(&quot;getClusterSelsFromGlmnet works&quot;, { set.seed(61282) x &lt;- matrix(stats::rnorm(15*11), nrow=15, ncol=11) y &lt;- stats::rnorm(15) good_clusters &lt;- list(red_cluster=1L:4L, green_cluster=5L:8L) process &lt;- processClusterLassoInputs(X=x, y=y, clusters=good_clusters, nlambda=100) X_glmnet &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;protolasso&quot;, prototypes=process$prototypes) fit &lt;- glmnet::glmnet(x=X_glmnet, y=y, family=&quot;gaussian&quot;, nlambda=100) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) res &lt;- getClusterSelsFromGlmnet(lasso_sets, process$clusters, process$prototypes, process$var_names) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% process$prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:11)) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(process$clusters)){ clust_i_found &lt;- clust_i_found | identical(clust_i, process$clusters[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } # Try again with cluster representative lasso X_glmnet &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;clusterRepLasso&quot;, prototypes=process$prototypes) fit &lt;- glmnet::glmnet(x=X_glmnet, y=y, family=&quot;gaussian&quot;, nlambda=100) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) res &lt;- getClusterSelsFromGlmnet(lasso_sets, process$clusters, process$prototypes, process$var_names) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% process$prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:11)) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(process$clusters)){ clust_i_found &lt;- clust_i_found | identical(clust_i, process$clusters[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } # X as a data.frame X_df &lt;- datasets::mtcars X_df_model &lt;- stats::model.matrix(~ ., X_df) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] process &lt;- processClusterLassoInputs(X=X_df, y=rnorm(nrow(X_df)), clusters=1:3, nlambda=100) X_glmnet &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;protolasso&quot;, prototypes=process$prototypes) fit &lt;- glmnet::glmnet(x=X_glmnet, y=rnorm(nrow(X_df)), family=&quot;gaussian&quot;, nlambda=100) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) res &lt;- getClusterSelsFromGlmnet(lasso_sets, process$clusters, process$prototypes, process$var_names) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% process$prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:ncol(X_df_model))) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(process$clusters)){ clust_i_found &lt;- clust_i_found | identical(clust_i, process$clusters[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } # X as a dataframe with factors (number of columns of final design matrix # after one-hot encoding factors won&#39;t match number of columns of df2) # cyl, gear, and carb are factors with more than 2 levels df2 &lt;- X_df df2$cyl &lt;- as.factor(df2$cyl) df2$vs &lt;- as.factor(df2$vs) df2$am &lt;- as.factor(df2$am) df2$gear &lt;- as.factor(df2$gear) df2$carb &lt;- as.factor(df2$carb) X_df_model &lt;- stats::model.matrix(~ ., df2) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] process &lt;- processClusterLassoInputs(X=df2, y=rnorm(nrow(df2)), clusters=list(), nlambda=100) X_glmnet &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;clusterRepLasso&quot;, prototypes=process$prototypes) fit &lt;- glmnet::glmnet(x=X_glmnet, y=rnorm(nrow(df2)), family=&quot;gaussian&quot;, nlambda=100) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) res &lt;- getClusterSelsFromGlmnet(lasso_sets, process$clusters, process$prototypes, process$var_names) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% process$prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:ncol(X_df_model))) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(process$clusters)){ clust_i_found &lt;- clust_i_found | identical(clust_i, process$clusters[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } # X as a matrix with column names x2 &lt;- x colnames(x2) &lt;- LETTERS[1:11] process &lt;- processClusterLassoInputs(X=x2, y=y, clusters=good_clusters, nlambda=100) X_glmnet &lt;- getXglmnet(x=process$x, clusters=process$clusters, type=&quot;protolasso&quot;, prototypes=process$prototypes) fit &lt;- glmnet::glmnet(x=X_glmnet, y=y, family=&quot;gaussian&quot;, nlambda=100) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) res &lt;- getClusterSelsFromGlmnet(lasso_sets, process$clusters, process$prototypes, process$var_names) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% process$prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:11)) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(process$clusters)){ clust_i_found &lt;- clust_i_found | identical(clust_i, process$clusters[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } }) ## Test passed 🥳 Finally, tests for protolasso(): testthat::test_that(&quot;protolasso works&quot;, { set.seed(61282) x &lt;- matrix(stats::rnorm(15*11), nrow=15, ncol=11) y &lt;- stats::rnorm(15) good_clusters &lt;- list(red_cluster=1L:4L, green_cluster=5L:8L) # Get properly formatted clusters and prototypes for testing format_clust_res &lt;- formatClusters(clusters=good_clusters, p=11, clust_names=names(good_clusters), get_prototypes=TRUE, x=x, y=y) prototypes &lt;- format_clust_res$prototypes clus_formatted &lt;- format_clust_res$clusters res &lt;- protolasso(x, y, good_clusters, nlambda=60) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;, &quot;beta&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) testthat::expect_true(is.null(names(res$selected_sets[[i]]))) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:11)) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(clus_formatted)){ clust_i_found &lt;- clust_i_found | identical(clust_i, clus_formatted[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } # beta testthat::expect_true(grepl(&quot;dgCMatrix&quot;, class(res$beta))) testthat::expect_true(nrow(res$beta) == 11 - 8 + 2) testthat::expect_true(ncol(res$beta) &lt;= 60) # X as a data.frame X_df &lt;- datasets::mtcars X_df_model &lt;- stats::model.matrix(~ ., X_df) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] y_df &lt;- rnorm(nrow(X_df)) # Get properly formatted clusters and prototypes for testing format_clust_res &lt;- formatClusters(clusters=1:3, p=ncol(X_df_model), get_prototypes=TRUE, x=X_df_model, y=y_df) prototypes &lt;- format_clust_res$prototypes clus_formatted &lt;- format_clust_res$clusters res &lt;- protolasso(X_df, y_df, 1:3, nlambda=80) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;, &quot;beta&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) testthat::expect_true(all(names(res$selected_sets[[i]]) %in% colnames(X_df_model))) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:ncol(X_df_model))) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(clus_formatted)){ clust_i_found &lt;- clust_i_found | identical(clust_i, clus_formatted[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } # beta testthat::expect_true(grepl(&quot;dgCMatrix&quot;, class(res$beta))) testthat::expect_true(nrow(res$beta) == ncol(X_df_model) - 3 + 1) testthat::expect_true(ncol(res$beta) &lt;= 80) # X as a dataframe with factors (number of columns of final design matrix # after one-hot encoding factors won&#39;t match number of columns of df2) # cyl, gear, and carb are factors with more than 2 levels df2 &lt;- X_df df2$cyl &lt;- as.factor(df2$cyl) df2$vs &lt;- as.factor(df2$vs) df2$am &lt;- as.factor(df2$am) df2$gear &lt;- as.factor(df2$gear) df2$carb &lt;- as.factor(df2$carb) X_df_model &lt;- stats::model.matrix(~ ., df2) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] # Should get an error if we try to call protolasso on df2 with clusters # because df2 contains factors with more than two levels testthat::expect_error(protolasso(df2, y_df, 4:6, nlambda=70), &quot;When stats::model.matrix converted the provided data.frame X to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert X to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;, fixed=TRUE) # Should be fine if no clusters are provided res &lt;- protolasso(df2, y_df, nlambda=70) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;, &quot;beta&quot;)) # Get properly formatted clusters and prototypes for testing format_clust_res &lt;- formatClusters(clusters=4:6, p=ncol(X_df_model), get_prototypes=TRUE, x=X_df_model, y=y_df) prototypes &lt;- format_clust_res$prototypes clus_formatted &lt;- format_clust_res$clusters res &lt;- protolasso(X_df_model, y_df, 4:6, nlambda=70) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;, &quot;beta&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) testthat::expect_true(all(names(res$selected_sets[[i]]) %in% colnames(X_df_model))) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:ncol(X_df_model))) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(clus_formatted)){ clust_i_found &lt;- clust_i_found | identical(clust_i, clus_formatted[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } # beta testthat::expect_true(grepl(&quot;dgCMatrix&quot;, class(res$beta))) testthat::expect_true(nrow(res$beta) == ncol(X_df_model) - 3 + 1) testthat::expect_true(ncol(res$beta) &lt;= 70) # X as a matrix with column names x2 &lt;- x colnames(x2) &lt;- LETTERS[1:11] # Get properly formatted clusters and prototypes for testing format_clust_res &lt;- formatClusters(clusters=good_clusters, p=11, clust_names=names(good_clusters), get_prototypes=TRUE, x=x2, y=y) prototypes &lt;- format_clust_res$prototypes clus_formatted &lt;- format_clust_res$clusters res &lt;- protolasso(x2, y, good_clusters, nlambda=50) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;, &quot;beta&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) testthat::expect_true(all(names(res$selected_sets[[i]]) %in% LETTERS[1:11])) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:11)) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(clus_formatted)){ clust_i_found &lt;- clust_i_found | identical(clust_i, clus_formatted[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } # beta testthat::expect_true(grepl(&quot;dgCMatrix&quot;, class(res$beta))) testthat::expect_true(nrow(res$beta) == 11 - 8 + 2) testthat::expect_true(ncol(res$beta) &lt;= 50) # Bad inputs testthat::expect_error(protolasso(X=&quot;x&quot;, y=y[1:10], clusters=good_clusters, nlambda=10), &quot;is.matrix(X) | is.data.frame(X) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(protolasso(X=x, y=y[1:10], clusters=good_clusters, nlambda=10), &quot;n == length(y) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(protolasso(X=x, y=y, clusters=list(1:4, 4:6), nlambda=10), &quot;Overlapping clusters detected; clusters must be non-overlapping. Overlapping clusters: 1, 2.&quot;, fixed=TRUE) testthat::expect_error(protolasso(X=x, y=y, clusters=list(2:3, 2:3), nlambda=10), &quot;length(clusters) == length(unique(clusters)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(protolasso(X=x, y=y, clusters=list(1:4, as.integer(NA)), nlambda=10), &quot;!is.na(clusters) are not all TRUE&quot;, fixed=TRUE) testthat::expect_error(protolasso(X=x, y=y, clusters=list(2:3, c(4, 4, 5)), nlambda=10), &quot;length(clusters[[i]]) == length(unique(clusters[[i]])) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(protolasso(X=x, y=y, clusters=good_clusters, nlambda=1), &quot;nlambda &gt;= 2 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(protolasso(X=x, y=y, clusters=good_clusters, nlambda=x), &quot;length(nlambda) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(protolasso(X=x, y=y, clusters=good_clusters, nlambda=&quot;nlambda&quot;), &quot;is.numeric(nlambda) | is.integer(nlambda) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(protolasso(X=x, y=y, clusters=good_clusters, nlambda=10.5), &quot;nlambda == round(nlambda) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🥇 clusterRepLasso(): #&#39; Select features via the cluster representative lasso (Bühlmann et. al. 2013) #&#39; #&#39; @param X An n x p numeric matrix (preferably) or a data.frame (which will #&#39; be coerced internally to a matrix by the function model.matrix) containing #&#39; p &gt;= 2 features/predictors #&#39; @param y The response; A length n numeric (or integer) real-valued vector. #&#39; @param clusters A list of integer vectors; each vector should contain the #&#39; indices of a cluster of features (a subset of 1:p). (If there is only one #&#39; cluster, clusters can either be a list of length 1 or an integer vector.) #&#39; All of the provided clusters must be non-overlapping. Every feature not #&#39; appearing in any cluster will be assumed to be unclustered (that is, they #&#39; will be treated as if they are in a &quot;cluster&quot; containing only themselves). #&#39; CAUTION: if the provided X is a data.frame that contains a categorical #&#39; feature with more than two levels, then the resulting matrix made from #&#39; model.matrix will have a different number of columns than the provided #&#39; data.frame, some of the feature numbers will change, and the clusters #&#39; argument will not work properly (in the current version of the package). #&#39; To get correct results in this case, please use model.matrix to convert #&#39; the data.frame to a numeric matrix on your own, then provide this matrix #&#39; and cluster assignments with respect to this matrix. Default is list() (so no #&#39; clusters are specified). #&#39; @param nlambda Integer; the number of lambda values to use in the lasso fit #&#39; for the cluster representative lasso. Default is 100 (following the default #&#39; for glmnet). For now, nlambda must be at least 2 (using a single lambda is #&#39; not supported). #&#39; @return A list with three elements. \\item{selected_sets}{A list of integer #&#39; vectors. Entry k of this list contains a selected set (an integer vector) of #&#39; size k yielded by the lasso--each member of the set is the index of a single #&#39; feature from a cluster selected by the cluster representative lasso (the #&#39; prototype from that cluster--the cluster member most highly correlated with #&#39; y). (If no set of size k was selected, entry k will be empty.)} #&#39; \\item{selected_clusts_list}{A list; each element of the list is a named list #&#39; of selected clusters. (That is, if a selected set of size k was yielded by #&#39; the cluster representative lasso, then selected_clusts_list[[k]] is a named #&#39; list of length k, where each member of the list is an integer vector #&#39; of cluster members. Note that selected_clusts_lists[[k]][[j]] will be the #&#39; cluster that contains feature selected_sets[[k]][j].)} \\item{beta}{The beta #&#39; output from glmnet when the lasso was estimated on a matrix of prototypes. #&#39; (See documentation for the function glmnet from the glmnet package for #&#39; details.)} #&#39; @references Bühlmann, P., Rütimann, P., van de Geer, S., &amp; Zhang, C. H. #&#39; (2013). Correlated variables in regression: Clustering and sparse estimation. #&#39; \\emph{Journal of Statistical Planning and Inference}, 143(11), 1835–1858. #&#39; \\url{https://doi.org/10.1016/j.jspi.2013.05.019}. \\cr Jerome Friedman, Trevor #&#39; Hastie, Robert Tibshirani (2010). Regularization Paths for Generalized Linear #&#39; Models via Coordinate Descent. \\emph{Journal of Statistical Software}, 33(1) #&#39; &#39; 1-22. URL \\url{https://www.jstatsoft.org/v33/i01/}. #&#39; @export clusterRepLasso &lt;- function(X, y, clusters=list(), nlambda=100){ # Handle and format inputs; get cluster prototypes ret &lt;- processClusterLassoInputs(X, y, clusters, nlambda) x &lt;- ret$x clusters &lt;- ret$clusters prototypes &lt;- ret$prototypes feat_names &lt;- ret$var_names rm(ret) # Format the design matrix for glmnet according to the cluster # representative lasso procedure X_glmnet &lt;- getXglmnet(x, clusters, type=&quot;clusterRepLasso&quot;, prototypes=prototypes) # Estimate the lasso on the cluster representatives fit &lt;- glmnet::glmnet(x=X_glmnet, y=y, family=&quot;gaussian&quot;, nlambda=nlambda) lasso_sets &lt;- unique(glmnet::predict.glmnet(fit, type=&quot;nonzero&quot;)) # Finally, extract the desired information from the lasso fit--all the # sets of selected clusters (one for each observed model size), and # corresponding sets of selected features cluster_sel_results &lt;- getClusterSelsFromGlmnet(lasso_sets, clusters, prototypes, feat_names) return(list(selected_sets=cluster_sel_results$selected_sets, selected_clusts_list=cluster_sel_results$selected_clusts_list, beta=fit$beta)) } Tests for clusterRepLasso(): # TODO(gregfaletto): deal with the fact that clusters argument doesn&#39;t work # for a data.frame input that has a categorical random variable with more than # two levels (because then p, and the numbering of the features, changes) testthat::test_that(&quot;clusterRepLasso works&quot;, { set.seed(61282) x &lt;- matrix(stats::rnorm(15*11), nrow=15, ncol=11) y &lt;- stats::rnorm(15) good_clusters &lt;- list(red_cluster=1L:4L, green_cluster=5L:8L) # Get properly formatted clusters and prototypes for testing format_clust_res &lt;- formatClusters(clusters=good_clusters, p=11, clust_names=names(good_clusters), get_prototypes=TRUE, x=x, y=y) prototypes &lt;- format_clust_res$prototypes clus_formatted &lt;- format_clust_res$clusters res &lt;- clusterRepLasso(x, y, good_clusters, nlambda=60) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;, &quot;beta&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) testthat::expect_true(is.null(names(res$selected_sets[[i]]))) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:11)) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(clus_formatted)){ clust_i_found &lt;- clust_i_found | identical(clust_i, clus_formatted[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } # beta testthat::expect_true(grepl(&quot;dgCMatrix&quot;, class(res$beta))) testthat::expect_true(nrow(res$beta) == 11 - 8 + 2) testthat::expect_true(ncol(res$beta) &lt;= 60) # X as a data.frame X_df &lt;- datasets::mtcars X_df_model &lt;- stats::model.matrix(~ ., X_df) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] y_df &lt;- rnorm(nrow(X_df)) # Get properly formatted clusters and prototypes for testing format_clust_res &lt;- formatClusters(clusters=1:3, p=ncol(X_df_model), get_prototypes=TRUE, x=X_df_model, y=y_df) prototypes &lt;- format_clust_res$prototypes clus_formatted &lt;- format_clust_res$clusters res &lt;- clusterRepLasso(X_df, y_df, 1:3, nlambda=80) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;, &quot;beta&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) testthat::expect_true(all(names(res$selected_sets[[i]]) %in% colnames(X_df_model))) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:ncol(X_df_model))) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(clus_formatted)){ clust_i_found &lt;- clust_i_found | identical(clust_i, clus_formatted[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } # beta testthat::expect_true(grepl(&quot;dgCMatrix&quot;, class(res$beta))) testthat::expect_true(nrow(res$beta) == ncol(X_df_model) - 3 + 1) testthat::expect_true(ncol(res$beta) &lt;= 80) # X as a dataframe with factors (number of columns of final design matrix # after one-hot encoding factors won&#39;t match number of columns of df2) # cyl, gear, and carb are factors with more than 2 levels df2 &lt;- X_df df2$cyl &lt;- as.factor(df2$cyl) df2$vs &lt;- as.factor(df2$vs) df2$am &lt;- as.factor(df2$am) df2$gear &lt;- as.factor(df2$gear) df2$carb &lt;- as.factor(df2$carb) # Should get an error if we try to call clusterRepLasso on df2 with clusters # because df2 contains factors with more than two levels testthat::expect_error(clusterRepLasso(df2, y_df, 4:6, nlambda=70), &quot;When stats::model.matrix converted the provided data.frame X to a matrix, the number of columns changed (probably because the provided data.frame contained a factor variable with at least three levels). Please convert X to a matrix yourself using model.matrix and provide cluster assignments according to the columns of the new matrix.&quot;, fixed=TRUE) # Should be fine if no clusters are provided res &lt;- clusterRepLasso(df2, y_df, nlambda=70) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;, &quot;beta&quot;)) X_df_model &lt;- stats::model.matrix(~ ., df2) X_df_model &lt;- X_df_model[, colnames(X_df_model) != &quot;(Intercept)&quot;] # Get properly formatted clusters and prototypes for testing format_clust_res &lt;- formatClusters(clusters=4:6, p=ncol(X_df_model), get_prototypes=TRUE, x=X_df_model, y=y_df) prototypes &lt;- format_clust_res$prototypes clus_formatted &lt;- format_clust_res$clusters res &lt;- clusterRepLasso(X_df_model, y_df, 4:6, nlambda=70) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;, &quot;beta&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) testthat::expect_true(all(names(res$selected_sets[[i]]) %in% colnames(X_df_model))) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:ncol(X_df_model))) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(clus_formatted)){ clust_i_found &lt;- clust_i_found | identical(clust_i, clus_formatted[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } # beta testthat::expect_true(grepl(&quot;dgCMatrix&quot;, class(res$beta))) testthat::expect_true(nrow(res$beta) == ncol(X_df_model) - 3 + 1) testthat::expect_true(ncol(res$beta) &lt;= 70) # X as a matrix with column names x2 &lt;- x colnames(x2) &lt;- LETTERS[1:11] # Get properly formatted clusters and prototypes for testing format_clust_res &lt;- formatClusters(clusters=good_clusters, p=11, clust_names=names(good_clusters), get_prototypes=TRUE, x=x2, y=y) prototypes &lt;- format_clust_res$prototypes clus_formatted &lt;- format_clust_res$clusters res &lt;- clusterRepLasso(x2, y, good_clusters, nlambda=50) testthat::expect_true(is.list(res)) testthat::expect_identical(names(res), c(&quot;selected_sets&quot;, &quot;selected_clusts_list&quot;, &quot;beta&quot;)) # selected_sets testthat::expect_true(is.list(res$selected_sets)) # Selected models should have one of each size without repetition lengths &lt;- lengths(res$selected_sets) lengths &lt;- lengths[lengths != 0] testthat::expect_identical(lengths, unique(lengths)) for(i in 1:length(res$selected_sets)){ if(!is.null(res$selected_sets[[i]])){ testthat::expect_true(is.integer(res$selected_sets[[i]])) testthat::expect_true(all(!is.na(res$selected_sets[[i]]))) testthat::expect_true(all(res$selected_sets[[i]] %in% prototypes)) testthat::expect_equal(length(res$selected_sets[[i]]), i) testthat::expect_true(all(names(res$selected_sets[[i]]) %in% LETTERS[1:11])) } else{ testthat::expect_true(is.null(res$selected_sets[[i]])) } } # selected_clusts_list testthat::expect_true(is.list(res$selected_clusts_list)) # Selected models should have one of each size without repetition clust_lengths &lt;- lengths(res$selected_clusts_list) clust_lengths &lt;- clust_lengths[clust_lengths != 0] testthat::expect_identical(clust_lengths, unique(clust_lengths)) for(k in 1:length(res$selected_clusts_list)){ if(!is.null(res$selected_clusts_list[[k]])){ testthat::expect_true(is.list(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_sets[[k]]), length(res$selected_clusts_list[[k]])) testthat::expect_equal(length(res$selected_clusts_list[[k]]), k) sel_feats &lt;- unlist(res$selected_clusts_list[[k]]) testthat::expect_true(all(sel_feats %in% 1:11)) testthat::expect_equal(length(sel_feats), length(unique(sel_feats))) n_clusts &lt;- k for(i in 1:n_clusts){ clust_i_found &lt;- FALSE clust_i &lt;- res$selected_clusts_list[[k]][[i]] for(j in 1:length(clus_formatted)){ clust_i_found &lt;- clust_i_found | identical(clust_i, clus_formatted[[j]]) } testthat::expect_true(clust_i_found) } } else{ testthat::expect_true(is.null(res$selected_clusts_list[[k]])) } } # beta testthat::expect_true(grepl(&quot;dgCMatrix&quot;, class(res$beta))) testthat::expect_true(nrow(res$beta) == 11 - 8 + 2) testthat::expect_true(ncol(res$beta) &lt;= 50) # Bad inputs testthat::expect_error(clusterRepLasso(X=&quot;x&quot;, y=y[1:10], clusters=good_clusters, nlambda=10), &quot;is.matrix(X) | is.data.frame(X) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(clusterRepLasso(X=x, y=y[1:10], clusters=good_clusters, nlambda=10), &quot;n == length(y) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(clusterRepLasso(X=x, y=y, clusters=list(1:4, 4:6), nlambda=10), &quot;Overlapping clusters detected; clusters must be non-overlapping. Overlapping clusters: 1, 2.&quot;, fixed=TRUE) testthat::expect_error(clusterRepLasso(X=x, y=y, clusters=list(2:3, 2:3), nlambda=10), &quot;length(clusters) == length(unique(clusters)) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(clusterRepLasso(X=x, y=y, clusters=list(1:4, as.integer(NA)), nlambda=10), &quot;!is.na(clusters) are not all TRUE&quot;, fixed=TRUE) testthat::expect_error(clusterRepLasso(X=x, y=y, clusters=list(2:3, c(4, 4, 5)), nlambda=10), &quot;length(clusters[[i]]) == length(unique(clusters[[i]])) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(clusterRepLasso(X=x, y=y, clusters=good_clusters, nlambda=1), &quot;nlambda &gt;= 2 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(clusterRepLasso(X=x, y=y, clusters=good_clusters, nlambda=x), &quot;length(nlambda) == 1 is not TRUE&quot;, fixed=TRUE) testthat::expect_error(clusterRepLasso(X=x, y=y, clusters=good_clusters, nlambda=&quot;nlambda&quot;), &quot;is.numeric(nlambda) | is.integer(nlambda) is not TRUE&quot;, fixed=TRUE) testthat::expect_error(clusterRepLasso(X=x, y=y, clusters=good_clusters, nlambda=10.5), &quot;nlambda == round(nlambda) is not TRUE&quot;, fixed=TRUE) }) ## Test passed 🥇 "],["documenting-the-package-and-adding-readme-and-pkgdown-website.html", "9 Documenting the package and adding README and pkgdown website 9.1 Add README 9.2 Add pkdgown site", " 9 Documenting the package and adding README and pkgdown website We finish by running commands that will document the package. litr::document() # &lt;-- use instead of devtools::document() ## ℹ Updating cssr documentation ## ℹ Loading cssr ## Writing &#39;]8;;file:///Users/gregfaletto/Documents/GitHub/cssr-project/cssr/NAMESPACENAMESPACE]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkB&#39;)checkB.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkClusters&#39;)checkClusters.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkCssClustersInput&#39;)checkCssClustersInput.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkCssInputs&#39;)checkCssInputs.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkCssLassoInputs&#39;)checkCssLassoInputs.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkCssLoopOutput&#39;)checkCssLoopOutput.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkCutoff&#39;)checkCutoff.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkFormCssDesignInputs&#39;)checkFormCssDesignInputs.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkFormatClustersInput&#39;)checkFormatClustersInput.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkGenClusteredDataInputs&#39;)checkGenClusteredDataInputs.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkGenClusteredDataWeightedInputs&#39;)checkGenClusteredDataWeightedInputs.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkGenClusteredDataWeightedRandomInputs&#39;)checkGenClusteredDataWeightedRandomInputs.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkGetClusterSelMatrixInput&#39;)checkGetClusterSelMatrixInput.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkGetCssPredsInputs&#39;)checkGetCssPredsInputs.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkGetSelectedClustersOutput&#39;)checkGetSelectedClustersOutput.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkGetXglmnetInputs&#39;)checkGetXglmnetInputs.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkMaxNumClusts&#39;)checkMaxNumClusts.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkMinNumClusts&#39;)checkMinNumClusts.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkNewXProvided&#39;)checkNewXProvided.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkPropFeatsRemove&#39;)checkPropFeatsRemove.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkSamplingType&#39;)checkSamplingType.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkSelectedClusters&#39;)checkSelectedClusters.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkWeighting&#39;)checkWeighting.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkXInputResults&#39;)checkXInputResults.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;checkY&#39;)checkY.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;clusterRepLasso&#39;)clusterRepLasso.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;corFunction&#39;)corFunction.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;createSubsamples&#39;)createSubsamples.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;css&#39;)css.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;cssLasso&#39;)cssLasso.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;cssLoop&#39;)cssLoop.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;cssPredict&#39;)cssPredict.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;cssSelect&#39;)cssSelect.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;cssr-package&#39;)cssr-package.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;formCssDesign&#39;)formCssDesign.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;formatClusters&#39;)formatClusters.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;genClusteredData&#39;)genClusteredData.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;genClusteredDataWeighted&#39;)genClusteredDataWeighted.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;genClusteredDataWeightedRandom&#39;)genClusteredDataWeightedRandom.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;genZmuY&#39;)genZmuY.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getAllClustWeights&#39;)getAllClustWeights.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getClustWeights&#39;)getClustWeights.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getClusterSelMatrix&#39;)getClusterSelMatrix.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getClusterSelsFromGlmnet&#39;)getClusterSelsFromGlmnet.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getCssDesign&#39;)getCssDesign.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getCssPreds&#39;)getCssPreds.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getCssSelections&#39;)getCssSelections.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getLassoLambda&#39;)getLassoLambda.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getModelSize&#39;)getModelSize.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getNoiseVar&#39;)getNoiseVar.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getPrototypes&#39;)getPrototypes.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getSelMatrix&#39;)getSelMatrix.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getSelectedClusters&#39;)getSelectedClusters.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getSelectedSets&#39;)getSelectedSets.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getSelectionPrototypes&#39;)getSelectionPrototypes.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getSubsamps&#39;)getSubsamps.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;getXglmnet&#39;)getXglmnet.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;identifyPrototype&#39;)identifyPrototype.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;print.cssr&#39;)print.cssr.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;printCssDf&#39;)printCssDf.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;processClusterLassoInputs&#39;)processClusterLassoInputs.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;protolasso&#39;)protolasso.Rd]8;;&#39; 9.1 Add README litr::add_readme(&quot;../source-files/README.Rmd&quot;) ## ✔ Writing &#39;README.Rmd&#39; ## ✔ Adding &#39;^README\\\\.Rmd$&#39; to &#39;.Rbuildignore&#39; ## ✔ Creating &#39;.git/hooks/&#39; ## ✔ Writing &#39;.git/hooks/pre-commit&#39; Let’s move the two images that we refer to in the README into man/figures. This is based on the “Images and figures” section of the man page for pkgdown::build_home_index(). fs::dir_create(&quot;man/figures&quot;) fs::file_copy(&quot;../source-files/stability-selection-diagram.png&quot;, &quot;man/figures&quot;) fs::file_copy(&quot;../source-files/sel_props.png&quot;, &quot;man/figures&quot;) 9.2 Add pkdgown site litr::add_pkgdown(&quot;../source-files/_pkgdown.yml&quot;) ## ✔ Adding &#39;^_pkgdown\\\\.yml$&#39;, &#39;^docs$&#39;, &#39;^pkgdown$&#39; to &#39;.Rbuildignore&#39; ## Warning in tools::parse_Rd(path, macros = macros, encoding = &quot;UTF-8&quot;): ## ./man/cssLoop.Rd:10: unknown macro &#39;\\item&#39; ## Warning in tools::parse_Rd(path, macros = macros, encoding = &quot;UTF-8&quot;): ## ./man/cssLoop.Rd:12: unknown macro &#39;\\item&#39; ## Warning in tools::parse_Rd(path, macros = macros, encoding = &quot;UTF-8&quot;): ## ./man/genZmuY.Rd:78: unexpected section header &#39;\\description&#39; ## Warning in tools::parse_Rd(path, macros = macros, encoding = &quot;UTF-8&quot;): ## ./man/genZmuY.Rd:82: unexpected section header &#39;\\references&#39; ## Warning in tools::parse_Rd(path, macros = macros, encoding = &quot;UTF-8&quot;): ## ./man/genZmuY.Rd:87: unexpected section header &#39;\\author&#39; ## Warning in tools::parse_Rd(path, macros = macros, encoding = &quot;UTF-8&quot;): ./man/genZmuY.Rd:90: unexpected END_OF_INPUT &#39; ## &#39; ## Warning in tools::parse_Rd(path, macros = macros, encoding = &quot;UTF-8&quot;): ## ./man/getSelMatrix.Rd:45: unknown macro &#39;\\item&#39; ## Warning in tools::parse_Rd(path, macros = macros, encoding = &quot;UTF-8&quot;): ## ./man/getSelMatrix.Rd:47: unknown macro &#39;\\item&#39; ## -- Installing package into temporary library ----------------------------------- ## == Building pkgdown site ======================================================= ## Reading from: &#39;/Users/gregfaletto/Documents/GitHub/cssr-project/cssr&#39; ## Writing to: &#39;/Users/gregfaletto/Documents/GitHub/cssr-project/docs&#39; ## -- Initialising site ----------------------------------------------------------- ## -- Building home --------------------------------------------------------------- ## Reading &#39;LICENSE.md&#39; ## Writing &#39;404.html&#39; ## -- Building function reference ------------------------------------------------- ## Reading &#39;man/checkB.Rd&#39; ## Reading &#39;man/checkClusters.Rd&#39; ## Reading &#39;man/checkCssClustersInput.Rd&#39; ## Reading &#39;man/checkCssInputs.Rd&#39; ## Reading &#39;man/checkCssLassoInputs.Rd&#39; ## Reading &#39;man/checkCssLoopOutput.Rd&#39; ## Reading &#39;man/checkCutoff.Rd&#39; ## Reading &#39;man/checkFormCssDesignInputs.Rd&#39; ## Reading &#39;man/checkFormatClustersInput.Rd&#39; ## Reading &#39;man/checkGenClusteredDataInputs.Rd&#39; ## Reading &#39;man/checkGenClusteredDataWeightedInputs.Rd&#39; ## Reading &#39;man/checkGenClusteredDataWeightedRandomInputs.Rd&#39; ## Reading &#39;man/checkGetClusterSelMatrixInput.Rd&#39; ## Reading &#39;man/checkGetCssPredsInputs.Rd&#39; ## Reading &#39;man/checkGetSelectedClustersOutput.Rd&#39; ## Reading &#39;man/checkGetXglmnetInputs.Rd&#39; ## Reading &#39;man/checkMaxNumClusts.Rd&#39; ## Reading &#39;man/checkMinNumClusts.Rd&#39; ## Reading &#39;man/checkNewXProvided.Rd&#39; ## Reading &#39;man/checkPropFeatsRemove.Rd&#39; ## Reading &#39;man/checkSamplingType.Rd&#39; ## Reading &#39;man/checkSelectedClusters.Rd&#39; ## Reading &#39;man/checkWeighting.Rd&#39; ## Reading &#39;man/checkXInputResults.Rd&#39; ## Reading &#39;man/checkY.Rd&#39; ## Reading &#39;man/clusterRepLasso.Rd&#39; ## Reading &#39;man/corFunction.Rd&#39; ## Reading &#39;man/createSubsamples.Rd&#39; ## Reading &#39;man/css.Rd&#39; ## Reading &#39;man/cssLasso.Rd&#39; ## Reading &#39;man/cssLoop.Rd&#39; ## Unknown tag: UNKNOWN/tag ## Unknown tag: UNKNOWN/tag ## Reading &#39;man/cssPredict.Rd&#39; ## Reading &#39;man/cssSelect.Rd&#39; ## Reading &#39;man/cssr-package.Rd&#39; ## Reading &#39;man/formCssDesign.Rd&#39; ## Reading &#39;man/formatClusters.Rd&#39; ## Reading &#39;man/genClusteredData.Rd&#39; ## Reading &#39;man/genClusteredDataWeighted.Rd&#39; ## Writing &#39;reference/genClusteredDataWeighted.html&#39; ## Reading &#39;man/genClusteredDataWeightedRandom.Rd&#39; ## Reading &#39;man/genZmuY.Rd&#39; ## Reading &#39;man/getAllClustWeights.Rd&#39; ## Reading &#39;man/getClustWeights.Rd&#39; ## Reading &#39;man/getClusterSelMatrix.Rd&#39; ## Reading &#39;man/getClusterSelsFromGlmnet.Rd&#39; ## Reading &#39;man/getCssDesign.Rd&#39; ## Reading &#39;man/getCssPreds.Rd&#39; ## Reading &#39;man/getCssSelections.Rd&#39; ## Reading &#39;man/getLassoLambda.Rd&#39; ## Reading &#39;man/getModelSize.Rd&#39; ## Reading &#39;man/getNoiseVar.Rd&#39; ## Reading &#39;man/getPrototypes.Rd&#39; ## Reading &#39;man/getSelMatrix.Rd&#39; ## Unknown tag: UNKNOWN/tag ## Unknown tag: UNKNOWN/tag ## Reading &#39;man/getSelectedClusters.Rd&#39; ## Reading &#39;man/getSelectedSets.Rd&#39; ## Reading &#39;man/getSelectionPrototypes.Rd&#39; ## Reading &#39;man/getSubsamps.Rd&#39; ## Reading &#39;man/getXglmnet.Rd&#39; ## Reading &#39;man/identifyPrototype.Rd&#39; ## Reading &#39;man/print.cssr.Rd&#39; ## Reading &#39;man/printCssDf.Rd&#39; ## Reading &#39;man/processClusterLassoInputs.Rd&#39; ## Reading &#39;man/protolasso.Rd&#39; ## Writing &#39;sitemap.xml&#39; ## -- Building search index ------------------------------------------------------- ## == DONE ======================================================================== "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
